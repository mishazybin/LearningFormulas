{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q41R-POjCq1e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.nn import MSELoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import time\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "import pickle\n",
    "import NestedFormula\n",
    "import auxiliary_functions\n",
    "import explore\n",
    "import importlib\n",
    "from hessian import hessian\n",
    "from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'explore' from '/home/zybinmikhail/Documents/personal github projects/LearningFormulas/explore.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(NestedFormula)\n",
    "importlib.reload(auxiliary_functions)\n",
    "importlib.reload(explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear combination of 3 variables and bias with standard-normally distributed coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0449, current formula \\left(-11.424x_1^{-0.027} + 10.731x_2^{-0.015} + 0.915x_3^{1.071} + 0.819\\right)\n",
      "  Finished run #1, loss 0.04426300898194313, best loss 0.04426300898194313\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.011057988740503788, best loss 0.011057988740503788\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 7.58524076882594e-10, best loss 7.58524076882594e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "38 seconds passed from the start, the iteration took 38 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.276x_{1}^{1}-0.65x_{2}^{1}+0.9x_{3}^{1}-0.344$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.276x_1^{1.000}-0.650x_2^{1.000} + 0.900x_3^{1.000}-0.344\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.2181853367313319e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.01343916542828083, best loss 0.01343916542828083\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0015267726266756654, best loss 0.0015267726266756654\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.013873125426471233, best loss 0.0015267726266756654\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.011437230743467808, best loss 0.0015267726266756654\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 0.00028848694637417793, best loss 0.00028848694637417793\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 0.011361205950379372, best loss 0.00028848694637417793\n",
      "  Initialization #7\n",
      "  Finished run #7, loss 0.012482903897762299, best loss 0.00028848694637417793\n",
      "  Initialization #8\n",
      "    Epoch 5000, current loss 0.00934, current formula \\left(5.719x_1^{-0.029}-0.210x_2^{1.102} + 1.330x_3^{-0.024}-6.305\\right)\n",
      "  Finished run #8, loss 0.00918937474489212, best loss 0.00028848694637417793\n",
      "  Initialization #9\n",
      "  Finished run #9, loss 0.011318389326334, best loss 0.00028848694637417793\n",
      "  Initialization #10\n",
      "  Finished run #10, loss 0.00027836591470986605, best loss 0.00027836591470986605\n",
      "1 minutes 34 seconds passed from the start, the iteration took 56 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.675x_{1}^{1}-0.208x_{2}^{1}-0.127x_{3}^{1}+1.352$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.674x_1^{0.997}-0.211x_2^{0.978}-1.659x_3^{0.021} + 2.916\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.8217513293213506\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0004741509328596294, best loss 0.0004741509328596294\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.00046852396917529404, best loss 0.00046852396917529404\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.000554167025256902, best loss 0.00046852396917529404\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.823388856043607e-09, best loss 2.823388856043607e-09\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 49 seconds passed from the start, the iteration took 15 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.58x_{1}^{1}-1.201x_{2}^{1}+0.161x_{3}^{1}-1.495$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.580x_1^{1.000}-1.201x_2^{1.000} + 0.161x_3^{1.002}-1.495\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.0111635002463e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.996097672879898e-10, best loss 7.996097672879898e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 51 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.571x_{1}^{1}-0.64x_{2}^{1}-0.373x_{3}^{1}+0.536$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.571x_1^{1.000}-0.640x_2^{1.000}-0.373x_3^{1.000} + 0.536\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.000738325021205e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.119, current formula \\left(0.060x_1^{5.802}-9.050x_2^{-0.051}-1.181x_3^{0.991} + 9.822\\right)\n",
      "    Epoch 10000, current loss 0.114, current formula \\left(0.059x_1^{5.951}-14.402x_2^{-0.034}-1.188x_3^{0.977} + 15.199\\right)\n",
      "  Finished run #1, loss 0.11366713047027588, best loss 0.11366713047027588\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.2134427624109776e-08, best loss 2.2134427624109776e-08\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 32 seconds passed from the start, the iteration took 41 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.065x_{1}^{1}+2.196x_{2}^{1}-1.213x_{3}^{1}-0.766$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.065x_1^{0.993} + 2.195x_2^{1.000}-1.213x_3^{0.999}-0.765\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.7070178810246794e-06\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #6----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.651099422796733e-09, best loss 3.651099422796733e-09\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 34 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.423x_{1}^{1}-0.364x_{2}^{1}-0.849x_{3}^{1}-0.66$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.424x_1^{1.000}-0.365x_2^{0.999}-0.849x_3^{1.000}-0.660\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.073016812444556e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #7----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.012222030200064182, best loss 0.012222030200064182\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.1197285704488422e-08, best loss 2.1197285704488422e-08\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 38 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.847x_{1}^{1}+0.59x_{2}^{1}+0.205x_{3}^{1}+1.124$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.847x_1^{0.999} + 0.590x_2^{0.999} + 0.206x_3^{0.996} + 1.123\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.166313272906507e-06\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #8----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 5.693628679637186e-09, best loss 5.693628679637186e-09\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 40 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.68x_{1}^{1}+0.608x_{2}^{1}-0.857x_{3}^{1}+0.342$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.679x_1^{1.001} + 0.608x_2^{0.999}-0.857x_3^{1.001} + 0.341\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.9255488898599943e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #9----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0002396345662418753, best loss 0.0002396345662418753\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0001678973058005795, best loss 0.0001678973058005795\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.002253648592159152, best loss 0.0001678973058005795\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0036190208047628403, best loss 0.0001678973058005795\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 4.4747611172013535e-10, best loss 4.4747611172013535e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 52 seconds passed from the start, the iteration took 13 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.421x_{1}^{1}-0.371x_{2}^{1}+0.112x_{3}^{1}-1.21$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.421x_1^{1.000}-0.371x_2^{1.000} + 0.112x_3^{1.001}-1.210\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.1145637650400927e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #10----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.012512505054473877, best loss 0.012512505054473877\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.011847813613712788, best loss 0.011847813613712788\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.04677753150463104, best loss 0.011847813613712788\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.9658236977425645e-10, best loss 2.9658236977425645e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 6 seconds passed from the start, the iteration took 13 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.744x_{1}^{1}-0.694x_{2}^{1}-0.945x_{3}^{1}+0.209$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.744x_1^{1.000}-0.694x_2^{1.000}-0.945x_3^{1.000} + 0.209\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.622096477786857e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.2181853367313319e-08, 0.8217513293213506, 7.0111635002463e-07, 5.000738325021205e-08, 6.7070178810246794e-06, 3.073016812444556e-07, 3.166313272906507e-06, 1.9255488898599943e-07, 2.1145637650400927e-07, 7.622096477786857e-09]\n",
      "For 9 formulas out of 10 the error is less than 1e-05.\n"
     ]
    }
   ],
   "source": [
    "explore.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear combination of 3 squared variables and bias with standard-normally distributed coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.19504092633724213, best loss 0.19504092633724213\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.007013747934252024, best loss 0.007013747934252024\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.009375261142849922, best loss 0.007013747934252024\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.009800040163099766, best loss 0.007013747934252024\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 1.8762023185070476e-12, best loss 1.8762023185070476e-12\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "15 seconds passed from the start, the iteration took 15 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -2.118x_{1}^{2}-2.121x_{2}^{2}+0.462x_{3}^{2}+0.852$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.118x_1^{2.000}-2.121x_2^{2.000} + 0.462x_3^{2.000} + 0.852\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.69699216717033e-12\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.5127137743701242e-12, best loss 3.5127137743701242e-12\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "16 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.787x_{1}^{2}-0.506x_{2}^{2}-1.607x_{3}^{2}+1.722$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.787x_1^{2.000}-0.506x_2^{2.000}-1.607x_3^{2.000} + 1.722\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.412026548081485e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.1483605057001114, best loss 0.1483605057001114\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.02518836408853531, best loss 0.02518836408853531\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.3154793226943795e-11, best loss 1.3154793226943795e-11\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "32 seconds passed from the start, the iteration took 15 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.043x_{1}^{2}-1.52x_{2}^{2}-0.755x_{3}^{2}-0.242$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.043x_1^{2.000}-1.520x_2^{2.000}-0.755x_3^{2.000}-0.242\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.558649565503304e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.5556061647159503e-11, best loss 1.5556061647159503e-11\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "33 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.549x_{1}^{2}+0.916x_{2}^{2}+1.277x_{3}^{2}+0.891$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.549x_1^{2.000} + 0.916x_2^{2.000} + 1.277x_3^{2.000} + 0.891\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.6123866630815817e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0013860539766028523, best loss 0.0013860539766028523\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0016387712676078081, best loss 0.0013860539766028523\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 5.024526801566953e-12, best loss 5.024526801566953e-12\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "38 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.11x_{1}^{2}-2.128x_{2}^{2}+0.169x_{3}^{2}-0.251$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.110x_1^{2.000}-2.128x_2^{2.000} + 0.169x_3^{2.000}-0.251\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.520428805612953e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #6----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.03510764613747597, best loss 0.03510764613747597\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.03426942229270935, best loss 0.03426942229270935\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.035176824778318405, best loss 0.03426942229270935\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.023263581097126007, best loss 0.023263581097126007\n",
      "  Initialization #5\n",
      "    Epoch 5000, current loss 0.054, current formula \\left(0.879x_1^{1.832}-8.612x_2^{-0.023} + 8.933x_3^{-0.019}-1.041\\right)\n",
      "    Epoch 10000, current loss 0.0535, current formula \\left(0.879x_1^{1.835}-12.666x_2^{-0.016} + 12.986x_3^{-0.013}-1.041\\right)\n",
      "  Finished run #5, loss 0.05348413810133934, best loss 0.023263581097126007\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 8.06729336111367e-12, best loss 8.06729336111367e-12\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "1 minutes 29 seconds passed from the start, the iteration took 51 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.917x_{1}^{2}+0.782x_{2}^{2}-0.866x_{3}^{2}-0.72$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.917x_1^{2.000} + 0.782x_2^{2.000}-0.866x_3^{2.000}-0.720\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.1134510842483516e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #7----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.010849709622561932, best loss 0.010849709622561932\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.038911230862140656, best loss 0.010849709622561932\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.009395286440849304, best loss 0.009395286440849304\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0017017177306115627, best loss 0.0017017177306115627\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 0.03575057163834572, best loss 0.0017017177306115627\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 0.011514522135257721, best loss 0.0017017177306115627\n",
      "  Initialization #7\n",
      "    Epoch 5000, current loss 0.0114, current formula \\left(-5.762x_1^{-0.020} + 0.945x_2^{1.895} + 3.524x_3^{-0.011} + 3.652\\right)\n",
      "  Finished run #7, loss 0.011352745816111565, best loss 0.0017017177306115627\n",
      "  Initialization #8\n",
      "  Finished run #8, loss 1.14887084221027e-11, best loss 1.14887084221027e-11\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "2 minutes 46 seconds passed from the start, the iteration took 1 minutes 17 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.517x_{1}^{2}+0.938x_{2}^{2}-0.182x_{3}^{2}+1.244$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.517x_1^{2.000} + 0.938x_2^{2.000}-0.182x_3^{2.000} + 1.244\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.36695601003672e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #8----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.00043949144310317934, best loss 0.00043949144310317934\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "2 minutes 48 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.118x_{1}^{2}-0.574x_{2}^{2}-0.106x_{3}^{2}+2.927$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.118x_1^{1.944}-0.576x_2^{2.009} + 2.378x_3^{-0.010} + 0.491\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.306655452500273\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #9----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.1731370175581688e-11, best loss 2.1731370175581688e-11\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "2 minutes 50 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.098x_{1}^{2}+0.082x_{2}^{2}-1.988x_{3}^{2}-0.771$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.098x_1^{2.000} + 0.082x_2^{1.999}-1.988x_3^{2.000}-0.771\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.782828465030533e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #10----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.292567591465904e-12, best loss 7.292567591465904e-12\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "2 minutes 55 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.726x_{1}^{2}-0.951x_{2}^{2}+0.516x_{3}^{2}-0.259$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.726x_1^{2.000}-0.951x_2^{2.000} + 0.516x_3^{2.000}-0.259\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.295644557788495e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[6.69699216717033e-12, 7.412026548081485e-11, 3.558649565503304e-10, 4.6123866630815817e-10, 3.520428805612953e-09, 3.1134510842483516e-10, 6.36695601003672e-09, 2.306655452500273, 7.782828465030533e-08, 5.295644557788495e-10]\n",
      "For 9 formulas out of 10 the error is less than 1e-05.\n"
     ]
    }
   ],
   "source": [
    "explore(min_power=2, max_power=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear combination of 3 variables with powers uniformly distributed over {1, 2 ,3 ,4, 5} and standard-normally distributed coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.06304360181093216, best loss 0.06304360181093216\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.004367060959339142, best loss 0.004367060959339142\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.3601357019832339e-11, best loss 1.3601357019832339e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "6 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.126x_{1}^{2}-1.236x_{2}^{2}+0.312x_{3}^{3}+0.729$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.126x_1^{2.000}-1.236x_2^{2.000} + 0.312x_3^{3.000} + 0.729\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.667260058065235e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.08279216289520264, best loss 0.08279216289520264\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.7293509289514897e-12, best loss 1.7293509289514897e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "10 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.937x_{1}^{4}-0.922x_{2}^{4}+1.209x_{3}^{5}+1.655$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.937x_1^{4.000}-0.922x_2^{4.000} + 1.209x_3^{5.000} + 1.655\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1465926620855628e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.422276226791424e-13, best loss 7.422276226791424e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "14 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.539x_{1}^{6}-1.276x_{2}^{3}-0.967x_{3}^{6}-0.346$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.539x_1^{6.000}-1.276x_2^{3.000}-0.967x_3^{6.000}-0.346\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1858755247625855e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.002982549136504531, best loss 0.002982549136504531\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.033160265535116196, best loss 0.002982549136504531\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.09207728505134583, best loss 0.002982549136504531\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.03271259367465973, best loss 0.002982549136504531\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 0.0027095582336187363, best loss 0.0027095582336187363\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 2.9511610169508096e-12, best loss 2.9511610169508096e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "36 seconds passed from the start, the iteration took 22 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.452x_{1}^{4}-0.316x_{2}^{1}-0.89x_{3}^{6}-1.062$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.452x_1^{4.000}-0.316x_2^{1.000}-0.890x_3^{6.000}-1.062\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.3764445208005004e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0621, current formula \\left(-7.449x_1^{-0.011}-0.163x_2^{3.560} + 6.996x_3^{-0.015} + 0.764\\right)\n",
      "  Finished run #1, loss 0.06207393482327461, best loss 0.06207393482327461\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0622, current formula \\left(-7.718x_1^{-0.011}-0.163x_2^{3.565} + 6.194x_3^{-0.017} + 1.836\\right)\n",
      "  Finished run #2, loss 0.06211938336491585, best loss 0.06207393482327461\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.208213824127613e-11, best loss 1.208213824127613e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 25 seconds passed from the start, the iteration took 49 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.526x_{1}^{4}-0.143x_{2}^{2}-1.118x_{3}^{6}+0.4$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.526x_1^{4.000}-0.143x_2^{2.000}-1.118x_3^{6.000} + 0.400\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.4469741119579486e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #6----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.08188065886497498, best loss 0.08188065886497498\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.182, current formula \\left(-9.522x_1^{-0.026} + 1.402x_2^{4.533} + 2.577x_3^{0.022} + 8.277\\right)\n",
      "  Finished run #2, loss 0.18087251484394073, best loss 0.08188065886497498\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0822642371058464, best loss 0.08188065886497498\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.086057455247259e-12, best loss 2.086057455247259e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 3 seconds passed from the start, the iteration took 38 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.963x_{1}^{5}+1.38x_{2}^{5}+0.423x_{3}^{6}+0.658$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.963x_1^{5.000} + 1.380x_2^{5.000} + 0.423x_3^{6.000} + 0.658\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.5023411086596232e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #7----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0009585803491063416, best loss 0.0009585803491063416\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.016282297670841217, best loss 0.0009585803491063416\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.016563350334763527, best loss 0.0009585803491063416\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 6.829097292000708e-13, best loss 6.829097292000708e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 31 seconds passed from the start, the iteration took 28 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.571x_{1}^{5}+0.15x_{2}^{5}-0.613x_{3}^{2}+1.084$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.571x_1^{5.000} + 0.150x_2^{5.000}-0.613x_3^{2.000} + 1.084\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.4865421660867923e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #8----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0010126919951289892, best loss 0.0010126919951289892\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 5.297980804064295e-12, best loss 5.297980804064295e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 34 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.154x_{1}^{5}-0.309x_{2}^{3}+1.08x_{3}^{1}+0.952$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.154x_1^{5.000}-0.309x_2^{3.000} + 1.080x_3^{1.000} + 0.952\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1178741107390318e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #9----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.05849596858024597, best loss 0.05849596858024597\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.000568809628020972, best loss 0.000568809628020972\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0352, current formula \\left(-1.289x_1^{-0.011}-5.506x_2^{-0.024} + 0.662x_3^{3.975} + 5.457\\right)\n",
      "  Finished run #3, loss 0.03520870953798294, best loss 0.000568809628020972\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.034622740000486374, best loss 0.000568809628020972\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 0.0006225152174010873, best loss 0.000568809628020972\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 5.907022267159778e-12, best loss 5.907022267159778e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 3 seconds passed from the start, the iteration took 29 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.11x_{1}^{3}+0.842x_{2}^{3}+0.655x_{3}^{4}-1.72$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.110x_1^{3.000} + 0.842x_2^{3.000} + 0.655x_3^{4.000}-1.720\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.363041794779213e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #10----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.005140147637575865, best loss 0.005140147637575865\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.1832983377868533e-11, best loss 1.1832983377868533e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 6 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.014x_{1}^{3}+0.342x_{2}^{2}-0.814x_{3}^{6}+0.378$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.014x_1^{2.997} + 0.342x_2^{2.000}-0.814x_3^{6.000} + 0.378\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.018604936760181e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[5.667260058065235e-09, 1.1465926620855628e-10, 1.1858755247625855e-10, 3.3764445208005004e-10, 1.4469741119579486e-08, 1.5023411086596232e-10, 3.4865421660867923e-10, 1.1178741107390318e-08, 2.363041794779213e-08, 9.018604936760181e-07]\n",
      "For 10 formulas out of 10 the error is less than 1e-05.\n"
     ]
    }
   ],
   "source": [
    "explore.explore(max_power=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0005649023805744946, best loss 0.0005649023805744946\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 3.363373165046757e-12, best loss 3.363373165046757e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.049x_{1}^{3.333}+0.114x_{2}^{4.667}+1.084x_{3}^{1.667}-0.099$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.049x_1^{3.333} + 0.114x_2^{4.667} + 1.084x_3^{1.667}-0.099\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0837911044804726e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.043854933232069016, best loss 0.043854933232069016\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 5.613911113755421e-09, best loss 5.613911113755421e-09\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "15 seconds passed from the start, the iteration took 12 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.221x_{1}^{2.0}-1.776x_{2}^{0.667}-1.643x_{3}^{1.333}+1.616$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.221x_1^{2.000}-1.776x_2^{0.667}-1.643x_3^{1.334} + 1.615\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.233614190178222e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.028962085023522377, best loss 0.028962085023522377\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 4.988416549167596e-05, best loss 4.988416549167596e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.026912150904536247, best loss 4.988416549167596e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.14470908045768738, best loss 4.988416549167596e-05\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 5.1276245358167216e-05, best loss 4.988416549167596e-05\n",
      "  Initialization #6\n",
      "    Epoch 5000, current loss 0.153, current formula \\left(0.061x_1^{14.948} + 13.875x_2^{-0.027}-12.422x_3^{-0.014}-2.685\\right)\n",
      "  Finished run #6, loss 0.15167467296123505, best loss 4.988416549167596e-05\n",
      "  Initialization #7\n",
      "  Finished run #7, loss 5.1009068556595594e-05, best loss 4.988416549167596e-05\n",
      "  Initialization #8\n",
      "  Finished run #8, loss 0.029082538560032845, best loss 4.988416549167596e-05\n",
      "  Initialization #9\n",
      "  Finished run #9, loss 0.02650262415409088, best loss 4.988416549167596e-05\n",
      "  Initialization #10\n",
      "  Finished run #10, loss 0.13250789046287537, best loss 4.988416549167596e-05\n",
      "1 minutes 27 seconds passed from the start, the iteration took 1 minutes 12 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.033x_{1}^{3.667}-1.803x_{2}^{1.667}+0.798x_{3}^{2.333}-0.584$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.351x_1^{-0.004}-1.803x_2^{1.664} + 0.799x_3^{2.329} + 0.779\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.464195771728083\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.00016132325981743634, best loss 0.00016132325981743634\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 5.5267452940543915e-12, best loss 5.5267452940543915e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 31 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.232x_{1}^{2.333}+0.259x_{2}^{4.0}-0.06x_{3}^{2.667}-0.169$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.232x_1^{2.333} + 0.259x_2^{4.000}-0.060x_3^{2.666}-0.169\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.936620335265317e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.017211973667144775, best loss 0.017211973667144775\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.972271304606643e-12, best loss 1.972271304606643e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 39 seconds passed from the start, the iteration took 9 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.623x_{1}^{2.0}-1.421x_{2}^{2.667}+1.193x_{3}^{2.333}-1.313$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.623x_1^{2.000}-1.421x_2^{2.667} + 1.193x_3^{2.333}-1.313\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.349257627594592e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #6----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0459, current formula \\left(-8.472x_1^{-0.034} + 7.621x_2^{-0.010}-2.173x_3^{3.907} + 1.297\\right)\n",
      "  Finished run #1, loss 0.045699264854192734, best loss 0.045699264854192734\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.03883028030395508, best loss 0.03883028030395508\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.010128953494131565, best loss 0.010128953494131565\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.225, current formula \\left(1.250x_1^{0.741}-0.498x_2^{3.728} + 7.295x_3^{-0.041}-8.444\\right)\n",
      "    Epoch 10000, current loss 0.223, current formula \\left(1.254x_1^{0.735}-0.498x_2^{3.743} + 11.863x_3^{-0.026}-13.029\\right)\n",
      "  Finished run #4, loss 0.2226993441581726, best loss 0.010128953494131565\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 4.736817708905772e-12, best loss 4.736817708905772e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 55 seconds passed from the start, the iteration took 1 minutes 16 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.241x_{1}^{1.0}-0.46x_{2}^{3.667}-2.218x_{3}^{4.0}-0.299$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.241x_1^{1.000}-0.460x_2^{3.667}-2.218x_3^{4.000}-0.299\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.099755621237688e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #7----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 4.2805082395291905e-12, best loss 4.2805082395291905e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 57 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 3.203x_{1}^{2.333}-1.724x_{2}^{4.333}-0.757x_{3}^{1.667}-1.98$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(3.203x_1^{2.333}-1.724x_2^{4.333}-0.757x_3^{1.667}-1.980\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 8.138962519816622e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #8----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.016357822343707085, best loss 0.016357822343707085\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 6.806492820032872e-06, best loss 6.806492820032872e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 60 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.609x_{1}^{4.667}+0.781x_{2}^{5.0}-0.898x_{3}^{0.333}+1.012$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.608x_1^{4.660} + 0.780x_2^{4.990}-0.940x_3^{0.310} + 1.056\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.0006299513376686962\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #9----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.62283077601022e-12, best loss 1.62283077601022e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 1 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.027x_{1}^{4.667}+1.451x_{2}^{2.333}-1.368x_{3}^{2.667}-0.876$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.027x_1^{4.667} + 1.451x_2^{2.333}-1.368x_3^{2.667}-0.876\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.5763519957680336e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #10----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.805804489180446e-05, best loss 7.805804489180446e-05\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.04445670545101166, best loss 7.805804489180446e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 7.458134496118873e-05, best loss 7.458134496118873e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 6.3320629124064e-05, best loss 6.3320629124064e-05\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 0.04257139191031456, best loss 6.3320629124064e-05\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 0.04354075714945793, best loss 6.3320629124064e-05\n",
      "  Initialization #7\n",
      "  Finished run #7, loss 0.04352091625332832, best loss 6.3320629124064e-05\n",
      "  Initialization #8\n",
      "  Finished run #8, loss 6.833985389675945e-05, best loss 6.3320629124064e-05\n",
      "  Initialization #9\n",
      "    Epoch 5000, current loss 0.19, current formula \\left(-7.580x_1^{-0.043}-0.033x_2^{1.028} + 1.034x_3^{4.753} + 8.133\\right)\n",
      "  Finished run #9, loss 0.18901683390140533, best loss 6.3320629124064e-05\n",
      "  Initialization #10\n",
      "  Finished run #10, loss 0.24506711959838867, best loss 6.3320629124064e-05\n",
      "3 minutes 57 seconds passed from the start, the iteration took 56 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.913x_{1}^{3.333}-0.043x_{2}^{1.667}+0.953x_{3}^{4.333}-0.265$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.913x_1^{3.330}-2.160x_2^{0.005} + 0.954x_3^{4.325} + 1.869\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.6850588041040635\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.0837911044804726e-09, 7.233614190178222e-08, 2.464195771728083, 3.936620335265317e-08, 6.349257627594592e-11, 6.099755621237688e-11, 8.138962519816622e-11, 0.0006299513376686962, 4.5763519957680336e-11, 1.6850588041040635]\n",
      "For 7 formulas out of 10 the error is less than 1e-05.\n"
     ]
    }
   ],
   "source": [
    "explore.explore(max_power=15, divide_powers_by=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0942, current formula \\left(-16.218x_1^{-0.017} + 14.928x_2^{-0.021} + 1.766x_3^{0.021} + 1.120x_4^{2.003}-0.748\\right)\n",
      "  Finished run #1, loss 0.0930163636803627, best loss 0.0930163636803627\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0951, current formula \\left(-12.279x_1^{-0.022} + 13.479x_2^{-0.023}-0.602x_3^{-0.045} + 1.120x_4^{2.003}-0.878\\right)\n",
      "    Epoch 10000, current loss 0.0946, current formula \\left(-13.577x_1^{-0.020} + 14.814x_2^{-0.021}-0.647x_3^{-0.042} + 1.120x_4^{2.003}-0.870\\right)\n",
      "  Finished run #2, loss 0.09464673697948456, best loss 0.0930163636803627\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0474, current formula \\left(-4.589x_1^{-0.053}-1.287x_2^{1.368}-0.519x_3^{-0.052} + 1.140x_4^{1.980} + 5.665\\right)\n",
      "  Finished run #3, loss 0.046409040689468384, best loss 0.046409040689468384\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.1, current formula \\left(1.143x_1^{1.339} + 12.331x_2^{-0.026} + 0.332x_3^{5.156}-13.906x_4^{-0.018} + 1.078\\right)\n",
      "    Epoch 10000, current loss 0.0988, current formula \\left(1.144x_1^{1.343} + 18.714x_2^{-0.018} + 0.332x_3^{5.143}-20.276x_4^{-0.013} + 1.062\\right)\n",
      "  Finished run #4, loss 0.09879747033119202, best loss 0.046409040689468384\n",
      "  Initialization #5\n",
      "    Epoch 5000, current loss 0.0532, current formula \\left(1.160x_1^{1.292}-1.310x_2^{1.280} + 0.301x_3^{3.468}-5.114x_4^{-0.046} + 5.475\\right)\n",
      "    Epoch 10000, current loss 0.052, current formula \\left(1.159x_1^{1.300}-1.311x_2^{1.279} + 0.301x_3^{3.467}-8.301x_4^{-0.030} + 8.680\\right)\n",
      "  Finished run #5, loss 0.05199287459254265, best loss 0.046409040689468384\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 7.338774032916717e-11, best loss 7.338774032916717e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "4 minutes 3 seconds passed from the start, the iteration took 4 minutes 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.136x_{1}^{1.333}-1.342x_{2}^{1.25}+0.295x_{3}^{3.083}+1.159x_{4}^{1.917}-0.244$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.136x_1^{1.333}-1.342x_2^{1.250} + 0.295x_3^{3.083} + 1.159x_4^{1.917}-0.244\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.3299586704439434e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0011191540397703648, best loss 0.0011191540397703648\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.001156878424808383, best loss 0.0011191540397703648\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0633557066321373, best loss 0.0011191540397703648\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0646, current formula \\left(-0.155x_1^{1.299}-6.539x_2^{-0.044}-2.509x_3^{0.649}-1.934x_4^{1.843} + 8.407\\right)\n",
      "    Epoch 10000, current loss 0.0624, current formula \\left(-0.159x_1^{1.085}-10.400x_2^{-0.029}-2.516x_3^{0.645}-1.935x_4^{1.843} + 12.296\\right)\n",
      "  Finished run #4, loss 0.06237761676311493, best loss 0.0011191540397703648\n",
      "  Initialization #5\n",
      "    Epoch 5000, current loss 0.168, current formula \\left(-0.488x_1^{0.047} + 1.332x_2^{1.668}-2.287x_3^{0.731} + 18.646x_4^{-0.021}-18.460\\right)\n",
      "    Epoch 10000, current loss 0.165, current formula \\left(-0.521x_1^{0.045} + 1.332x_2^{1.666}-2.287x_3^{0.731} + 30.321x_4^{-0.014}-30.114\\right)\n",
      "  Finished run #5, loss 0.164914071559906, best loss 0.0011191540397703648\n",
      "  Initialization #6\n",
      "    Epoch 5000, current loss 0.178, current formula \\left(-3.719x_1^{0.005} + 1.329x_2^{1.699}-2.316x_3^{0.706} + 7.729x_4^{-0.046}-4.231\\right)\n",
      "    Epoch 10000, current loss 0.172, current formula \\left(-6.899x_1^{0.003} + 1.331x_2^{1.676}-2.292x_3^{0.726} + 11.487x_4^{-0.033}-4.863\\right)\n",
      "  Finished run #6, loss 0.17245455086231232, best loss 0.0011191540397703648\n",
      "  Initialization #7\n",
      "    Epoch 5000, current loss 0.221, current formula \\left(-0.335x_1^{0.161}-18.382x_2^{-0.018}-2.383x_3^{0.703} + 19.902x_4^{-0.020}-0.604\\right)\n",
      "    Epoch 10000, current loss 0.218, current formula \\left(-0.373x_1^{0.141}-24.744x_2^{-0.013}-2.383x_3^{0.704} + 26.302x_4^{-0.015}-0.607\\right)\n",
      "  Finished run #7, loss 0.21840810775756836, best loss 0.0011191540397703648\n",
      "  Initialization #8\n",
      "    Epoch 5000, current loss 0.178, current formula \\left(-3.591x_1^{0.005} + 1.330x_2^{1.697}-2.315x_3^{0.707} + 7.812x_4^{-0.045}-4.445\\right)\n",
      "  Finished run #8, loss 0.1738404929637909, best loss 0.0011191540397703648\n",
      "  Initialization #9\n",
      "    Epoch 5000, current loss 0.0724, current formula \\left(-8.389x_1^{0.001} + 1.331x_2^{1.632} + 11.748x_3^{-0.045}-1.975x_4^{1.966}-4.453\\right)\n",
      "    Epoch 10000, current loss 0.0707, current formula \\left(-10.230x_1^{0.001} + 1.332x_2^{1.628} + 13.701x_3^{-0.040}-1.975x_4^{1.967}-4.573\\right)\n",
      "  Finished run #9, loss 0.07067271322011948, best loss 0.0011191540397703648\n",
      "  Initialization #10\n",
      "    Epoch 5000, current loss 0.0776, current formula \\left(-4.134x_1^{0.001} + 1.327x_2^{1.663} + 8.133x_3^{-0.062}-1.974x_4^{1.955}-5.063\\right)\n",
      "    Epoch 10000, current loss 0.0709, current formula \\left(-9.018x_1^{0.001} + 1.331x_2^{1.628} + 13.352x_3^{-0.041}-1.975x_4^{1.967}-5.434\\right)\n",
      "  Finished run #10, loss 0.07094106823205948, best loss 0.0011191540397703648\n",
      "10 minutes 8 seconds passed from the start, the iteration took 6 minutes 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.163x_{1}^{4.0}+1.352x_{2}^{1.5}-2.43x_{3}^{0.667}-1.985x_{4}^{1.833}+0.952$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.169x_1^{0.023} + 1.350x_2^{1.496}-2.425x_3^{0.667}-1.980x_4^{1.832} + 2.058\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.0063896865672595\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.207, current formula \\left(-0.154x_1^{0.389}-7.613x_2^{-0.043}-0.251x_3^{1.166}-2.744x_4^{-0.048} + 10.734\\right)\n",
      "  Finished run #1, loss 0.2074088603258133, best loss 0.2074088603258133\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0717, current formula \\left(-0.093x_1^{7.623} + 1.774x_2^{2.433} + 7.794x_3^{-0.010}-9.239x_4^{-0.019} + 0.696\\right)\n",
      "  Finished run #2, loss 0.07172449678182602, best loss 0.07172449678182602\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 2.259490247524809e-05, best loss 2.259490247524809e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 3.4714398022828163e-11, best loss 3.4714398022828163e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "11 minutes 8 seconds passed from the start, the iteration took 1 minutes 0 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.029x_{1}^{1.333}+1.801x_{2}^{2.417}-0.361x_{3}^{2.083}+1.207x_{4}^{3.417}-1.003$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.029x_1^{1.332} + 1.801x_2^{2.417}-0.361x_3^{2.083} + 1.207x_4^{3.417}-1.003\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.8310162592125474e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.146, current formula \\left(1.570x_1^{2.314}-5.034x_2^{-0.051}-0.235x_3^{3.021} + 0.117x_4^{6.323} + 5.976\\right)\n",
      "  Finished run #1, loss 0.14529700577259064, best loss 0.14529700577259064\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0028159967623651028, best loss 0.0028159967623651028\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.00048364687245339155, best loss 0.00048364687245339155\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.003353861393406987, best loss 0.00048364687245339155\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 6.656671307919693e-12, best loss 6.656671307919693e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "12 minutes 2 seconds passed from the start, the iteration took 54 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.585x_{1}^{2.083}+1.683x_{2}^{3.0}-0.242x_{3}^{2.667}+0.109x_{4}^{1.917}+0.174$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.585x_1^{2.083} + 1.683x_2^{3.000}-0.242x_3^{2.667} + 0.109x_4^{1.917} + 0.174\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.067346564489643e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0636, current formula \\left(-1.213x_1^{0.641} + 0.128x_2^{1.892}-9.821x_3^{-0.020} + 8.572x_4^{-0.034}-0.525\\right)\n",
      "    Epoch 10000, current loss 0.062, current formula \\left(-1.212x_1^{0.641} + 0.129x_2^{1.852}-17.596x_3^{-0.012} + 16.359x_4^{-0.018}-0.544\\right)\n",
      "  Finished run #1, loss 0.06200076639652252, best loss 0.06200076639652252\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0556, current formula \\left(3.211x_1^{-0.071} + 0.134x_2^{2.998} + 0.898x_3^{2.649} + 3.351x_4^{-0.079}-9.748\\right)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5fd5fc00a897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexplore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_power\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivide_powers_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/zybinmikhail/Documents/personal github projects/LearningFormulas/explore.py\u001b[0m in \u001b[0;36mexplore\u001b[0;34m(n_variables, m_samples, min_power, max_power, number_of_tested_formulas, recovery_threshold, divide_powers_by)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mcoeffs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpowers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_power\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivide_powers_by\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mcnt_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mregressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNestedFormula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearnFormula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_for_formula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mprint_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ground truth and obtained formula\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zybinmikhail/Documents/personal github projects/LearningFormulas/NestedFormula.py\u001b[0m in \u001b[0;36mLearnFormula\u001b[0;34m(X, y, optimizer_for_formula, device, n_init, max_iter, lr, depth, verbose, verbose_frequency, max_epochs_without_improvement, minimal_acceptable_improvement, max_tol, use_swa)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mminimal_acceptable_improvement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0mepochs_without_improvement\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "explore.explore(n_variables=4, max_power=48, divide_powers_by=12, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.887219283098652e-11, best loss 2.887219283098652e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.012x_{1}^{2.0}-0.097x_{2}^{2.0}-1.218$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.012x_1^{2.013}-0.097x_2^{2.000}-1.218\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.456918690541867e-05\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.068, current formula \\left(2.937x_1^{-0.097} + 1.551x_2^{0.056}-5.977\\right)\n",
      "  Finished run #1, loss 0.06783705204725266, best loss 0.06783705204725266\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0007987562566995621, best loss 0.0007987562566995621\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0008980157435871661, best loss 0.0007987562566995621\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0009091713582165539, best loss 0.0007987562566995621\n",
      "13 seconds passed from the start, the iteration took 11 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.332x_{1}^{4.0}-0.116x_{2}^{3.0}-0.918$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.369x_1^{4.068}-0.828x_2^{0.044}-0.167\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.9623455228632138\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0144, current formula \\left(2.073x_1^{-0.054} + 1.509x_2^{2.047}-2.839\\right)\n",
      "    Epoch 10000, current loss 0.0144, current formula \\left(2.529x_1^{-0.045} + 1.508x_2^{2.049}-3.296\\right)\n",
      "  Finished run #1, loss 0.01440005749464035, best loss 0.01440005749464035\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.014640597626566887, best loss 0.01440005749464035\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0412, current formula \\left(1.544x_1^{-0.058}-3.301x_2^{-0.153} + 2.077\\right)\n",
      "  Finished run #3, loss 0.04110497608780861, best loss 0.01440005749464035\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.014667109586298466, best loss 0.01440005749464035\n",
      "34 seconds passed from the start, the iteration took 21 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.798x_{1}^{5.0}+1.386x_{2}^{3.0}-0.383$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.529x_1^{-0.045} + 1.508x_2^{2.049}-3.296\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.184924438027826\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0008529613260179758, best loss 0.0008529613260179758\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0007705435273237526, best loss 0.0007705435273237526\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0008288666140288115, best loss 0.0007705435273237526\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.010564148426055908, best loss 0.0007705435273237526\n",
      "39 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.646x_{1}^{5.0}+0.129x_{2}^{2.0}-1.402$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.572x_1^{4.461} + 1.010x_2^{0.035}-2.332\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1594597115845384\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0404, current formula \\left(3.663x_1^{-0.129}-3.757x_2^{-0.048} + 0.329\\right)\n",
      "    Epoch 10000, current loss 0.0394, current formula \\left(5.941x_1^{-0.083}-5.999x_2^{-0.031} + 0.286\\right)\n",
      "  Finished run #1, loss 0.039384353905916214, best loss 0.039384353905916214\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0396, current formula \\left(5.343x_1^{-0.092}-5.077x_2^{-0.036}-0.037\\right)\n",
      "  Finished run #2, loss 0.03931284323334694, best loss 0.03931284323334694\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0014484928688034415, best loss 0.0014484928688034415\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.025301998481154442, best loss 0.0014484928688034415\n",
      "1 minutes 5 seconds passed from the start, the iteration took 26 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.666x_{1}^{5.0}+0.404x_{2}^{1.0}+0.542$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.789x_1^{5.039}-1.672x_2^{-0.077} + 2.598\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.9424249272710525\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[3.456918690541867e-05, 1.9623455228632138, 9.184924438027826, 1.1594597115845384, 1.9424249272710525]\n",
      "For 0 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.007208777125924826, best loss 0.007208777125924826\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.007206058129668236, best loss 0.007206058129668236\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.00020570644119288772, best loss 0.00020570644119288772\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.2077898620409542e-08, best loss 2.2077898620409542e-08\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "6 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.405x_{1}^{4.0}-0.572x_{2}^{1.0}-2.323$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.406x_1^{4.021}-0.570x_2^{1.010}-2.326\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.00010480470324711889\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.021, current formula \\left(-1.457x_1^{-0.049} + 2.420x_2^{-0.038}-3.101\\right)\n",
      "  Finished run #1, loss 0.02103329449892044, best loss 0.02103329449892044\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.107469797632544e-12, best loss 2.107469797632544e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "13 seconds passed from the start, the iteration took 8 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.017x_{1}^{1.5}-0.773x_{2}^{5.5}-1.999$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.017x_1^{1.501}-0.773x_2^{5.500}-1.999\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8320665487181475e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0006829872145317495, best loss 0.0006829872145317495\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.980172497668576e-10, best loss 2.980172497668576e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "18 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.489x_{1}^{0.5}-0.384x_{2}^{1.0}+1.223$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.490x_1^{0.499}-0.384x_2^{1.000} + 1.223\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.731054362774102e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0005435767816379666, best loss 0.0005435767816379666\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0504, current formula \\left(2.885x_1^{0.153} + 3.195x_2^{-0.069}-6.118\\right)\n",
      "    Epoch 10000, current loss 0.0494, current formula \\left(3.430x_1^{0.125} + 4.133x_2^{-0.055}-7.606\\right)\n",
      "  Finished run #2, loss 0.04937557503581047, best loss 0.0005435767816379666\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 4.222045022622689e-12, best loss 4.222045022622689e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "31 seconds passed from the start, the iteration took 13 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.159x_{1}^{3.5}-1.402x_{2}^{2.5}+0.38$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.159x_1^{3.500}-1.402x_2^{2.500} + 0.380\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.019511627400107e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.005927386227995157, best loss 0.005927386227995157\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.000886291905771941, best loss 0.000886291905771941\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.00577, current formula \\left(1.762x_1^{0.113} + 1.212x_2^{-0.057}-3.134\\right)\n",
      "  Finished run #3, loss 0.005758550949394703, best loss 0.000886291905771941\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.005836052354425192, best loss 0.000886291905771941\n",
      "46 seconds passed from the start, the iteration took 16 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.396x_{1}^{2.0}-1.785x_{2}^{5.0}-0.288$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.981x_1^{-0.128}-1.297x_2^{4.524} + 0.937\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.6772145127371139\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[0.00010480470324711889, 1.8320665487181475e-07, 6.731054362774102e-08, 3.019511627400107e-08, 1.6772145127371139]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.008476484566926956, best loss 0.008476484566926956\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00843, current formula \\left(1.636x_1^{-0.129} + 0.677x_2^{-0.019}-2.303\\right)\n",
      "    Epoch 10000, current loss 0.00826, current formula \\left(2.471x_1^{-0.090} + 0.654x_2^{-0.019}-3.121\\right)\n",
      "  Finished run #2, loss 0.008258654735982418, best loss 0.008258654735982418\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.002317447680979967, best loss 0.002317447680979967\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.002309931442141533, best loss 0.002309931442141533\n",
      "18 seconds passed from the start, the iteration took 18 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.013x_{1}^{4.333}-0.157x_{2}^{5.25}+0.385$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.765x_1^{2.650} + 0.229x_2^{-0.042} + 0.134\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.222396092366884\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.4360069517115335e-11, best loss 2.4360069517115335e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "19 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.791x_{1}^{1.667}+1.048x_{2}^{1.417}-0.643$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.791x_1^{1.667} + 1.048x_2^{1.417}-0.643\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.4600304843479534e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0105, current formula \\left(3.057x_1^{-0.050}-0.895x_2^{0.044}-2.928\\right)\n",
      "  Finished run #1, loss 0.010448373854160309, best loss 0.010448373854160309\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.3519674095519019e-11, best loss 1.3519674095519019e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "29 seconds passed from the start, the iteration took 10 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.67x_{1}^{2.417}-0.106x_{2}^{0.917}-0.346$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.670x_1^{2.417}-0.106x_2^{0.917}-0.346\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.5968636169503296e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.003074372885748744, best loss 0.003074372885748744\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.172, current formula \\left(-2.511x_1^{-0.139} + 0.000x_2^{-2.340} + 4.189\\right)\n",
      "    Epoch 10000, current loss 0.171, current formula \\left(-2.629x_1^{-0.134} + 0.000x_2^{-2.341} + 4.308\\right)\n",
      "  Finished run #2, loss 0.17118705809116364, best loss 0.003074372885748744\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0028801264706999063, best loss 0.0028801264706999063\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0030464325100183487, best loss 0.0028801264706999063\n",
      "44 seconds passed from the start, the iteration took 15 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.028x_{1}^{4.917}+0.281x_{2}^{4.75}+0.91$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.050x_1^{4.619} + 0.638x_2^{0.057} + 0.337\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.513529966236298\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.0878120519919321e-05, best loss 1.0878120519919321e-05\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 8.95328339538537e-05, best loss 1.0878120519919321e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.816345729821478e-06, best loss 1.816345729821478e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "48 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.117x_{1}^{1.583}+1.627x_{2}^{0.25}+0.725$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.117x_1^{1.661} + 1.930x_2^{0.203} + 0.419\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.03869175864686789\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[6.222396092366884, 3.4600304843479534e-10, 3.5968636169503296e-08, 4.513529966236298, 0.03869175864686789]\n",
      "For 2 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00261, current formula \\left(0.554x_1^{0.172}-0.551x_2^{-0.293}-0.948x_3^{-0.460} + 1.758\\right)\n",
      "    Epoch 10000, current loss 0.00238, current formula \\left(0.279x_1^{0.613}-0.528x_2^{-0.331}-1.234x_3^{-0.371} + 2.328\\right)\n",
      "  Finished run #1, loss 0.002382873324677348, best loss 0.002382873324677348\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0005196615238673985, best loss 0.0005196615238673985\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0009897901909425855, best loss 0.0005196615238673985\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.000921, current formula \\left(0.381x_1^{5.455}-0.395x_2^{-0.519} + 1.605x_3^{0.595}-0.376\\right)\n",
      "  Finished run #4, loss 0.00047282525338232517, best loss 0.00047282525338232517\n",
      "29 seconds passed from the start, the iteration took 29 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.435x_{1}^{5.0}+0.57x_{2}^{1.0}+1.208x_{3}^{1.0}-0.837$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.448x_1^{6.492}-0.602x_2^{-0.417} + 1.176x_3^{1.211} + 0.369\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0155794972327603\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.121, current formula \\left(1.773x_1^{-0.277} + 0.000x_2^{-3.346} + 0.409x_3^{2.049}-4.013\\right)\n",
      "    Epoch 10000, current loss 0.121, current formula \\left(1.773x_1^{-0.277} + 0.000x_2^{-3.346} + 0.409x_3^{2.049}-4.013\\right)\n",
      "  Finished run #1, loss 0.1213066503405571, best loss 0.1213066503405571\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.118, current formula \\left(8.891x_1^{-0.068} + 0.486x_2^{4.682}-7.339x_3^{-0.043}-3.415\\right)\n",
      "    Epoch 10000, current loss 0.117, current formula \\left(12.787x_1^{-0.049} + 0.511x_2^{4.951}-11.146x_3^{-0.029}-3.512\\right)\n",
      "  Finished run #2, loss 0.11663822084665298, best loss 0.11663822084665298\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 6.351641332003055e-06, best loss 6.351641332003055e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "58 seconds passed from the start, the iteration took 30 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.87x_{1}^{3.0}-0.476x_{2}^{1.0}+0.611x_{3}^{3.0}-1.029$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.863x_1^{3.090}-0.490x_2^{1.267} + 0.627x_3^{2.846}-1.078\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.015090433409997368\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0019888575188815594, best loss 0.0019888575188815594\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.004838422406464815, best loss 0.0019888575188815594\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0007071061991155148, best loss 0.0007071061991155148\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0019490929553285241, best loss 0.0007071061991155148\n",
      "1 minutes 8 seconds passed from the start, the iteration took 10 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.056x_{1}^{6.0}+0.318x_{2}^{2.0}+0.473x_{3}^{1.0}+1.241$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.218x_1^{6.221} + 0.375x_2^{1.692} + 3.245x_3^{0.044}-1.662\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.457641261891628\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00531, current formula \\left(-0.860x_1^{4.253}-3.400x_2^{0.003} + 0.000x_3^{-3.310} + 2.667\\right)\n",
      "    Epoch 10000, current loss 0.00531, current formula \\left(-0.860x_1^{4.253}-3.400x_2^{0.003} + 0.000x_3^{-3.310} + 2.667\\right)\n",
      "  Finished run #1, loss 0.005307597573846579, best loss 0.005307597573846579\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00095, current formula \\left(-0.777x_1^{4.508}-3.250x_2^{0.003} + 1.070x_3^{-0.117} + 1.354\\right)\n",
      "  Finished run #2, loss 0.000946512445807457, best loss 0.000946512445807457\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.3706136314795003e-07, best loss 1.3706136314795003e-07\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 31 seconds passed from the start, the iteration took 23 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.669x_{1}^{3.0}+0.17x_{2}^{3.0}-0.379x_{3}^{1.0}-0.503$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.671x_1^{3.047} + 0.172x_2^{3.168}-0.382x_3^{0.967}-0.498\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.0045008196140782376\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.005374480504542589, best loss 0.005374480504542589\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.9246967908337353e-10, best loss 1.9246967908337353e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 38 seconds passed from the start, the iteration took 7 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.116x_{1}^{2.0}+0.541x_{2}^{4.0}-0.48x_{3}^{4.0}+0.679$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.116x_1^{2.000} + 0.541x_2^{3.998}-0.480x_3^{3.998} + 0.679\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1307813404367754e-06\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.0155794972327603, 0.015090433409997368, 2.457641261891628, 0.0045008196140782376, 1.1307813404367754e-06]\n",
      "For 1 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.013283509761095047, best loss 0.013283509761095047\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.014123504981398582, best loss 0.013283509761095047\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 5.455011887534056e-06, best loss 5.455011887534056e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "6 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.372x_{1}^{1.0}+0.777x_{2}^{4.0}+1.023x_{3}^{2.5}-0.462$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.351x_1^{1.069} + 0.783x_2^{4.239} + 1.032x_3^{2.657}-0.408\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.0129159778306064\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.8891554947063636e-12, best loss 2.8891554947063636e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "8 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.279x_{1}^{4.5}-0.384x_{2}^{5.0}-1.21x_{3}^{4.0}-0.478$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.279x_1^{4.500}-0.384x_2^{5.000}-1.210x_3^{4.000}-0.478\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.63382880718057e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00738, current formula \\left(0.939x_1^{-0.054} + 0.475x_2^{4.219} + 2.004x_3^{-0.063}-2.213\\right)\n",
      "    Epoch 10000, current loss 0.00732, current formula \\left(0.927x_1^{-0.055} + 0.475x_2^{4.156} + 3.511x_3^{-0.038}-3.727\\right)\n",
      "  Finished run #1, loss 0.007317731156945229, best loss 0.007317731156945229\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00807, current formula \\left(-225065.109x_1^{65.079}-2.503x_2^{-0.093} + 2.850x_3^{-0.096} + 0.624\\right)\n",
      "    Epoch 10000, current loss 0.00735, current formula \\left(-472642.000x_1^{68.880}-3.466x_2^{-0.069} + 3.815x_3^{-0.075} + 0.618\\right)\n",
      "  Finished run #2, loss 0.007350327912718058, best loss 0.007317731156945229\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0021229384001344442, best loss 0.0021229384001344442\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.022329410538077354, best loss 0.0021229384001344442\n",
      "38 seconds passed from the start, the iteration took 31 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.203x_{1}^{6.0}+0.229x_{2}^{3.0}-0.518x_{3}^{4.0}+1.133$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.177x_1^{-0.024} + 2.163x_2^{0.048}-0.587x_3^{4.314}-0.711\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.462607826868916\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0005790015566162765, best loss 0.0005790015566162765\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.537115895189345e-05, best loss 1.537115895189345e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.9303871001685735e-11, best loss 1.9303871001685735e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "45 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.05x_{1}^{1.5}-0.148x_{2}^{4.0}+1.873x_{3}^{6.0}-0.005$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.050x_1^{1.501}-0.148x_2^{3.999} + 1.873x_3^{6.000}-0.005\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.1945216035463228e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.006087713874876499, best loss 0.006087713874876499\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0346, current formula \\left(2.868x_1^{-0.059} + 3.257x_2^{-0.056}-3.180x_3^{-0.069}-3.479\\right)\n",
      "  Finished run #2, loss 0.03461228311061859, best loss 0.006087713874876499\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.00648, current formula \\left(1.556x_1^{-0.072}-0.926x_2^{5.357} + 1.016x_3^{1.251}-2.451\\right)\n",
      "    Epoch 10000, current loss 0.00644, current formula \\left(1.972x_1^{-0.058}-0.924x_2^{5.363} + 1.014x_3^{1.255}-2.867\\right)\n",
      "  Finished run #3, loss 0.006435648538172245, best loss 0.006087713874876499\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 6.583347061939193e-11, best loss 6.583347061939193e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 12 seconds passed from the start, the iteration took 27 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.627x_{1}^{6.0}-0.724x_{2}^{4.5}+0.701x_{3}^{4.0}-0.272$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.627x_1^{5.999}-0.724x_2^{4.500} + 0.701x_3^{4.000}-0.272\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0287564235410076e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[0.0129159778306064, 7.63382880718057e-10, 7.462607826868916, 2.1945216035463228e-07, 1.0287564235410076e-07]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00383, current formula \\left(1.435x_1^{-0.142} + 1.611x_2^{52.363}-1.130x_3^{0.718}-2.506\\right)\n",
      "  Finished run #1, loss 0.0027619453612715006, best loss 0.0027619453612715006\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00415, current formula \\left(1.949x_1^{-0.121}-0.773x_2^{-0.123}-0.818x_3^{1.858}-2.605\\right)\n",
      "  Finished run #2, loss 0.004151767585426569, best loss 0.0027619453612715006\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.00115, current formula \\left(-1.243x_1^{0.518}-0.000x_2^{-5.649}-0.588x_3^{1.013}-0.389\\right)\n",
      "    Epoch 10000, current loss 0.00115, current formula \\left(-1.243x_1^{0.518}-0.000x_2^{-5.649}-0.588x_3^{1.013}-0.389\\right)\n",
      "  Finished run #3, loss 0.0011502135312184691, best loss 0.0011502135312184691\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0001437368046026677, best loss 0.0001437368046026677\n",
      "32 seconds passed from the start, the iteration took 32 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.09x_{1}^{0.667}+0.242x_{2}^{1.0}-0.597x_{3}^{1.417}-0.773$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.127x_1^{0.653}-0.185x_2^{-0.468}-0.543x_3^{1.496}-0.383\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.3569901422041547\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0025434449780732393, best loss 0.0025434449780732393\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0023691693786531687, best loss 0.0023691693786531687\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.8422226276015863e-05, best loss 1.8422226276015863e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0025452810805290937, best loss 1.8422226276015863e-05\n",
      "43 seconds passed from the start, the iteration took 11 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.309x_{1}^{3.667}+0.047x_{2}^{3.833}-0.231x_{3}^{0.5}+0.843$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.294x_1^{3.631} + 0.637x_2^{0.025}-0.241x_3^{0.540} + 0.221\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.177270725862806\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00769, current formula \\left(-2.386x_1^{-0.139} + 0.242x_2^{3.011} + 0.437x_3^{5.377} + 4.786\\right)\n",
      "  Finished run #1, loss 0.007406153716146946, best loss 0.007406153716146946\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0021185933146625757, best loss 0.0021185933146625757\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0097, current formula \\left(-2.957x_1^{-0.130} + 0.248x_2^{3.025} + 1.470x_3^{-0.015} + 3.960\\right)\n",
      "    Epoch 10000, current loss 0.00876, current formula \\left(-5.239x_1^{-0.080} + 0.252x_2^{3.119} + 1.557x_3^{-0.017} + 6.174\\right)\n",
      "  Finished run #3, loss 0.008764364756643772, best loss 0.0021185933146625757\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 3.0393201086553745e-05, best loss 3.0393201086553745e-05\n",
      "1 minutes 11 seconds passed from the start, the iteration took 28 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.495x_{1}^{0.833}+0.24x_{2}^{4.667}+0.064x_{3}^{4.75}+1.344$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.488x_1^{0.873} + 0.233x_2^{4.192}-0.439x_3^{-0.028} + 1.822\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.362132295908201\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0612, current formula \\left(5.403x_1^{-0.112} + 0.778x_2^{0.138} + 2.092x_3^{3.341}-6.665\\right)\n",
      "    Epoch 10000, current loss 0.0588, current formula \\left(9.309x_1^{-0.069} + 0.782x_2^{0.132} + 2.064x_3^{3.310}-10.593\\right)\n",
      "  Finished run #1, loss 0.0588022880256176, best loss 0.0588022880256176\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.109, current formula \\left(4.802x_1^{-0.103} + 1.943x_2^{0.114}-6.367x_3^{-0.028}-0.165\\right)\n",
      "    Epoch 10000, current loss 0.107, current formula \\left(6.631x_1^{-0.078} + 2.340x_2^{0.091}-8.582x_3^{-0.021}-0.190\\right)\n",
      "  Finished run #2, loss 0.10682830959558487, best loss 0.0588022880256176\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.004405236802995205, best loss 0.004405236802995205\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.008147154003381729, best loss 0.004405236802995205\n",
      "1 minutes 42 seconds passed from the start, the iteration took 32 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.622x_{1}^{2.083}+0.518x_{2}^{5.667}+1.038x_{3}^{2.833}+0.609$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.602x_1^{2.368}-0.248x_2^{-0.087} + 0.866x_3^{2.061} + 0.820\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.920711751740768\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.244116568472236e-05, best loss 7.244116568472236e-05\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.747332473518327e-05, best loss 2.747332473518327e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 3.3753549359971657e-06, best loss 3.3753549359971657e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 55 seconds passed from the start, the iteration took 12 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.112x_{1}^{1.333}-1.174x_{2}^{0.917}-1.299x_{3}^{0.667}+0.106$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.119x_1^{1.081}-1.137x_2^{0.985}-1.291x_3^{0.663} + 0.050\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.010419794462657428\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[0.3569901422041547, 2.177270725862806, 3.362132295908201, 4.920711751740768, 0.010419794462657428]\n",
      "For 0 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0004442825447767973, best loss 0.0004442825447767973\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.009990156628191471, best loss 0.0004442825447767973\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.011860509403049946, best loss 0.0004442825447767973\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0059436531737446785, best loss 0.0004442825447767973\n",
      "12 seconds passed from the start, the iteration took 12 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.339x_{1}^{1.0}+0.902x_{2}^{6.0}+1.187x_{3}^{5.0}+0.468x_{4}^{1.0}+0.352$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.171x_1^{0.951} + 1.096x_2^{7.153} + 1.165x_3^{4.941} + 1.673x_4^{0.160}-0.831\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.55101442610444\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0343, current formula \\left(0.477x_1^{0.345}-3.546x_2^{-0.205} + 0.000x_3^{-1.613} + 4.207x_4^{0.006}-0.673\\right)\n",
      "  Finished run #1, loss 0.033885203301906586, best loss 0.033885203301906586\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0012739007361233234, best loss 0.0012739007361233234\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0295, current formula \\left(0.789x_1^{0.780}-1.136x_2^{-0.571}-1.058x_3^{7.078}-0.000x_4^{-4.188} + 1.166\\right)\n",
      "    Epoch 10000, current loss 0.0295, current formula \\left(0.789x_1^{0.780}-1.136x_2^{-0.571}-1.058x_3^{7.078}-0.000x_4^{-4.188} + 1.166\\right)\n",
      "  Finished run #3, loss 0.029461095109581947, best loss 0.0012739007361233234\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0037, current formula \\left(396.331x_1^{102.774}-1.972x_2^{-0.588}-3.781x_3^{5.470}-1.568x_4^{0.574} + 3.907\\right)\n",
      "    Epoch 10000, current loss 0.00283, current formula \\left(828.754x_1^{115.752}-2.413x_2^{-0.512}-4.157x_3^{5.573}-2.031x_4^{0.398} + 4.850\\right)\n",
      "  Finished run #4, loss 0.0028347258921712637, best loss 0.0012739007361233234\n",
      "1 minutes 5 seconds passed from the start, the iteration took 54 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.349x_{1}^{3.0}+1.166x_{2}^{5.0}-0.393x_{3}^{4.0}+0.436x_{4}^{2.0}-0.523$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.588x_1^{-0.319} + 1.044x_2^{5.532}-0.299x_3^{6.218} + 0.734x_4^{0.368}-0.074\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.230143022680173\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00517, current formula \\left(0.000x_1^{-2.350} + 2.142x_2^{-0.031}-2.728x_3^{-0.102} + 0.961x_4^{-0.127}-0.803\\right)\n",
      "  Finished run #1, loss 0.005173008423298597, best loss 0.005173008423298597\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0059042321518063545, best loss 0.005173008423298597\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0003890024090651423, best loss 0.0003890024090651423\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.005046351812779903, best loss 0.0003890024090651423\n",
      "1 minutes 25 seconds passed from the start, the iteration took 19 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.223x_{1}^{6.0}-0.346x_{2}^{5.0}+0.592x_{3}^{3.0}-0.347x_{4}^{1.0}-0.308$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.587x_1^{-0.059}-0.080x_2^{2.043} + 0.643x_3^{3.497} + 0.909x_4^{-0.083}-2.135\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.77774875863532\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.005741639994084835, best loss 0.005741639994084835\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.010967180132865906, best loss 0.005741639994084835\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.01108760666102171, best loss 0.005741639994084835\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 5.421699461294338e-05, best loss 5.421699461294338e-05\n",
      "1 minutes 46 seconds passed from the start, the iteration took 21 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.369x_{1}^{6.0}-1.044x_{2}^{5.0}-0.35x_{3}^{2.0}+0.297x_{4}^{6.0}+0.92$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-35.901x_1^{10.126}-0.791x_2^{3.913}-0.578x_3^{0.451}-1.025x_4^{-0.036} + 2.353\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 152.93903178620164\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0216, current formula \\left(1.569x_1^{6.839}-0.001x_2^{-3.061} + 3.963x_3^{-0.172} + 0.002x_4^{-1.645}-5.357\\right)\n",
      "    Epoch 10000, current loss 0.0214, current formula \\left(1.569x_1^{6.807}-0.001x_2^{-3.063} + 3.987x_3^{-0.172} + 0.002x_4^{-1.646}-5.383\\right)\n",
      "  Finished run #1, loss 0.021447118371725082, best loss 0.021447118371725082\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0324665866792202, best loss 0.021447118371725082\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.00036762605304829776, best loss 0.00036762605304829776\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0003082694311160594, best loss 0.0003082694311160594\n",
      "2 minutes 16 seconds passed from the start, the iteration took 31 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.189x_{1}^{5.0}-0.845x_{2}^{5.0}-2.013x_{3}^{1.0}-0.419x_{4}^{3.0}+0.346$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.005x_1^{4.137}-0.737x_2^{0.136}-1.906x_3^{1.094}-0.534x_4^{8.594} + 0.835\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.224754878573522\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[0.55101442610444, 2.230143022680173, 5.77774875863532, 152.93903178620164, 6.224754878573522]\n",
      "For 0 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.003351423656567931, best loss 0.003351423656567931\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0005441167159006, best loss 0.0005441167159006\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.000571357668377459, best loss 0.0005441167159006\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.086, current formula \\left(-3.988x_1^{-0.100}-0.001x_2^{-2.164} + 2.577x_3^{-0.025}-1.815x_4^{0.460} + 3.217\\right)\n",
      "  Finished run #4, loss 0.0859956219792366, best loss 0.0005441167159006\n",
      "21 seconds passed from the start, the iteration took 21 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.511x_{1}^{3.0}-0.54x_{2}^{2.0}+0.778x_{3}^{3.5}-0.786x_{4}^{1.5}+0.128$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(3.023x_1^{3.376} + 0.001x_2^{-2.675} + 1.201x_3^{1.664} + 0.864x_4^{-0.133}-1.820\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.920369148372779\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.006672222167253494, best loss 0.006672222167253494\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.006639563944190741, best loss 0.006639563944190741\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0005779371713288128, best loss 0.0005779371713288128\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0255, current formula \\left(1.546x_1^{-0.178}-0.967x_2^{3.543} + 0.000x_3^{-2.221}-2.953x_4^{0.297}-1.125\\right)\n",
      "    Epoch 10000, current loss 0.0253, current formula \\left(1.579x_1^{-0.175}-0.967x_2^{3.555} + 0.000x_3^{-2.221}-2.953x_4^{0.298}-1.162\\right)\n",
      "  Finished run #4, loss 0.025330467149615288, best loss 0.0005779371713288128\n",
      "52 seconds passed from the start, the iteration took 31 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -2.167x_{1}^{0.5}+1.073x_{2}^{4.5}-1.248x_{3}^{0.5}-0.466x_{4}^{3.5}+0.426$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.281x_1^{0.649} + 0.759x_2^{1.688}-1.614x_3^{0.355} + 0.481x_4^{-0.288}-0.151\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.6420073809852136\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0021986979991197586, best loss 0.0021986979991197586\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00489, current formula \\left(-2.820x_1^{0.060} + 0.960x_2^{-0.145} + 2.607x_3^{0.203}-0.942x_4^{-0.034} + 0.015\\right)\n",
      "  Finished run #2, loss 0.004697716329246759, best loss 0.0021986979991197586\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.610352410352789e-05, best loss 1.610352410352789e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0025127092376351357, best loss 1.610352410352789e-05\n",
      "1 minutes 18 seconds passed from the start, the iteration took 26 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.828x_{1}^{0.5}-0.722x_{2}^{3.5}+0.768x_{3}^{1.0}+0.226x_{4}^{5.5}-0.089$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.927x_1^{0.522}-0.823x_2^{3.604} + 0.707x_3^{1.491} + 0.213x_4^{2.970} + 0.063\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.7447374194273277\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.6162427831150126e-06, best loss 7.6162427831150126e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 20 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.878x_{1}^{6.0}-1.167x_{2}^{2.0}+0.748x_{3}^{5.0}-0.078x_{4}^{1.5}-0.896$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.983x_1^{6.507}-1.204x_2^{2.024} + 0.828x_3^{5.156}-1.816x_4^{0.010} + 0.866\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.9612086411259332\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0698, current formula \\left(-0.985x_1^{1.229} + 3.599x_2^{0.010}-4.256x_3^{-0.118}-0.590x_4^{0.387} + 0.731\\right)\n",
      "    Epoch 10000, current loss 0.0682, current formula \\left(-0.978x_1^{1.239} + 5.690x_2^{0.007}-6.197x_3^{-0.085}-0.784x_4^{0.286} + 0.779\\right)\n",
      "  Finished run #1, loss 0.06824573874473572, best loss 0.06824573874473572\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0689, current formula \\left(-0.987x_1^{1.210} + 4.657x_2^{0.008}-5.125x_3^{-0.100}-0.687x_4^{0.330} + 0.646\\right)\n",
      "    Epoch 10000, current loss 0.0677, current formula \\left(-0.973x_1^{1.253} + 6.910x_2^{0.005}-7.278x_3^{-0.073}-0.881x_4^{0.251} + 0.736\\right)\n",
      "  Finished run #2, loss 0.06772936135530472, best loss 0.06772936135530472\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.00012066130148014054, best loss 0.00012066130148014054\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0001225331798195839, best loss 0.00012066130148014054\n",
      "1 minutes 58 seconds passed from the start, the iteration took 38 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.695x_{1}^{3.0}+0.103x_{2}^{5.5}+1.628x_{3}^{4.5}-0.057x_{4}^{2.5}-1.22$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.729x_1^{3.339}-0.814x_2^{-0.049} + 1.627x_3^{4.361}-0.073x_4^{0.197}-0.343\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.204486788298485\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[3.920369148372779, 2.6420073809852136, 0.7447374194273277, 0.9612086411259332, 4.204486788298485]\n",
      "For 0 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0644, current formula \\left(1.408x_1^{1.176}-2.070x_2^{-0.146}-2.194x_3^{-0.161} + 1.296x_4^{2.167} + 7.063\\right)\n",
      "    Epoch 10000, current loss 0.0623, current formula \\left(1.392x_1^{1.221}-2.938x_2^{-0.110}-3.005x_3^{-0.125} + 1.294x_4^{2.203} + 8.787\\right)\n",
      "  Finished run #1, loss 0.062260232865810394, best loss 0.062260232865810394\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.5791101065643076e-11, best loss 1.5791101065643076e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "23 seconds passed from the start, the iteration took 23 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.41x_{1}^{1.5}+0.932x_{2}^{2.0}+1.108x_{3}^{3.5}+1.095x_{4}^{5.25}+1.592$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.410x_1^{1.500} + 0.932x_2^{2.000} + 1.108x_3^{3.500} + 1.095x_4^{5.250} + 1.592\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.590685413561005e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.000614702410530299, best loss 0.000614702410530299\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.073, current formula \\left(6.172x_1^{-0.128}-3.093x_2^{-0.002} + 0.544x_3^{-0.184}-3.010x_4^{-0.017}-2.220\\right)\n",
      "    Epoch 10000, current loss 0.0701, current formula \\left(8.653x_1^{-0.096}-3.151x_2^{-0.005} + 0.857x_3^{-0.138}-5.698x_4^{-0.011}-2.278\\right)\n",
      "  Finished run #2, loss 0.07014907896518707, best loss 0.000614702410530299\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 4.823625090466521e-07, best loss 4.823625090466521e-07\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "46 seconds passed from the start, the iteration took 23 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -2.467x_{1}^{0.917}+0.452x_{2}^{4.167}-0.356x_{3}^{4.833}+1.146x_{4}^{4.333}+0.508$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.466x_1^{0.925} + 0.454x_2^{4.155}-0.351x_3^{4.771} + 1.085x_4^{4.184} + 0.500\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.003370876972025193\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0523, current formula \\left(-3.389x_1^{-0.059}-1.014x_2^{0.368}-2.812x_3^{1.417} + 2.804x_4^{-0.037} + 2.472\\right)\n",
      "  Finished run #1, loss 0.05209673196077347, best loss 0.05209673196077347\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 3.097635999438353e-05, best loss 3.097635999438353e-05\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0634, current formula \\left(-4.910x_1^{-0.029} + 227269.625x_2^{106.599}-2.243x_3^{1.127} + 6.301x_4^{-0.013}-0.464\\right)\n",
      "    Epoch 10000, current loss 0.0629, current formula \\left(-6.402x_1^{-0.023} + 469958.375x_2^{112.424}-2.243x_3^{1.137} + 7.731x_4^{-0.011}-0.402\\right)\n",
      "  Finished run #3, loss 0.06287824362516403, best loss 3.097635999438353e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.2042571799829602e-05, best loss 2.2042571799829602e-05\n",
      "1 minutes 17 seconds passed from the start, the iteration took 31 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.073x_{1}^{2.0}-0.515x_{2}^{4.75}-2.534x_{3}^{1.25}-0.117x_{4}^{3.333}+0.693$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.114x_1^{2.067}-0.551x_2^{4.687}-2.540x_3^{1.267}-0.165x_4^{0.478} + 0.780\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.9081287910013186\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.022, current formula \\left(-2.177x_1^{0.053} + 4.420x_2^{0.104} + 1.593x_3^{1.511}-2.634x_4^{-0.073} + 1.811\\right)\n",
      "  Finished run #1, loss 0.02161226235330105, best loss 0.02161226235330105\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0478, current formula \\left(0.001x_1^{-1.264} + 5.428x_2^{0.063}-3.260x_3^{-0.135}-2.528x_4^{-0.121} + 2.952\\right)\n",
      "  Finished run #2, loss 0.04647119343280792, best loss 0.02161226235330105\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0324, current formula \\left(-63.577x_1^{40.869} + 3.280x_2^{0.096}-2.907x_3^{-0.123} + 1.600x_4^{1.564} + 1.076\\right)\n",
      "    Epoch 10000, current loss 0.0318, current formula \\left(-104.807x_1^{43.605} + 4.505x_2^{0.068}-4.133x_3^{-0.091} + 1.589x_4^{1.546} + 1.087\\right)\n",
      "  Finished run #3, loss 0.031847745180130005, best loss 0.02161226235330105\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0321, current formula \\left(0.108x_1^{2.981} + 3.403x_2^{0.088}-3.611x_3^{-0.096} + 1.600x_4^{1.559} + 1.605\\right)\n",
      "    Epoch 10000, current loss 0.0316, current formula \\left(0.101x_1^{2.978} + 4.935x_2^{0.059}-5.146x_3^{-0.071} + 1.592x_4^{1.540} + 1.615\\right)\n",
      "  Finished run #4, loss 0.031628210097551346, best loss 0.02161226235330105\n",
      "2 minutes 20 seconds passed from the start, the iteration took 1 minutes 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.902x_{1}^{3.417}+1.493x_{2}^{1.667}+1.198x_{3}^{4.167}+1.365x_{4}^{4.333}+0.669$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.415x_1^{0.047} + 5.069x_2^{0.088} + 1.592x_3^{1.505}-3.047x_4^{-0.064} + 1.811\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 8.474135609398434\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.003072223160415888, best loss 0.003072223160415888\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0162309929728508, best loss 0.003072223160415888\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0439, current formula \\left(1.386x_1^{-0.074} + 3.454x_2^{-0.060}-4.418x_3^{-0.056} + 1.450x_4^{-0.030}-2.612\\right)\n",
      "  Finished run #3, loss 0.04370756447315216, best loss 0.003072223160415888\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0001203129140776582, best loss 0.0001203129140776582\n",
      "2 minutes 45 seconds passed from the start, the iteration took 25 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.922x_{1}^{5.167}-0.384x_{2}^{4.917}+0.959x_{3}^{3.167}-0.45x_{4}^{5.25}-0.549$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.784x_1^{5.512}-0.374x_2^{1.961} + 1.067x_3^{3.508}-0.420x_4^{0.131}-0.178\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.9267710435570677\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[7.590685413561005e-09, 0.003370876972025193, 0.9081287910013186, 8.474135609398434, 3.9267710435570677]\n",
      "For 1 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 5.733186278153446e-13, best loss 5.733186278153446e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.22x_{1}^{4.0}+0.141x_{2}^{4.0}+0.108$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.220x_1^{4.000} + 0.141x_2^{4.000} + 0.108\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.6652926704274762e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.663378636218571e-12, best loss 1.663378636218571e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.564x_{1}^{5.0}+1.355x_{2}^{3.0}+0.07$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.564x_1^{5.000} + 1.355x_2^{3.000} + 0.070\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.170860935457597e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.660502890384665e-12, best loss 3.660502890384665e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "5 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.876x_{1}^{6.0}-1.206x_{2}^{3.0}+1.151$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.876x_1^{6.000}-1.206x_2^{3.000} + 1.151\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.596714285933558e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 8.355038666127412e-13, best loss 8.355038666127412e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "6 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.175x_{1}^{6.0}-1.104x_{2}^{1.0}-0.093$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.175x_1^{6.000}-1.104x_2^{1.000}-0.093\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.6829597149790063e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.6829313904140903e-11, best loss 3.6829313904140903e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "8 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.234x_{1}^{1.0}-0.443x_{2}^{1.0}-0.767$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.234x_1^{1.000}-0.443x_2^{1.000}-0.767\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 8.968959841482161e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.6652926704274762e-09, 2.170860935457597e-10, 6.596714285933558e-10, 3.6829597149790063e-10, 8.968959841482161e-09]\n",
      "For 5 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.132804614001337e-11, best loss 1.132804614001337e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.351x_{1}^{1.5}+1.011x_{2}^{2.0}-0.154$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.351x_1^{1.500} + 1.011x_2^{2.000}-0.154\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.605309707386482e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.193, current formula \\left(-4.675x_1^{-0.036}-2.251x_2^{-0.071} + 6.016\\right)\n",
      "  Finished run #1, loss 0.19193489849567413, best loss 0.19193489849567413\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.17, current formula \\left(-6.058x_1^{-0.031} + 0.792x_2^{1.455} + 4.657\\right)\n",
      "    Epoch 10000, current loss 0.168, current formula \\left(-9.713x_1^{-0.021} + 0.794x_2^{1.471} + 8.325\\right)\n",
      "  Finished run #2, loss 0.1678815335035324, best loss 0.1678815335035324\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0086, current formula \\left(2.014x_1^{3.595}-2.767x_2^{-0.049} + 1.261\\right)\n",
      "    Epoch 10000, current loss 0.00829, current formula \\left(2.013x_1^{3.593}-4.029x_2^{-0.035} + 2.527\\right)\n",
      "  Finished run #3, loss 0.008286943659186363, best loss 0.008286943659186363\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.17, current formula \\left(-6.345x_1^{-0.030} + 0.792x_2^{1.456} + 4.947\\right)\n",
      "    Epoch 10000, current loss 0.168, current formula \\left(-9.583x_1^{-0.021} + 0.794x_2^{1.471} + 8.195\\right)\n",
      "  Finished run #4, loss 0.16792407631874084, best loss 0.008286943659186363\n",
      "55 seconds passed from the start, the iteration took 53 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.984x_{1}^{3.5}+0.604x_{2}^{1.0}-1.964$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.013x_1^{3.593}-4.029x_2^{-0.035} + 2.527\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 8.542507746717586\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.144, current formula \\left(6.246x_1^{-0.048}-1.716x_2^{1.008}-6.969\\right)\n",
      "  Finished run #1, loss 0.14184655249118805, best loss 0.14184655249118805\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 7.593700841745932e-12, best loss 7.593700841745932e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 8 seconds passed from the start, the iteration took 13 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.86x_{1}^{1.5}-1.694x_{2}^{1.5}+0.204$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.860x_1^{1.500}-1.694x_2^{1.500} + 0.204\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 8.017662089798705e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 4.871509012155384e-12, best loss 4.871509012155384e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 10 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.35x_{1}^{1.5}+1.036x_{2}^{4.0}-0.056$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.350x_1^{1.500} + 1.036x_2^{4.000}-0.056\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.378059329101518e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 9.531930800221744e-12, best loss 9.531930800221744e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 12 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.179x_{1}^{1.0}-1.041x_{2}^{3.5}-0.676$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.179x_1^{1.000}-1.041x_2^{3.500}-0.676\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.6862603958762746e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.605309707386482e-09, 8.542507746717586, 8.017662089798705e-11, 9.378059329101518e-10, 5.6862603958762746e-09]\n",
      "For 4 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.009506824426352978, best loss 0.009506824426352978\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.037920787930488586, best loss 0.009506824426352978\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 7.502043691126614e-13, best loss 7.502043691126614e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "6 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.519x_{1}^{5.833}+0.913x_{2}^{3.0}+0.319$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.519x_1^{5.833} + 0.913x_2^{3.000} + 0.319\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.489756122438848e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0016202437691390514, best loss 0.0016202437691390514\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0016553743043914437, best loss 0.0016202437691390514\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.10972290486097336, best loss 0.0016202437691390514\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0016005930956453085, best loss 0.0016005930956453085\n",
      "17 seconds passed from the start, the iteration took 11 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.331x_{1}^{1.917}-0.199x_{2}^{5.917}-0.348$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.320x_1^{1.876}-1.130x_2^{0.026} + 0.718\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.341474568732821\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00506, current formula \\left(0.719x_1^{0.139}-0.381x_2^{3.961} + 0.447\\right)\n",
      "  Finished run #1, loss 4.124345179615241e-13, best loss 4.124345179615241e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "26 seconds passed from the start, the iteration took 9 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.412x_{1}^{4.917}-0.421x_{2}^{5.333}+1.006$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.412x_1^{4.917}-0.421x_2^{5.333} + 1.006\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.408475610759524e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0766, current formula \\left(-1.244x_1^{1.956} + 4.200x_2^{-0.035}-3.746\\right)\n",
      "    Epoch 10000, current loss 0.0759, current formula \\left(-1.245x_1^{1.955} + 6.281x_2^{-0.024}-5.830\\right)\n",
      "  Finished run #1, loss 0.07593465596437454, best loss 0.07593465596437454\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.119, current formula \\left(3.300x_1^{-0.092} + 2.671x_2^{-0.047}-6.226\\right)\n",
      "  Finished run #2, loss 0.11813763529062271, best loss 0.07593465596437454\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 8.653851073237018e-12, best loss 8.653851073237018e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "54 seconds passed from the start, the iteration took 28 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.259x_{1}^{1.25}-1.381x_{2}^{4.833}+0.993$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.259x_1^{1.250}-1.381x_2^{4.833} + 0.993\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.232308973925683e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.018785903230309486, best loss 0.018785903230309486\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0377, current formula \\left(-0.756x_1^{2.619}-5.517x_2^{-0.037} + 7.475\\right)\n",
      "    Epoch 10000, current loss 0.0361, current formula \\left(-0.753x_1^{2.598}-9.088x_2^{-0.024} + 11.056\\right)\n",
      "  Finished run #2, loss 0.036061011254787445, best loss 0.018785903230309486\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0375, current formula \\left(-0.756x_1^{2.618}-5.728x_2^{-0.036} + 7.687\\right)\n",
      "    Epoch 10000, current loss 0.0363, current formula \\left(-0.753x_1^{2.600}-8.312x_2^{-0.026} + 10.279\\right)\n",
      "  Finished run #3, loss 0.03630346432328224, best loss 0.018785903230309486\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 1.6407497105755398e-12, best loss 1.6407497105755398e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 25 seconds passed from the start, the iteration took 31 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.725x_{1}^{2.583}+1.119x_{2}^{0.917}+1.136$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.725x_1^{2.583} + 1.119x_2^{0.917} + 1.136\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.803713065688498e-12\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[4.489756122438848e-10, 7.341474568732821, 7.408475610759524e-10, 7.232308973925683e-10, 5.803713065688498e-12]\n",
      "For 4 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.03818466514348984, best loss 0.03818466514348984\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0379909947514534, best loss 0.0379909947514534\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.121, current formula \\left(-4.496x_1^{-0.047} + 5.587x_2^{-0.026}-0.923x_3^{0.903}-0.521\\right)\n",
      "    Epoch 10000, current loss 0.119, current formula \\left(-5.923x_1^{-0.037} + 7.025x_2^{-0.021}-0.928x_3^{0.887}-0.518\\right)\n",
      "  Finished run #3, loss 0.1191522479057312, best loss 0.0379909947514534\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0646, current formula \\left(1.283x_1^{2.399} + 2.225x_2^{-0.060} + 3.504x_3^{-0.056}-6.408\\right)\n",
      "  Finished run #4, loss 0.06457430124282837, best loss 0.0379909947514534\n",
      "36 seconds passed from the start, the iteration took 36 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.267x_{1}^{3.0}-0.837x_{2}^{2.0}-1.077x_{3}^{1.0}+0.572$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.291x_1^{2.740} + 2.738x_2^{-0.051}-1.031x_3^{0.817}-2.625\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.9025181348581617\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.00023627345217391849, best loss 0.00023627345217391849\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 3.73251646604289e-12, best loss 3.73251646604289e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "40 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.149x_{1}^{1.0}+1.07x_{2}^{5.0}-1.415x_{3}^{6.0}+1.771$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.149x_1^{1.000} + 1.070x_2^{5.000}-1.415x_3^{6.000} + 1.771\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.4413322474714505e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.008400343358516693, best loss 0.008400343358516693\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00429, current formula \\left(-0.028x_1^{0.529}-0.950x_2^{-0.029}-0.291x_3^{4.657} + 2.355\\right)\n",
      "    Epoch 10000, current loss 0.00427, current formula \\left(-0.028x_1^{0.515}-1.455x_2^{-0.019}-0.292x_3^{4.654} + 2.862\\right)\n",
      "  Finished run #2, loss 0.0042682248167693615, best loss 0.0042682248167693615\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.00436421437188983, best loss 0.0042682248167693615\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.005124887451529503, best loss 0.0042682248167693615\n",
      "1 minutes 6 seconds passed from the start, the iteration took 26 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.035x_{1}^{3.0}+0.326x_{2}^{6.0}-0.32x_{3}^{4.0}+1.315$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.028x_1^{0.515}-1.455x_2^{-0.019}-0.292x_3^{4.654} + 2.862\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.915366857171049\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.03326220065355301, best loss 0.03326220065355301\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.223189687899918e-11, best loss 2.223189687899918e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 13 seconds passed from the start, the iteration took 7 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.903x_{1}^{1.0}+0.209x_{2}^{1.0}+0.796x_{3}^{3.0}-0.533$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.903x_1^{1.000} + 0.209x_2^{1.000} + 0.796x_3^{3.000}-0.533\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.2619637784543035e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.011, current formula \\left(1.475x_1^{-0.055}-1.484x_2^{2.003}-1.088x_3^{5.079}-1.513\\right)\n",
      "    Epoch 10000, current loss 0.0109, current formula \\left(2.246x_1^{-0.038}-1.484x_2^{2.004}-1.088x_3^{5.077}-2.287\\right)\n",
      "  Finished run #1, loss 0.010891660116612911, best loss 0.010891660116612911\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.052, current formula \\left(0.546x_1^{-0.134}-1.537x_2^{1.751} + 1.997x_3^{-0.072}-2.825\\right)\n",
      "  Finished run #2, loss 0.05175172910094261, best loss 0.010891660116612911\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.2068451706731542e-12, best loss 1.2068451706731542e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 44 seconds passed from the start, the iteration took 31 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.531x_{1}^{5.0}-1.498x_{2}^{2.0}-1.145x_{3}^{5.0}+0.142$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.531x_1^{5.000}-1.498x_2^{2.000}-1.145x_3^{5.000} + 0.142\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.7357962686251734e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[3.9025181348581617, 2.4413322474714505e-09, 6.915366857171049, 3.2619637784543035e-09, 1.7357962686251734e-10]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.38181024382611e-12, best loss 2.38181024382611e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.023x_{1}^{2.0}-1.085x_{2}^{4.5}+0.304x_{3}^{3.0}-1.396$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.023x_1^{2.000}-1.085x_2^{4.500} + 0.304x_3^{3.000}-1.396\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.0491515785790527e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.024873003363609314, best loss 0.024873003363609314\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.0893796715399917e-12, best loss 1.0893796715399917e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "6 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.937x_{1}^{5.0}-0.683x_{2}^{1.5}-0.515x_{3}^{2.0}-0.355$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.937x_1^{5.000}-0.683x_2^{1.500}-0.515x_3^{2.000}-0.355\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.330948712106745e-12\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0027848274912685156, best loss 0.0027848274912685156\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0222, current formula \\left(0.341x_1^{7.674} + 3.272x_2^{-0.038}-0.649x_3^{1.791}-4.073\\right)\n",
      "    Epoch 10000, current loss 0.022, current formula \\left(0.342x_1^{7.661} + 4.624x_2^{-0.028}-0.648x_3^{1.788}-5.427\\right)\n",
      "  Finished run #2, loss 0.02196941152215004, best loss 0.0027848274912685156\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 4.376277118467442e-12, best loss 4.376277118467442e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "27 seconds passed from the start, the iteration took 21 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.278x_{1}^{5.0}-0.715x_{2}^{4.5}-0.536x_{3}^{2.5}-0.619$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.278x_1^{5.000}-0.715x_2^{4.500}-0.536x_3^{2.500}-0.619\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0157491736606516e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.00021963572362437844, best loss 0.00021963572362437844\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0011867275461554527, best loss 0.00021963572362437844\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.00022659453679807484, best loss 0.00021963572362437844\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.00021513634419534355, best loss 0.00021513634419534355\n",
      "35 seconds passed from the start, the iteration took 8 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.459x_{1}^{1.5}-0.078x_{2}^{6.0}-0.168x_{3}^{4.0}+0.296$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.462x_1^{1.506}-0.265x_2^{0.035}-0.162x_3^{4.029} + 0.541\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.096685210821286\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.022159483283758163, best loss 0.022159483283758163\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0019633574411273003, best loss 0.0019633574411273003\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0219, current formula \\left(0.813x_1^{-0.038} + 2.958x_2^{-0.066} + 1.623x_3^{0.426}-3.658\\right)\n",
      "    Epoch 10000, current loss 0.0212, current formula \\left(0.753x_1^{-0.042} + 6.333x_2^{-0.033} + 1.639x_3^{0.419}-7.000\\right)\n",
      "  Finished run #3, loss 0.02123101055622101, best loss 0.0019633574411273003\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.0193820227110137e-10, best loss 2.0193820227110137e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "58 seconds passed from the start, the iteration took 23 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.215x_{1}^{5.5}-0.898x_{2}^{2.5}+1.463x_{3}^{0.5}+0.793$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.215x_1^{5.500}-0.898x_2^{2.500} + 1.463x_3^{0.500} + 0.793\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.118460177402556e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[2.0491515785790527e-09, 9.330948712106745e-12, 1.0157491736606516e-08, 5.096685210821286, 9.118460177402556e-09]\n",
      "For 4 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.011003042571246624, best loss 0.011003042571246624\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 7.855653627597547e-12, best loss 7.855653627597547e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "7 seconds passed from the start, the iteration took 7 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.713x_{1}^{0.917}+0.17x_{2}^{4.25}+0.497x_{3}^{3.917}+0.809$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.713x_1^{0.917} + 0.170x_2^{4.250} + 0.497x_3^{3.917} + 0.809\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.346418805286378e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0257, current formula \\left(-4.410x_1^{-0.044}-0.382x_2^{2.513} + 0.266x_3^{1.261} + 3.751\\right)\n",
      "    Epoch 10000, current loss 0.0252, current formula \\left(-6.259x_1^{-0.032}-0.384x_2^{2.522} + 0.263x_3^{1.231} + 5.602\\right)\n",
      "  Finished run #1, loss 0.025210507214069366, best loss 0.025210507214069366\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0269, current formula \\left(-6.160x_1^{-0.034}-0.377x_2^{2.393}-1.398x_3^{-0.029} + 7.065\\right)\n",
      "    Epoch 10000, current loss 0.0264, current formula \\left(-9.399x_1^{-0.023}-0.380x_2^{2.407}-1.383x_3^{-0.029} + 10.293\\right)\n",
      "  Finished run #2, loss 0.0263828057795763, best loss 0.025210507214069366\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.02687224932014942, best loss 0.025210507214069366\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 1.5969413291738732e-11, best loss 1.5969413291738732e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "45 seconds passed from the start, the iteration took 38 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.947x_{1}^{1.333}-0.513x_{2}^{3.333}+0.193x_{3}^{0.583}-1.291$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.947x_1^{1.333}-0.513x_2^{3.333} + 0.193x_3^{0.583}-1.291\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.3787403351327937e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0038202418945729733, best loss 0.0038202418945729733\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0041308533400297165, best loss 0.0038202418945729733\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.004083243664354086, best loss 0.0038202418945729733\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 1.3548258266382618e-06, best loss 1.3548258266382618e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "56 seconds passed from the start, the iteration took 11 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.007x_{1}^{5.5}-0.279x_{2}^{2.583}-0.421x_{3}^{0.5}+0.241$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-3.151x_1^{-0.000}-0.278x_2^{2.559}-0.420x_3^{0.501} + 3.394\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.167061513562332\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.066, current formula \\left(1.093x_1^{2.292}-2.898x_2^{-0.081} + 0.205x_3^{3.710} + 3.052\\right)\n",
      "  Finished run #1, loss 0.06573272496461868, best loss 0.06573272496461868\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0524, current formula \\left(-5.303x_1^{-0.042} + 1.317x_2^{8.494} + 0.204x_3^{9.054} + 5.660\\right)\n",
      "    Epoch 10000, current loss 0.0517, current formula \\left(-7.333x_1^{-0.031} + 1.314x_2^{8.454} + 0.206x_3^{8.949} + 7.692\\right)\n",
      "  Finished run #2, loss 0.05166385695338249, best loss 0.05166385695338249\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0647, current formula \\left(1.093x_1^{2.314}-6.306x_2^{-0.041} + 0.205x_3^{3.708} + 6.473\\right)\n",
      "    Epoch 10000, current loss 0.0645, current formula \\left(1.093x_1^{2.317}-7.817x_2^{-0.033} + 0.205x_3^{3.706} + 7.986\\right)\n",
      "  Finished run #3, loss 0.06448788940906525, best loss 0.05166385695338249\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0528, current formula \\left(-4.512x_1^{-0.048} + 1.320x_2^{8.519} + 0.203x_3^{9.138} + 4.864\\right)\n",
      "    Epoch 10000, current loss 0.0517, current formula \\left(-7.163x_1^{-0.032} + 1.314x_2^{8.455} + 0.206x_3^{8.951} + 7.522\\right)\n",
      "  Finished run #4, loss 0.05170964077115059, best loss 0.05166385695338249\n",
      "1 minutes 58 seconds passed from the start, the iteration took 1 minutes 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.152x_{1}^{3.0}+1.223x_{2}^{5.833}+0.142x_{3}^{5.167}-0.209$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-7.335x_1^{-0.031} + 1.314x_2^{8.454} + 0.206x_3^{8.948} + 7.694\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 23.55174429037021\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0287, current formula \\left(0.308x_1^{2.713} + 3.479x_2^{-0.039}-0.481x_3^{4.343}-3.496\\right)\n",
      "    Epoch 10000, current loss 0.0281, current formula \\left(0.306x_1^{2.688} + 5.503x_2^{-0.026}-0.481x_3^{4.356}-5.526\\right)\n",
      "  Finished run #1, loss 0.028136635199189186, best loss 0.028136635199189186\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00906, current formula \\left(-1.465x_1^{-0.045}-0.911x_2^{2.396} + 5.135x_3^{-0.010}-3.271\\right)\n",
      "  Finished run #2, loss 0.009058204479515553, best loss 0.009058204479515553\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0287, current formula \\left(0.308x_1^{2.714} + 3.393x_2^{-0.040}-0.481x_3^{4.342}-3.410\\right)\n",
      "    Epoch 10000, current loss 0.0282, current formula \\left(0.306x_1^{2.688} + 5.426x_2^{-0.027}-0.481x_3^{4.357}-5.449\\right)\n",
      "  Finished run #3, loss 0.028150875121355057, best loss 0.009058204479515553\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.00903, current formula \\left(-2.747x_1^{-0.025}-0.910x_2^{2.394} + 2.280x_3^{-0.021} + 0.869\\right)\n",
      "  Finished run #4, loss 0.00902534183114767, best loss 0.00902534183114767\n",
      "2 minutes 50 seconds passed from the start, the iteration took 53 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.26x_{1}^{3.833}-0.842x_{2}^{2.333}-0.334x_{3}^{5.167}+0.38$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.880x_1^{-0.024}-0.910x_2^{2.394} + 2.413x_3^{-0.020} + 0.869\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 8.489504843566298\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[2.346418805286378e-09, 3.3787403351327937e-09, 7.167061513562332, 23.55174429037021, 8.489504843566298]\n",
      "For 2 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.06749826669692993, best loss 0.06749826669692993\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.07158830016851425, best loss 0.06749826669692993\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.204, current formula \\left(-8.582x_1^{-0.034} + 9.538x_2^{-0.024}-0.232x_3^{3.726}-0.257x_4^{2.705} + 1.937\\right)\n",
      "    Epoch 10000, current loss 0.202, current formula \\left(-14.667x_1^{-0.021} + 15.590x_2^{-0.015}-0.227x_3^{3.702}-0.253x_4^{2.697} + 1.957\\right)\n",
      "  Finished run #3, loss 0.20206327736377716, best loss 0.06749826669692993\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0014431930612772703, best loss 0.0014431930612772703\n",
      "34 seconds passed from the start, the iteration took 34 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.714x_{1}^{4.0}-1.165x_{2}^{4.0}-0.248x_{3}^{6.0}+0.007x_{4}^{1.0}+2.611$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.713x_1^{3.908}-1.197x_2^{3.857} + 0.857x_3^{-0.034} + 0.036x_4^{5.537} + 1.702\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.562996995474428\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 5.519176261847836e-12, best loss 5.519176261847836e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "36 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.371x_{1}^{4.0}+1.212x_{2}^{1.0}-1.133x_{3}^{2.0}+1.676x_{4}^{2.0}-1.842$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.371x_1^{4.000} + 1.212x_2^{1.000}-1.133x_3^{2.000} + 1.676x_4^{2.000}-1.842\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1974796463063184e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.004420350771397352, best loss 0.004420350771397352\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.011673469096422195, best loss 0.004420350771397352\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.00021635349548887461, best loss 0.00021635349548887461\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.00887, current formula \\left(2.485x_1^{-0.020}-2.025x_2^{-0.042}-0.122x_3^{2.085} + 0.503x_4^{1.853} + 0.736\\right)\n",
      "  Finished run #4, loss 0.008789977058768272, best loss 0.00021635349548887461\n",
      "1 minutes 4 seconds passed from the start, the iteration took 28 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.324x_{1}^{3.0}+0.349x_{2}^{3.0}-0.09x_{3}^{2.0}+0.531x_{4}^{2.0}+1.148$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.327x_1^{3.025} + 0.347x_2^{3.110} + 2.975x_3^{-0.008} + 0.537x_4^{2.068}-1.874\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.507916248396197\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.010235363617539406, best loss 0.010235363617539406\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.965393126024395e-11, best loss 1.965393126024395e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 11 seconds passed from the start, the iteration took 7 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.698x_{1}^{6.0}+0.476x_{2}^{4.0}-1.378x_{3}^{2.0}-0.102x_{4}^{1.0}-0.688$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.698x_1^{6.000} + 0.476x_2^{4.000}-1.378x_3^{2.000}-0.102x_4^{1.000}-0.688\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8048162476870367e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0188, current formula \\left(-3.794x_1^{-0.029}-1.364x_2^{3.786}-2.996x_3^{-0.031} + 1.018x_4^{1.093} + 6.034\\right)\n",
      "  Finished run #1, loss 0.018782539293169975, best loss 0.018782539293169975\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0875, current formula \\left(0.698x_1^{5.582} + 3.977x_2^{-0.037} + 0.459x_3^{1.024} + 1.364x_4^{0.618}-6.066\\right)\n",
      "    Epoch 10000, current loss 0.0866, current formula \\left(0.691x_1^{5.501} + 7.124x_2^{-0.022} + 0.463x_3^{1.016} + 1.364x_4^{0.614}-9.227\\right)\n",
      "  Finished run #2, loss 0.08655915409326553, best loss 0.018782539293169975\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 4.433257233538157e-11, best loss 4.433257233538157e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 50 seconds passed from the start, the iteration took 39 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.565x_{1}^{4.0}-1.343x_{2}^{4.0}+0.477x_{3}^{1.0}+1.043x_{4}^{1.0}-1.387$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.565x_1^{4.000}-1.343x_2^{4.000} + 0.477x_3^{1.000} + 1.043x_4^{1.000}-1.387\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.937801097543393e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[6.562996995474428, 1.1974796463063184e-09, 2.507916248396197, 1.8048162476870367e-08, 3.937801097543393e-09]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.05226098746061325, best loss 0.05226098746061325\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.09503836929798126, best loss 0.05226098746061325\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.075, current formula \\left(-4.467x_1^{-0.026} + 2.481x_2^{-0.050} + 0.624x_3^{4.234}-1.355x_4^{2.503} + 0.919\\right)\n",
      "    Epoch 10000, current loss 0.0746, current formula \\left(-5.531x_1^{-0.021} + 3.551x_2^{-0.036} + 0.622x_3^{4.206}-1.356x_4^{2.494} + 0.913\\right)\n",
      "  Finished run #3, loss 0.07461889088153839, best loss 0.05226098746061325\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.159, current formula \\left(-5.352x_1^{-0.027} + 0.873x_2^{-0.096} + 2.316x_3^{0.051} + 4.655x_4^{-0.055}-3.904\\right)\n",
      "    Epoch 10000, current loss 0.157, current formula \\left(-7.113x_1^{-0.021} + 1.192x_2^{-0.075} + 2.303x_3^{0.051} + 6.110x_4^{-0.043}-3.911\\right)\n",
      "  Finished run #4, loss 0.1573868691921234, best loss 0.05226098746061325\n",
      "50 seconds passed from the start, the iteration took 50 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.962x_{1}^{4.5}-0.809x_{2}^{4.5}+0.589x_{3}^{3.0}-1.302x_{4}^{3.0}-1.168$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.316x_1^{-0.044}-0.781x_2^{4.376} + 0.643x_3^{4.953}-1.355x_4^{2.345} + 1.550\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.783440084033357\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00798, current formula \\left(4.420x_1^{-0.064}-0.299x_2^{-0.031} + 1.859x_3^{3.322} + 0.159x_4^{3.365}-3.887\\right)\n",
      "    Epoch 10000, current loss 0.00734, current formula \\left(6.907x_1^{-0.043}-0.361x_2^{-0.023} + 1.859x_3^{3.326} + 0.161x_4^{3.359}-6.320\\right)\n",
      "  Finished run #1, loss 0.007338535971939564, best loss 0.007338535971939564\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.11, current formula \\left(-1.616x_1^{0.340} + 5.822x_2^{0.010}-6.479x_3^{-0.053}-1.603x_4^{-0.053} + 4.905\\right)\n",
      "    Epoch 10000, current loss 0.109, current formula \\left(-1.698x_1^{0.314} + 8.944x_2^{0.006}-9.679x_3^{-0.037}-1.618x_4^{-0.052} + 5.092\\right)\n",
      "  Finished run #2, loss 0.10861983150243759, best loss 0.007338535971939564\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.00905, current formula \\left(3.275x_1^{-0.085} + 0.059x_2^{0.303} + 1.851x_3^{3.314} + 0.253x_4^{0.236}-3.265\\right)\n",
      "    Epoch 10000, current loss 0.00812, current formula \\left(5.595x_1^{-0.053} + 0.085x_2^{0.188} + 1.851x_3^{3.317} + 0.219x_4^{0.315}-5.581\\right)\n",
      "  Finished run #3, loss 0.008118145167827606, best loss 0.007338535971939564\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.109, current formula \\left(-1.284x_1^{0.500} + 4.896x_2^{0.011}-4.007x_3^{-0.080} + 0.371x_4^{1.427} + 1.150\\right)\n",
      "  Finished run #4, loss 0.10886235535144806, best loss 0.007338535971939564\n",
      "2 minutes 0 seconds passed from the start, the iteration took 1 minutes 10 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.326x_{1}^{0.5}-0.006x_{2}^{0.5}+1.866x_{3}^{3.5}+0.215x_{4}^{4.0}+1.432$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(6.907x_1^{-0.043}-0.361x_2^{-0.023} + 1.859x_3^{3.326} + 0.161x_4^{3.359}-6.320\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 14.335493525127715\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.020509855821728706, best loss 0.020509855821728706\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 9.231825970346108e-06, best loss 9.231825970346108e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 7 seconds passed from the start, the iteration took 7 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.064x_{1}^{0.5}+0.894x_{2}^{1.5}-0.31x_{3}^{5.0}+0.645x_{4}^{2.0}+0.215$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.164x_1^{0.113} + 0.893x_2^{1.500}-0.308x_3^{4.967} + 0.645x_4^{2.005} + 0.111\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.01908235288247251\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0538, current formula \\left(-2.620x_1^{-0.026} + 1.032x_2^{0.660}-2.424x_3^{4.517} + 1.066x_4^{1.335} + 3.197\\right)\n",
      "    Epoch 10000, current loss 0.0534, current formula \\left(-4.157x_1^{-0.018} + 1.023x_2^{0.676}-2.421x_3^{4.513} + 1.067x_4^{1.330} + 4.748\\right)\n",
      "  Finished run #1, loss 0.05337178707122803, best loss 0.05337178707122803\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 5.6321156072236533e-11, best loss 5.6321156072236533e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 29 seconds passed from the start, the iteration took 22 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.971x_{1}^{5.5}+0.977x_{2}^{0.5}-2.353x_{3}^{5.0}+1.018x_{4}^{1.5}+0.302$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.971x_1^{5.500} + 0.977x_2^{0.500}-2.353x_3^{5.000} + 1.018x_4^{1.500} + 0.302\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8419392431054702e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.02959625981748104, best loss 0.02959625981748104\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.02570531889796257, best loss 0.02570531889796257\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.026171214878559113, best loss 0.02570531889796257\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0392627939581871, best loss 0.02570531889796257\n",
      "2 minutes 44 seconds passed from the start, the iteration took 15 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.778x_{1}^{6.0}-0.13x_{2}^{4.5}-0.57x_{3}^{3.0}+0.616x_{4}^{1.0}-0.173$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.607x_1^{-0.056}-3.692x_2^{0.011}-0.542x_3^{2.984} + 0.530x_4^{0.910} + 1.655\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 8.729562025841945\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[4.783440084033357, 14.335493525127715, 0.01908235288247251, 1.8419392431054702e-09, 8.729562025841945]\n",
      "For 1 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0027522242162376642, best loss 0.0027522242162376642\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.007931549102067947, best loss 0.0027522242162376642\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 3.2058731449069455e-05, best loss 3.2058731449069455e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.008453725837171078, best loss 3.2058731449069455e-05\n",
      "20 seconds passed from the start, the iteration took 20 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.906x_{1}^{0.25}+0.813x_{2}^{0.5}-0.238x_{3}^{5.25}-0.026x_{4}^{3.667}+1.406$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.903x_1^{0.254} + 0.807x_2^{0.505}-0.241x_3^{5.425} + 0.503x_4^{-0.009} + 0.902\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.563523400917834\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0237, current formula \\left(1.287x_1^{4.349}-2.158x_2^{-0.057}-0.745x_3^{7.216} + 0.806x_4^{0.837} + 1.589\\right)\n",
      "    Epoch 10000, current loss 0.0235, current formula \\left(1.288x_1^{4.366}-3.489x_2^{-0.037}-0.743x_3^{7.209} + 0.804x_4^{0.845} + 2.928\\right)\n",
      "  Finished run #1, loss 0.023460714146494865, best loss 0.023460714146494865\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.126, current formula \\left(-2.121x_1^{-0.071}-0.856x_2^{-0.116} + 4.818x_3^{-0.017}-2.379x_4^{-0.090} + 0.894\\right)\n",
      "    Epoch 10000, current loss 0.124, current formula \\left(-2.819x_1^{-0.056}-1.184x_2^{-0.089} + 6.640x_3^{-0.013}-3.178x_4^{-0.070} + 0.914\\right)\n",
      "  Finished run #2, loss 0.12365460395812988, best loss 0.023460714146494865\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 3.0387248273200385e-11, best loss 3.0387248273200385e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 2 seconds passed from the start, the iteration took 42 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.355x_{1}^{4.333}+0.797x_{2}^{5.167}-0.625x_{3}^{4.5}+0.807x_{4}^{0.75}-0.82$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.355x_1^{4.333} + 0.797x_2^{5.167}-0.625x_3^{4.500} + 0.807x_4^{0.750}-0.820\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.2827128001744212e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 5.7501451919961255e-06, best loss 5.7501451919961255e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 4 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.583x_{1}^{1.667}-1.246x_{2}^{0.333}-1.851x_{3}^{3.75}+0.689x_{4}^{5.75}-0.356$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.583x_1^{1.679}-1.288x_2^{0.315}-1.852x_3^{3.757} + 0.687x_4^{5.754}-0.310\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.0005022969043246345\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.2332757211297452e-11, best loss 1.2332757211297452e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 6 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.27x_{1}^{1.583}+1.103x_{2}^{1.5}+0.877x_{3}^{1.333}-0.221x_{4}^{1.75}+0.803$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.270x_1^{1.583} + 1.103x_2^{1.500} + 0.877x_3^{1.333}-0.221x_4^{1.750} + 0.803\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.1143487207966576e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0178, current formula \\left(-0.568x_1^{3.349}-0.090x_2^{-0.238}-3.673x_3^{-0.044} + 4.302x_4^{-0.015}-0.143\\right)\n",
      "    Epoch 10000, current loss 0.0177, current formula \\left(-0.567x_1^{3.331}-0.126x_2^{-0.188}-4.940x_3^{-0.033} + 5.550x_4^{-0.012}-0.086\\right)\n",
      "  Finished run #1, loss 0.017670072615146637, best loss 0.017670072615146637\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.018034476786851883, best loss 0.017670072615146637\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 4.97691731576877e-12, best loss 4.97691731576877e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 33 seconds passed from the start, the iteration took 27 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.484x_{1}^{2.75}+0.024x_{2}^{2.333}+0.676x_{3}^{2.25}-0.291x_{4}^{4.25}+0.097$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.484x_1^{2.750} + 0.024x_2^{2.334} + 0.676x_3^{2.250}-0.291x_4^{4.250} + 0.097\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0322343920516403e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.563523400917834, 1.2827128001744212e-09, 0.0005022969043246345, 2.1143487207966576e-09, 1.0322343920516403e-07]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.237804559712675e-12, best loss 2.237804559712675e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "4 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.971x_{1}^{1.0}-0.152x_{2}^{3.0}-0.122$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.971x_1^{1.000}-0.152x_2^{3.000}-0.122\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.5186780328034784e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0217, current formula \\left(-0.956x_1^{0.247} + 0.506x_2^{2.023}-0.822\\right)\n",
      "  Finished run #1, loss 3.5827766534796135e-12, best loss 3.5827766534796135e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "28 seconds passed from the start, the iteration took 24 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.76x_{1}^{5.0}+0.513x_{2}^{2.0}-1.461$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.760x_1^{5.000} + 0.513x_2^{2.000}-1.461\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.028649579548073e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00385, current formula \\left(-1.253x_1^{-0.041} + 1.098x_2^{6.009} + 1.060\\right)\n",
      "    Epoch 10000, current loss 0.00379, current formula \\left(-1.877x_1^{-0.028} + 1.098x_2^{6.009} + 1.687\\right)\n",
      "  Finished run #1, loss 0.0037903471384197474, best loss 0.0037903471384197474\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0642, current formula \\left(-0.471x_1^{-0.082}-2.427x_2^{-0.047} + 2.983\\right)\n",
      "  Finished run #2, loss 0.0639244019985199, best loss 0.0037903471384197474\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.00377, current formula \\left(-2.176x_1^{-0.025} + 1.098x_2^{6.009} + 1.986\\right)\n",
      "    Epoch 10000, current loss 0.00375, current formula \\left(-2.636x_1^{-0.021} + 1.098x_2^{6.009} + 2.446\\right)\n",
      "  Finished run #3, loss 0.0037549103144556284, best loss 0.0037549103144556284\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.00385, current formula \\left(-1.228x_1^{-0.041} + 1.098x_2^{6.009} + 1.036\\right)\n",
      "    Epoch 10000, current loss 0.00379, current formula \\left(-1.874x_1^{-0.028} + 1.098x_2^{6.009} + 1.683\\right)\n",
      "  Finished run #4, loss 0.003790544578805566, best loss 0.0037549103144556284\n",
      "2 minutes 55 seconds passed from the start, the iteration took 2 minutes 27 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.29x_{1}^{3.0}+1.103x_{2}^{6.0}-0.319$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.636x_1^{-0.021} + 1.098x_2^{6.009} + 2.446\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.0654018465668\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.853620981347783e-12, best loss 3.853620981347783e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 59 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.303x_{1}^{1.0}+0.52x_{2}^{2.0}+0.03$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.303x_1^{1.000} + 0.520x_2^{2.000} + 0.030\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.159526028115536e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.3069581224559035e-12, best loss 1.3069581224559035e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 12 seconds passed from the start, the iteration took 13 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.638x_{1}^{6.0}+0.434x_{2}^{6.0}+0.672$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.638x_1^{6.000} + 0.434x_2^{6.000} + 0.672\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.7138525265636416e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[2.5186780328034784e-09, 6.028649579548073e-10, 5.0654018465668, 6.159526028115536e-10, 1.7138525265636416e-09]\n",
      "For 4 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.5417242095759907e-12, best loss 2.5417242095759907e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "7 seconds passed from the start, the iteration took 7 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.059x_{1}^{5.5}+0.807x_{2}^{1.5}+0.276$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.059x_1^{5.500} + 0.807x_2^{1.500} + 0.276\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.060023594045561e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 5.326921382220462e-06, best loss 5.326921382220462e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "15 seconds passed from the start, the iteration took 8 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.011x_{1}^{4.5}+0.174x_{2}^{5.5}+1.417$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.036x_1^{0.002} + 0.175x_2^{5.519} + 0.385\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.470217362624261\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0012666406109929085, best loss 0.0012666406109929085\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.211, current formula \\left(-10.197x_1^{-0.031}-0.889x_2^{-0.030} + 12.156\\right)\n",
      "    Epoch 10000, current loss 0.208, current formula \\left(-19.046x_1^{-0.018}-0.846x_2^{-0.031} + 20.972\\right)\n",
      "  Finished run #2, loss 0.20836782455444336, best loss 0.0012666406109929085\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.211, current formula \\left(-8.158x_1^{-0.038} + 0.174x_2^{2.252} + 9.141\\right)\n",
      "    Epoch 10000, current loss 0.208, current formula \\left(-12.152x_1^{-0.027} + 0.174x_2^{2.279} + 13.146\\right)\n",
      "  Finished run #3, loss 0.2084556370973587, best loss 0.0012666406109929085\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0013531517470255494, best loss 0.0012666406109929085\n",
      "1 minutes 45 seconds passed from the start, the iteration took 1 minutes 30 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.038x_{1}^{3.5}+0.179x_{2}^{3.5}+0.204$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.041x_1^{3.496} + 0.650x_2^{0.061}-0.372\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.4765809186508507\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.004502415657043457, best loss 0.004502415657043457\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.4862860941988743e-10, best loss 1.4862860941988743e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 58 seconds passed from the start, the iteration took 12 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.364x_{1}^{1.5}+0.869x_{2}^{0.5}-0.382$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.364x_1^{1.500} + 0.869x_2^{0.500}-0.382\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.7571139794608825e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.02155980095267296, best loss 0.02155980095267296\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.1033104117819104e-11, best loss 1.1033104117819104e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 7 seconds passed from the start, the iteration took 10 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.808x_{1}^{0.5}+0.698x_{2}^{5.0}-0.347$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.808x_1^{0.500} + 0.698x_2^{5.000}-0.347\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.1313937281774998e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[6.060023594045561e-11, 4.470217362624261, 2.4765809186508507, 6.7571139794608825e-09, 2.1313937281774998e-10]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 8.767663786830859e-13, best loss 8.767663786830859e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "4 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.568x_{1}^{4.917}+1.234x_{2}^{4.917}+0.035$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.568x_1^{4.917} + 1.234x_2^{4.917} + 0.035\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8519099864722223e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0344, current formula \\left(-1.184x_1^{2.734}-3.803x_2^{-0.046} + 4.490\\right)\n",
      "    Epoch 10000, current loss 0.0338, current formula \\left(-1.185x_1^{2.733}-5.812x_2^{-0.032} + 6.504\\right)\n",
      "  Finished run #1, loss 0.033767905086278915, best loss 0.033767905086278915\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0986, current formula \\left(9.245x_1^{-0.027}-10.732x_2^{-0.018} + 1.616\\right)\n",
      "  Finished run #2, loss 0.09741154313087463, best loss 0.033767905086278915\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0981, current formula \\left(12.140x_1^{-0.021}-7.705x_2^{-0.024}-4.328\\right)\n",
      "  Finished run #3, loss 0.09738039970397949, best loss 0.033767905086278915\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0344, current formula \\left(-1.184x_1^{2.733}-3.733x_2^{-0.047} + 4.420\\right)\n",
      "    Epoch 10000, current loss 0.0338, current formula \\left(-1.185x_1^{2.733}-5.666x_2^{-0.032} + 6.358\\right)\n",
      "  Finished run #4, loss 0.033797990530729294, best loss 0.033767905086278915\n",
      "2 minutes 32 seconds passed from the start, the iteration took 2 minutes 28 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.183x_{1}^{2.833}+0.919x_{2}^{2.583}+0.24$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.185x_1^{2.733}-5.828x_2^{-0.032} + 6.520\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 18.360047081965313\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00648, current formula \\left(-2.635x_1^{-0.050} + 0.572x_2^{4.973} + 2.032\\right)\n",
      "    Epoch 10000, current loss 0.00616, current formula \\left(-3.841x_1^{-0.036} + 0.572x_2^{4.974} + 3.242\\right)\n",
      "  Finished run #1, loss 0.00615753373131156, best loss 0.00615753373131156\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 5.878412340232231e-12, best loss 5.878412340232231e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 16 seconds passed from the start, the iteration took 44 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.616x_{1}^{0.75}+0.573x_{2}^{4.833}-1.094$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.616x_1^{0.750} + 0.573x_2^{4.833}-1.094\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.897920126088138e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 9.580531897326883e-13, best loss 9.580531897326883e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 20 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.246x_{1}^{1.75}+0.938x_{2}^{3.75}+0.627$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.246x_1^{1.750} + 0.938x_2^{3.750} + 0.627\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.4800783648970538e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.289348291639186e-11, best loss 7.289348291639186e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 27 seconds passed from the start, the iteration took 7 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.253x_{1}^{5.667}-0.417x_{2}^{0.5}+1.059$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.253x_1^{5.667}-0.417x_2^{0.500} + 1.059\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.911770261159745e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.8519099864722223e-10, 18.360047081965313, 2.897920126088138e-10, 2.4800783648970538e-11, 7.911770261159745e-09]\n",
      "For 4 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.4571599055732705e-12, best loss 3.4571599055732705e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "5 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.546x_{1}^{3.0}+1.704x_{2}^{5.0}-0.877x_{3}^{2.0}-0.95$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.546x_1^{3.000} + 1.704x_2^{5.000}-0.877x_3^{2.000}-0.950\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1501098486275753e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0596, current formula \\left(1.244x_1^{5.087}-1.033x_2^{5.802} + 3.821x_3^{-0.041}-5.135\\right)\n",
      "    Epoch 10000, current loss 0.0589, current formula \\left(1.243x_1^{5.082}-1.032x_2^{5.804} + 5.924x_3^{-0.028}-7.244\\right)\n",
      "  Finished run #1, loss 0.0589015893638134, best loss 0.0589015893638134\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.045, current formula \\left(1.283x_1^{5.119} + 2.734x_2^{-0.041}-1.205x_3^{4.186}-3.941\\right)\n",
      "    Epoch 10000, current loss 0.0447, current formula \\left(1.284x_1^{5.117} + 4.172x_2^{-0.028}-1.204x_3^{4.186}-5.384\\right)\n",
      "  Finished run #2, loss 0.04467007517814636, best loss 0.04467007517814636\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.1818714409916886e-12, best loss 1.1818714409916886e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 35 seconds passed from the start, the iteration took 1 minutes 30 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.246x_{1}^{5.0}-1.031x_{2}^{6.0}-1.162x_{3}^{4.0}-0.935$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.246x_1^{5.000}-1.031x_2^{6.000}-1.162x_3^{4.000}-0.935\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.2840700759323747e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0046, current formula \\left(-0.959x_1^{-0.039} + 1.052x_2^{5.756} + 0.370x_3^{5.830} + 2.066\\right)\n",
      "    Epoch 10000, current loss 0.00457, current formula \\left(-1.412x_1^{-0.027} + 1.052x_2^{5.757} + 0.370x_3^{5.826} + 2.521\\right)\n",
      "  Finished run #1, loss 0.004565421026200056, best loss 0.004565421026200056\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.1945076004715727e-12, best loss 1.1945076004715727e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 22 seconds passed from the start, the iteration took 47 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.334x_{1}^{6.0}+1.061x_{2}^{6.0}+0.373x_{3}^{6.0}+1.024$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.334x_1^{6.000} + 1.061x_2^{6.000} + 0.373x_3^{6.000} + 1.024\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.0846095643329524e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00424, current formula \\left(-1.875x_1^{-0.025} + 0.358x_2^{6.318}-1.306x_3^{-0.033} + 3.285\\right)\n",
      "  Finished run #1, loss 0.004233105573803186, best loss 0.004233105573803186\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00935, current formula \\left(3.913x_1^{0.014}-1.587x_2^{-0.025}-1.195x_3^{-0.038}-0.930\\right)\n",
      "  Finished run #2, loss 0.009344140067696571, best loss 0.004233105573803186\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.009003065526485443, best loss 0.004233105573803186\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 3.110338158904269e-12, best loss 3.110338158904269e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 40 seconds passed from the start, the iteration took 1 minutes 18 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.275x_{1}^{3.0}+0.37x_{2}^{6.0}+0.178x_{3}^{1.0}-0.147$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.275x_1^{3.000} + 0.370x_2^{6.000} + 0.178x_3^{1.000}-0.147\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.3289694617290024e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.3376547092214253e-10, best loss 1.3376547092214253e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 46 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -2.214x_{1}^{1.0}+0.33x_{2}^{2.0}-0.575x_{3}^{1.0}-1.105$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.214x_1^{1.000} + 0.330x_2^{2.000}-0.575x_3^{1.000}-1.105\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.22060777491892e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.1501098486275753e-10, 2.2840700759323747e-10, 2.0846095643329524e-09, 2.3289694617290024e-09, 6.22060777491892e-09]\n",
      "For 5 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.33, current formula \\left(-0.148x_1^{3.072}-0.286x_2^{1.356}-11.936x_3^{-0.039} + 12.503\\right)\n",
      "    Epoch 10000, current loss 0.324, current formula \\left(-0.148x_1^{3.002}-0.284x_2^{1.340}-17.835x_3^{-0.027} + 18.428\\right)\n",
      "  Finished run #1, loss 0.32422971725463867, best loss 0.32422971725463867\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00356, current formula \\left(-0.114x_1^{4.787}-1.191x_2^{0.048} + 2.647x_3^{2.494} + 0.331\\right)\n",
      "  Finished run #2, loss 4.947772660329752e-12, best loss 4.947772660329752e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 17 seconds passed from the start, the iteration took 1 minutes 17 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.12x_{1}^{4.5}-0.279x_{2}^{3.5}+2.651x_{3}^{2.5}-0.739$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.120x_1^{4.500}-0.279x_2^{3.500} + 2.651x_3^{2.500}-0.739\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 8.957661279396234e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.026727164164185524, best loss 0.026727164164185524\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.006381478626281023, best loss 0.006381478626281023\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0258, current formula \\left(4.990x_1^{0.017}-2.640x_2^{-0.026}-7.387x_3^{-0.020} + 4.464\\right)\n",
      "    Epoch 10000, current loss 0.0257, current formula \\left(4.998x_1^{0.017}-2.645x_2^{-0.026}-8.942x_3^{-0.017} + 6.018\\right)\n",
      "  Finished run #3, loss 0.025690864771604538, best loss 0.006381478626281023\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 3.565574484970524e-12, best loss 3.565574484970524e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 21 seconds passed from the start, the iteration took 1 minutes 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.378x_{1}^{3.0}+0.326x_{2}^{2.5}+0.662x_{3}^{1.5}-1.334$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.378x_1^{3.000} + 0.326x_2^{2.500} + 0.662x_3^{1.500}-1.334\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0635217151389043e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00764, current formula \\left(1.461x_1^{5.045}-1.949x_2^{-0.031} + 0.932x_3^{4.483} + 2.318\\right)\n",
      "    Epoch 10000, current loss 0.00756, current formula \\left(1.462x_1^{5.046}-2.802x_2^{-0.022} + 0.933x_3^{4.481} + 3.173\\right)\n",
      "  Finished run #1, loss 0.007562102284282446, best loss 0.007562102284282446\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.0561233962022576e-12, best loss 1.0561233962022576e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 8 seconds passed from the start, the iteration took 47 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.455x_{1}^{5.0}+0.387x_{2}^{3.5}+0.952x_{3}^{4.5}+0.213$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.455x_1^{5.000} + 0.387x_2^{3.500} + 0.952x_3^{4.500} + 0.213\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.9242919197258743e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0015427002217620611, best loss 0.0015427002217620611\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0011098987888544798, best loss 0.0011098987888544798\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.09761632978916168, best loss 0.0011098987888544798\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0007819951279088855, best loss 0.0007819951279088855\n",
      "3 minutes 46 seconds passed from the start, the iteration took 38 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.373x_{1}^{0.5}+0.029x_{2}^{1.0}+1.477x_{3}^{5.5}+0.017$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.056x_1^{0.044}-0.491x_2^{-0.014} + 1.476x_3^{5.501} + 2.251\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.3328741777788795\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0218, current formula \\left(1.168x_1^{-0.055} + 1.862x_2^{-0.051} + 0.463x_3^{3.172}-1.692\\right)\n",
      "  Finished run #1, loss 0.021636219695210457, best loss 0.021636219695210457\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.021986916661262512, best loss 0.021636219695210457\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.01407396886497736, best loss 0.01407396886497736\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.02247605472803116, best loss 0.01407396886497736\n",
      "4 minutes 47 seconds passed from the start, the iteration took 1 minutes 0 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.558x_{1}^{4.5}-0.458x_{2}^{1.5}+0.43x_{3}^{3.5}+1.801$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.463x_1^{-0.047}-0.467x_2^{1.603} + 0.446x_3^{3.212} + 0.151\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.9391985323695806\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[8.957661279396234e-10, 1.0635217151389043e-09, 2.9242919197258743e-10, 1.3328741777788795, 3.9391985323695806]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 6.254349121936897e-11, best loss 6.254349121936897e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "6 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.39x_{1}^{2.833}-2.399x_{2}^{4.75}+1.496x_{3}^{0.5}-0.356$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.390x_1^{2.833}-2.399x_2^{4.750} + 1.496x_3^{0.500}-0.356\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.3985355096224339e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.01212826743721962, best loss 0.01212826743721962\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.007989181205630302, best loss 0.007989181205630302\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.005099344067275524, best loss 0.005099344067275524\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.168536497038076e-07, best loss 2.168536497038076e-07\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "34 seconds passed from the start, the iteration took 28 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.148x_{1}^{0.167}+0.321x_{2}^{3.417}+0.409x_{3}^{4.5}+0.345$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.129x_1^{0.202} + 0.321x_2^{3.417} + 0.409x_3^{4.500} + 0.325\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.0002819901945920744\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0203, current formula \\left(-0.772x_1^{0.239}-1.991x_2^{0.777}-2.478x_3^{-0.053} + 1.665\\right)\n",
      "  Finished run #1, loss 0.019944606348872185, best loss 0.019944606348872185\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0202, current formula \\left(-0.774x_1^{0.238}-1.994x_2^{0.774}-2.567x_3^{-0.051} + 1.760\\right)\n",
      "  Finished run #2, loss 0.020222345367074013, best loss 0.019944606348872185\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0755, current formula \\left(-2.662x_1^{0.049} + 12.842x_2^{-0.036}-12.537x_3^{-0.011}-0.788\\right)\n",
      "    Epoch 10000, current loss 0.0735, current formula \\left(-2.665x_1^{0.049} + 18.759x_2^{-0.025}-18.403x_3^{-0.008}-0.844\\right)\n",
      "  Finished run #3, loss 0.07353824377059937, best loss 0.019944606348872185\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 3.870183718390763e-06, best loss 3.870183718390763e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 25 seconds passed from the start, the iteration took 1 minutes 51 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.005x_{1}^{0.167}-2.005x_{2}^{0.75}+0.688x_{3}^{2.417}-0.887$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.916x_1^{0.189}-2.005x_2^{0.750} + 0.688x_3^{2.415}-0.978\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.0023725920828787344\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.3485506074616413e-12, best loss 2.3485506074616413e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 29 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.588x_{1}^{4.25}-0.072x_{2}^{3.25}+0.267x_{3}^{5.667}-0.723$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.588x_1^{4.250}-0.072x_2^{3.250} + 0.267x_3^{5.666}-0.723\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.851231697574986e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.00022699196415487677, best loss 0.00022699196415487677\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.000908, current formula \\left(-0.942x_1^{2.597}-0.034x_2^{4.602}-2.533x_3^{-0.034} + 2.982\\right)\n",
      "    Epoch 10000, current loss 0.000852, current formula \\left(-0.942x_1^{2.596}-0.035x_2^{4.603}-3.495x_3^{-0.026} + 3.945\\right)\n",
      "  Finished run #2, loss 0.0008519195253029466, best loss 0.00022699196415487677\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.001259737415239215, best loss 0.00022699196415487677\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0011678199516609311, best loss 0.00022699196415487677\n",
      "3 minutes 26 seconds passed from the start, the iteration took 57 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.943x_{1}^{2.583}-0.04x_{2}^{5.0}+0.517x_{3}^{0.333}-0.028$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.942x_1^{2.589}-3.143x_2^{0.002} + 0.876x_3^{0.152} + 2.729\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.053817742796894\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.3985355096224339e-09, 0.0002819901945920744, 0.0023725920828787344, 5.851231697574986e-09, 6.053817742796894]\n",
      "For 2 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.09656322002410889, best loss 0.09656322002410889\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.136, current formula \\left(-2.966x_1^{0.013} + 2.028x_2^{-0.053}-2.257x_3^{-0.004} + 4.265x_4^{-0.053}-1.405\\right)\n",
      "  Finished run #2, loss 0.13558471202850342, best loss 0.09656322002410889\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0907856673002243, best loss 0.0907856673002243\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0944, current formula \\left(1.313x_1^{-0.026}-0.919x_2^{4.151}-0.160x_3^{0.014} + 7.131x_4^{-0.033}-8.344\\right)\n",
      "  Finished run #4, loss 0.09428060054779053, best loss 0.0907856673002243\n",
      "1 minutes 35 seconds passed from the start, the iteration took 1 minutes 35 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.267x_{1}^{5.0}-0.954x_{2}^{4.0}-0.011x_{3}^{2.0}-1.366x_{4}^{4.0}+0.558$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.319x_1^{6.324}-0.921x_2^{4.057}-0.207x_3^{0.022} + 5.348x_4^{-0.044}-5.115\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 11.035699001628807\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.3167086712637683e-06, best loss 3.3167086712637683e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 40 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.009x_{1}^{3.0}-0.248x_{2}^{3.0}+0.018x_{3}^{2.0}-0.504x_{4}^{2.0}+0.582$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.019x_1^{0.128}-0.248x_2^{2.997} + 0.018x_3^{1.958}-0.504x_4^{2.003} + 0.568\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.9165908047699608\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.4047645345453015e-12, best loss 3.4047645345453015e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 1 seconds passed from the start, the iteration took 21 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.203x_{1}^{5.0}+0.312x_{2}^{6.0}-1.329x_{3}^{4.0}-0.639x_{4}^{5.0}-1.152$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.203x_1^{5.000} + 0.312x_2^{6.000}-1.329x_3^{4.000}-0.639x_4^{5.000}-1.152\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.486025461070514e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.011065475642681122, best loss 0.011065475642681122\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.13872326910495758, best loss 0.011065475642681122\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.01096189022064209, best loss 0.01096189022064209\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.00312, current formula \\left(-0.020x_1^{0.941}-1.423x_2^{-0.034} + 1.810x_3^{5.988}-0.489x_4^{3.968} + 2.776\\right)\n",
      "    Epoch 10000, current loss 0.00308, current formula \\left(-0.020x_1^{0.937}-2.122x_2^{-0.024} + 1.809x_3^{5.987}-0.489x_4^{3.967} + 3.477\\right)\n",
      "  Finished run #4, loss 0.0030841082334518433, best loss 0.0030841082334518433\n",
      "3 minutes 18 seconds passed from the start, the iteration took 1 minutes 17 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.018x_{1}^{6.0}+0.268x_{2}^{3.0}+1.814x_{3}^{6.0}-0.5x_{4}^{4.0}+1.23$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.020x_1^{0.937}-2.123x_2^{-0.024} + 1.809x_3^{5.987}-0.489x_4^{3.967} + 3.477\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.0591853206461765\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 9.695412154542282e-05, best loss 9.695412154542282e-05\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 9.67375235632062e-05, best loss 9.67375235632062e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0009523620246909559, best loss 9.67375235632062e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.000774055952206254, best loss 9.67375235632062e-05\n",
      "3 minutes 43 seconds passed from the start, the iteration took 25 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.05x_{1}^{2.0}+0.77x_{2}^{1.0}-0.132x_{3}^{4.0}-0.501x_{4}^{2.0}+1.08$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.372x_1^{-0.026} + 0.769x_2^{1.000}-0.131x_3^{3.922}-0.501x_4^{1.998} + 0.682\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.4941236820419679\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[11.035699001628807, 0.9165908047699608, 5.486025461070514e-10, 5.0591853206461765, 0.4941236820419679]\n",
      "For 1 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.01659274846315384, best loss 0.01659274846315384\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0217, current formula \\left(-2.446x_1^{0.482} + 2.782x_2^{-0.053}-0.612x_3^{5.304}-3.719x_4^{-0.034} + 0.836\\right)\n",
      "  Finished run #2, loss 0.02152463234961033, best loss 0.01659274846315384\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.009598714299499989, best loss 0.009598714299499989\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.017029281705617905, best loss 0.009598714299499989\n",
      "58 seconds passed from the start, the iteration took 58 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -2.4x_{1}^{0.5}-0.647x_{2}^{1.0}-0.62x_{3}^{5.5}+0.589x_{4}^{1.5}-0.046$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.451x_1^{0.478} + 1.645x_2^{-0.082}-0.611x_3^{5.263} + 0.601x_4^{1.608}-2.090\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.185661879858134\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.949790698243305e-05, best loss 3.949790698243305e-05\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.017390431836247444, best loss 3.949790698243305e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 4.220204209559597e-05, best loss 3.949790698243305e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.013125368393957615, best loss 3.949790698243305e-05\n",
      "1 minutes 22 seconds passed from the start, the iteration took 24 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.345x_{1}^{2.0}-0.517x_{2}^{3.5}+1.034x_{3}^{5.0}+0.031x_{4}^{3.5}+0.284$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.346x_1^{1.995}-0.517x_2^{3.504} + 1.035x_3^{4.995}-1.576x_4^{-0.003} + 1.872\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.9304970110986441\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.446, current formula \\left(-8.625x_1^{-0.049} + 4.226x_2^{-0.036} + 3.662x_3^{-0.040} + 0.529x_4^{0.667}-0.050\\right)\n",
      "    Epoch 10000, current loss 0.441, current formula \\left(-11.318x_1^{-0.039} + 5.724x_2^{-0.028} + 4.873x_3^{-0.031} + 0.517x_4^{0.714}-0.045\\right)\n",
      "  Finished run #1, loss 0.4410792589187622, best loss 0.4410792589187622\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0812, current formula \\left(2.705x_1^{3.063} + 3.140x_2^{-0.052}-2.038x_3^{0.095} + 0.492x_4^{1.071}-2.976\\right)\n",
      "  Finished run #2, loss 0.04792493209242821, best loss 0.04792493209242821\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.037592992186546326, best loss 0.037592992186546326\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0536, current formula \\left(2.698x_1^{3.094} + 6.841x_2^{-0.027}-0.912x_3^{3.920}-9.001x_4^{-0.014} + 0.952\\right)\n",
      "    Epoch 10000, current loss 0.0517, current formula \\left(2.699x_1^{3.095} + 9.507x_2^{-0.020}-0.912x_3^{3.918}-11.607x_4^{-0.010} + 0.922\\right)\n",
      "  Finished run #4, loss 0.05169333517551422, best loss 0.037592992186546326\n",
      "3 minutes 33 seconds passed from the start, the iteration took 2 minutes 10 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.67x_{1}^{3.0}-1.014x_{2}^{3.0}-0.932x_{3}^{4.0}+0.436x_{4}^{1.0}-1.083$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.673x_1^{2.971}-1.016x_2^{2.938} + 1.787x_3^{-0.064} + 0.451x_4^{0.906}-3.190\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.151234911647556\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.003493516007438302, best loss 0.003493516007438302\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00641, current formula \\left(-1.264x_1^{6.081}-0.637x_2^{-0.060}-0.798x_3^{-0.063} + 0.820x_4^{0.472}-0.040\\right)\n",
      "  Finished run #2, loss 0.00634206784889102, best loss 0.003493516007438302\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.003003333928063512, best loss 0.003003333928063512\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.00599695323035121, best loss 0.003003333928063512\n",
      "4 minutes 29 seconds passed from the start, the iteration took 56 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.257x_{1}^{6.0}+0.267x_{2}^{3.0}+0.27x_{3}^{2.0}+0.809x_{4}^{0.5}-1.711$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.263x_1^{6.114} + 0.261x_2^{3.108}-2.317x_3^{-0.025} + 0.822x_4^{0.480} + 0.744\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8714921084662894\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.9780097698651744e-12, best loss 1.9780097698651744e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "4 minutes 34 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.112x_{1}^{1.5}-0.399x_{2}^{4.0}+0.371x_{3}^{3.5}-0.307x_{4}^{4.0}+0.861$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.112x_1^{1.500}-0.399x_2^{4.000} + 0.371x_3^{3.500}-0.307x_4^{4.000} + 0.861\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.4503164929178134e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.185661879858134, 1.9304970110986441, 3.151234911647556, 1.8714921084662894, 2.4503164929178134e-10]\n",
      "For 1 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.020748550072312355, best loss 0.020748550072312355\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.007585201412439346, best loss 0.007585201412439346\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.022154904901981354, best loss 0.007585201412439346\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.028292179107666016, best loss 0.007585201412439346\n",
      "36 seconds passed from the start, the iteration took 36 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.702x_{1}^{5.25}+0.567x_{2}^{0.083}+0.165x_{3}^{2.5}+0.403x_{4}^{3.667}-1.346$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.709x_1^{5.293} + 0.495x_2^{0.099} + 0.166x_3^{2.616}-0.718x_4^{-0.081}-0.406\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8005286479111453\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.2378125394406645e-11, best loss 2.2378125394406645e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "49 seconds passed from the start, the iteration took 13 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.79x_{1}^{1.0}-0.425x_{2}^{3.417}-0.621x_{3}^{2.333}-0.889x_{4}^{5.833}-0.048$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.790x_1^{1.000}-0.425x_2^{3.417}-0.621x_3^{2.333}-0.889x_4^{5.833}-0.048\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0482903572972546e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0008136674878187478, best loss 0.0008136674878187478\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.010386984795331955, best loss 0.0008136674878187478\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0026464583352208138, best loss 0.0008136674878187478\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 1.623861960696471e-12, best loss 1.623861960696471e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 50 seconds passed from the start, the iteration took 1 minutes 0 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.253x_{1}^{3.5}+0.952x_{2}^{4.833}+0.395x_{3}^{3.0}-0.137x_{4}^{3.583}+0.077$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.253x_1^{3.500} + 0.952x_2^{4.833} + 0.395x_3^{3.000}-0.137x_4^{3.583} + 0.077\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.997267765207482e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.11, current formula \\left(1.567x_1^{0.316}-3.791x_2^{-0.004} + 0.629x_3^{-0.102} + 6.934x_4^{-0.047}-5.728\\right)\n",
      "    Epoch 10000, current loss 0.107, current formula \\left(1.612x_1^{0.302}-3.823x_2^{-0.004} + 0.849x_3^{-0.082} + 8.977x_4^{-0.038}-8.020\\right)\n",
      "  Finished run #1, loss 0.10737858712673187, best loss 0.10737858712673187\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.00010147714056074619, best loss 0.00010147714056074619\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.01991933025419712, best loss 0.00010147714056074619\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0172, current formula \\left(-8.996x_1^{-0.029} + 1.432x_2^{0.011} + 9.226x_3^{-0.011}-1.709x_4^{1.137}-1.029\\right)\n",
      "    Epoch 10000, current loss 0.017, current formula \\left(-11.024x_1^{-0.024} + 1.439x_2^{0.011} + 11.240x_3^{-0.009}-1.709x_4^{1.136}-1.020\\right)\n",
      "  Finished run #4, loss 0.016977833583950996, best loss 0.00010147714056074619\n",
      "3 minutes 40 seconds passed from the start, the iteration took 1 minutes 51 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.776x_{1}^{0.25}+0.055x_{2}^{1.5}-0.539x_{3}^{2.5}-1.727x_{4}^{1.083}-0.814$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.743x_1^{0.258}-1.211x_2^{-0.011}-0.540x_3^{2.522}-1.728x_4^{1.084} + 0.467\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.6143180493323102\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0271, current formula \\left(0.364x_1^{0.896}-1.449x_2^{4.701} + 3.570x_3^{-0.043} + 0.171x_4^{4.080}-3.420\\right)\n",
      "    Epoch 10000, current loss 0.0267, current formula \\left(0.366x_1^{0.882}-1.449x_2^{4.701} + 5.416x_3^{-0.030} + 0.172x_4^{4.139}-5.272\\right)\n",
      "  Finished run #1, loss 0.02667781338095665, best loss 0.02667781338095665\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0007714319508522749, best loss 0.0007714319508522749\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.123, current formula \\left(0.365x_1^{1.132} + 2.978x_2^{-0.057} + 1.783x_3^{-0.073}-0.645x_4^{-0.023}-4.315\\right)\n",
      "  Finished run #3, loss 0.12201472371816635, best loss 0.0007714319508522749\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0289, current formula \\left(-5.441x_1^{-0.017}-1.458x_2^{4.715} + 4.750x_3^{-0.033} + 0.159x_4^{4.188} + 1.126\\right)\n",
      "  Finished run #4, loss 0.02859054133296013, best loss 0.0007714319508522749\n",
      "5 minutes 42 seconds passed from the start, the iteration took 2 minutes 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.429x_{1}^{0.583}-1.438x_{2}^{4.667}-0.808x_{3}^{3.0}+0.132x_{4}^{3.167}+0.426$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.437x_1^{0.552}-1.440x_2^{4.645}-0.813x_3^{3.065}-1.220x_4^{-0.018} + 1.687\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.5068772381579782\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.8005286479111453, 1.0482903572972546e-09, 6.997267765207482e-10, 0.6143180493323102, 1.5068772381579782]\n",
      "For 2 formulas out of 5 the error is less than 1e-05.\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for m_samples in [10, 100, 1000]:\n",
    "    results[m_samples] = {}\n",
    "    for n_variables in range(2, 5):\n",
    "        results[m_samples][n_variables] = []\n",
    "        i = 0\n",
    "        for min_power, max_power, divide_powers_by in ((1, 6, 1), (1, 12, 2), (1, 72, 12)):\n",
    "            recoveries = explore.explore(n_variables=n_variables, \n",
    "                                             m_samples=m_samples, number_of_tested_formulas=5, \n",
    "                                             min_power=min_power, max_power=max_power, \n",
    "                                                 divide_powers_by=divide_powers_by)\n",
    "            results[m_samples][n_variables].append(recoveries / 5)\n",
    "            i += 1\n",
    "            \n",
    "with open(\"results.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(results, fout)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiments took 1 hour 3 minutes 31 seconds\n"
     ]
    }
   ],
   "source": [
    "times = np.array([\n",
    "    (5, 42),\n",
    "    (4, 34),\n",
    "    (3, 43), (3, 26), (4, 47), (3, 46), (3, 27), (2, 7), (3, 12), (1, 33), (2, 44), (1, 50), (2, 50), (0, 58), \n",
    "    (1, 44), (1, 25), (1, 12), (0, 8), (2, 45), (1, 58), (2, 16), (1, 55), (1, 12), (1, 38), (0, 48), (0, 46), \n",
    "    (1, 5)\n",
    "])\n",
    "seconds = (times[:, 0].sum() * 60 + times[:, 1].sum())\n",
    "minutes, seconds = divmod(seconds, 60)\n",
    "hours, minutes = divmod(minutes, 60)\n",
    "print(f\"The experiments took {hours} hour {minutes} minutes {seconds} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {2: [0.2, 0.6, 0.4], 3: [0.2, 0.6, 0.0], 4: [0.0, 0.0, 0.2]},\n",
       " 100: {2: [1.0, 0.8, 0.8], 3: [0.6, 0.8, 0.4], 4: [0.6, 0.2, 0.6]},\n",
       " 1000: {2: [0.8, 0.6, 0.8], 3: [1.0, 0.6, 0.4], 4: [0.2, 0.2, 0.4]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = {}\n",
    "for m_samples in [10, 100, 1000]:\n",
    "    se[m_samples] = {}\n",
    "    for n_variables in range(2, 5):\n",
    "        a = np.array(results[m_samples][n_variables])\n",
    "        se[m_samples][n_variables] = np.sqrt(a * (1 - a) / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "barwidth = 1/6\n",
    "a = np.arange(-1, 2) / 4\n",
    "colors = {10: \"orange\", 100: \"cyan\", 1000: \"red\"}\n",
    "patches = []        \n",
    "plt.figure(figsize=(15, 10))\n",
    "for n_variables in range(2, 5):\n",
    "    for m_samples in [1000, 100, 10]:\n",
    "        plt.bar(a + n_variables, results[m_samples][n_variables], width=1/4, yerr=1.96 * se[m_samples][n_variables],\n",
    "                color=colors[m_samples], edgecolor = 'black', capsize=4, alpha=0.5)   \n",
    "    patches.append(mpatches.Patch(color=colors[m_samples], label=str(m_samples) + \" samples\"))\n",
    "plt.xlabel('n variables')\n",
    "plt.ylabel('recovery rate')\n",
    "plt.xticks([2, 3, 4])\n",
    "plt.title(\"NestedFormula experiments, 5 for each configuration, with 95% confidence intervals\")\n",
    "plt.legend(handles=patches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAANsCAYAAAAAwqq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzde7iVZbnv8e+NgkAoIgYeMLA0UzmkoOi2bCKZaC4oM5WlBUvLDhuzdpm4IhU3FZ1s18oy19KgVYnoSiUixQ4sa6UhmAqIBhrGKQ+ABwwU7d5/jMF0MJnAgDmHc/Dy/VzXvJzv6Rn3eOczXseP5z1EZiJJkiRJKp52bV2AJEmSJKk2DHySJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCsrAJ0mSJEkFZeCTpFYUEUsi4t1tXcfWRESfiMiI2L2ta2mJiFgQEQ1tXcfrJSI6RcTPI+K5iLi5revZknr4DETECRGxKCLWRsT7IuKXETGqLWuqtKv1XUlty8AnaadT/kL5VES8oWLeRyJiVgvbbYiIZS0u8LX2royIDeUvnRt/Pt9a7e/qMvPIzJz1er9uRMyKiI+0UltLImJdRf+YuZXVzwR6At0z84Ot8foFdhXw3czskpm3ZeapmTm5LQqJiEkRMaFyXlv1XUm7JgOfpJ3VbsDFbV1EFW4qf+nc+PO17W1gZx+Ja20F3B//VNE/3rOV9XoDf87MV7b3BQq4z7alN7Cg1i+yC+5XSTshA5+kndXXgc9FxN7NLYyIt0XEXRGxOiIejYizKpadFhEPR8QLEbE8Ij5XHi38JXBAxWjLARHRLiLGRsRjEbEqIqZGxD4VbX0oIp4oL/tCtcWX255Wrm9xRHy0YtmVEXFLRPw4Ip4HRpfn3Vye90JEzIuIt0bEZeXRzqUR8Z6KNjY5ra68/Y+3UMu/RMTCcruPR8THtlH7+eX110TEnRHRuzz/f0XEMxFxUHl6QHmdt1XUdFl536+JiB9GRMeKdk+PiAci4tmI+ENE9G/yfi6NiIeAFyNi98r3uAP7p2tEXB8RK8t9YEJE7FZeNjoifh8R3yjX+ZeIOLW87EvAO4HvlvvId6PkW+XXeb782n233QuqFxHjgcuBs8uve0G5b44r97+nIuJHEdG1vP7G03YviIi/Ar/ZQrtb2+cb+/0L5b/Z+5ts+9GKfvNwRBxdsfjtEfFQlE4/vany79xMDc22ExGHR2k09dkonQI5vGKbSRFxTUT8orzdHyPiLeVljwFvBn5e3ld7RMWobETsFhHfLPfVv0TEmKg4xTm28tnZ0n4t972/ld/v3RFxZHn+hcC5wOfLtfy86WuU6/t/EbGi/PP/ImKP8rKGiFgWEZ8t/41XRsS/bGlfSlJzDHySdlZzgFnA55ouiFJ4uwv4KdADOAf4XkQcUV7leuBjmbkn0Bf4TWa+CJwKrKgYbVkBXAS8D3gXcACwBrim/DpHAN8HPlRe1h3oVWX9U4Bl5e3OBL4cESdVLB8B3ALsDfykPO+fgP8EugF/Au6kdBw/kNIpbD+o8rWbego4HdgL+BfgW02+vDeKiBHAvwJnAG8EfgfcCJCZfyjXMDkiOgE/Br6YmY9UNHEucArwFuCtwLhyu0cBNwAfo7QffwBM2/jFt2wk8F5g7y2Mcm3P/pkEvAIcAhwFvAeoPE1zMPAosC/wNeD6iIjM/EL5PY8p95Ex5W1PLL+frsBZwKrm9t8W/CQino6ImRExoLkVMvMK4Mu8NmJ8PTC6/DOEUsDpAny3yabvAg6ntM83UcU+f4xSuO0KjAd+HBH7l7f9IHAl8GFK/WZ4k/d8FjAMOBjoX65zM1tqJyLaAz8HZlL6DF9U3k+HVWx+TrmubsBi4EvlffUW4K+8NnL6UpOX/Silz/rbgaMpfb63V9P9+kvg0HKt91P+zGbmdeXfv1au5Z+aaesLwHHlegYAx1L+XJTtR+lvcCBwAXBNRHTbgZol7aIMfJJ2ZpcDF0XEG5vMPx1Ykpk/zMxXMvNPwH8BG6972gAcERF7ZeaazLx/K6/xceALmbms/MXxSuDM8mjAmcD0zLy7vOyLwD+abH9WeYRi488BURoBOwG4NDPXZ+YDwH9Q+tK70T3la4/+kZnryvN+l5l3lsPOzZQC18TM3EApQPaJLYx4bk1m/iIzH8uS/6b0JfudW9kfX8nMheU6vkxpNKd3efmVlL6czgaWUw7HFb6bmUszczWlL+gjy/MvBH6QmX/MzFfL11u9ROmL8EbfKW+7juZVtX8ioidwGvDpzHwxM58CvkUpQGz0RGb+e2a+CkwG9qd0/VxzNgB7Am8DorxvVm5h3abOBfpQOgXxt8Cd2/E3PBe4OjMfz8y1wGXAObHpaYZXlt9jc/tsq/s8M2/OzBXlPngTsIhSGIFSOP5aZt5X7jeLM/OJira/U952NaXg9vYtvIcttXMcpQA7MTNfzszfANN5rb8A3JqZs8t/759s5TWaOgv4dvkzvQaYWOV2lTbZr5l5Q2a+UHGMGLBxtLUK5wJXZeZTmfk0pRD7oYrlG8rLN2TmDGAtcFgz7UhSswx8knZamTmf0pfAsU0W9QYGVwYtSl+q9isv/wClL/xPRMR/R8TxW3mZ3sCtFe0sBF6l9OX/AGBpRT0vsvnIztTM3LviZ0V5u9WZ+ULFek9Q+hf8jZayuScrfl8HPFMOJBunofQlebtExKkRcW+UTi99ltK+2XcLq/cGvl2xP1YDsbH2criaRGnk9JuZmU22r3xfT1DaFxvb/WyTv9lBFcubbtucavdPb6A9sLLitX5AaXRmo79t/CUz/16x7WbKYeS7lMLtUxFxXUTstY1aN277P5m5LjP/nplfAZ5ly2G7qQMo7cONngB2Z9NgurV9ttV9HhEfjtdO93yW0t90Y784iNII4Jb8reL3v7Plfrmldg4AlmZm5T+gNP2MVPsazbZdMb2tftWcxm3Kp4hOjNLpr88DS8qLtvQZaq6epn/Hyn6/qsmI9va8V0ky8Ena6V1B6RStpmHpv5sErS6Z+QmA8mjCCEpf8G8Dppa3axpONrZ1apO2OmbmcmAlpS+sAEREZ0qnxm3LCmCfiNizYt6bKI2IbdRcLdvjRaBzxfR+za1UPn3vv4BvAD0zc29gBqUQ15yllE6HrdwfnbJ0OicRcSClv8kPgW82OSUTKvYXpfe8oqLdLzVpt3Nm3lixfkv3SeV7eAnYt+K19srMI6vcfrM6MvM7mTkQOILSqZ2X7GBtyZb3fVMrKIW2jd5E6TTVyuC7tX22xX1eHrH9d2AMpbuC7g3Mr6htKaXTcltqS+2sAA6KiMrvKU0/IztqJZueen1Qk+XVfHYq9+s/UzoF+92URrf7lOdHM+s2p7m/44otrCtJ283AJ2mnlpmLgZuAT1XMng68NUo3VGlf/jkmSjeB6BAR50ZE1/Jo1PO8dhrmk0D3JqdiXQt8KV67Mckby9exQekau9Mj4h0R0YHSdWLbPK5m5lLgD8BXIqJjlG6UcQGla95aywOUTu9rHxGDKJ1+2pwOwB7A08ArUbo5ydbuFHktcFnFTSm6lq/DIiKC0uje9ZTez0rg/zbZ/n9HRK8o3fjmC5T+dlAKFx+PiMFR8oaIeG+TUNwqyqdbzqQUSPeK0s1P3hIR76qyiScpXTMHQLlvDS5fd/YisJ5yn4rSDWCWNNdIRLwpSs+L61DuB5dQGhX6nyrruBH4TEQcHBFdeO0av2rv4rm1ff4GSkHl6XKt/0JphG+j/6B006SB5W0PqTitd3tsqZ0/UhrJ+ny5DzdQukZzyg68RlNTgYsj4sDy6bOXNlle7Wdnoz0p/QPCKkpB8ctNlm/SX5pxIzCufGzZl9Kp6q15LJC0izPwSSqCqyh9QQWgfKrkeyhdk7WC0qlfX6UUbKB0fcyS8ulXH6d0uidZurnIjcDj5dPYDgC+DUwDZkbEC8C9lG7oQWYuAP43pZvDrKR0Q5dqn+M3ktJIwArgVuCKzPzVDrz3LfkipZGTNZSuCfppcyuV99WnKH0JXkNptGLalhrNzFsp7csp5f03n9INMCi304PSjVqS0g1g/iUiKk9R/CmlsPU4pVP5JpTbnUNppPa75ToWs4UbfbSSD1MKuw+XX+8WStfpVePblK7jXBMR36F0s5F/L7fzBKUv/l8vr3sQWw5we1K66c8aSiNXwyiNJld7w5cbKN2k5m7gL5SC5kVVbrvVfZ6ZDwPfBO6hFFj6Vb6PzLyZ0jWYPwVeoDRSvg/baUvtZObLlALeqcAzwPeAD+emNwDaUf9OqQ8+ROnmPjMojYxuPP23qs9OhR9R+rsvp9Sf7m2y/HpK1ww/GxG3NbP9BEo3oXoImEfppi8TmllPknZIbH55hSRJra880vWRVg62dS1KD1K/ODMXtnUtal55VPvazNyREUpJqnuO8EmSVCOZ+R7DXn2JiE5Rehbn7hXXnN7a1nVJUq0Y+CRJ0q4kKJ2quYbSKZ0LKV03J0mF5CmdkiRJklRQjvBJkiRJUkHt3tYFbK999903+/Tp0zj94osv8oY3vGHLG0jYT1Qd+4mqZV9RNewnqob9RNWq7Ctz5859JjPfWM12O13g69OnD3PmzGmcnjVrFg0NDW1XkHYK9hNVw36iatlXVA37iaphP1G1KvtKRDxR7Xae0ilJkiRJBWXgkyRJkqSCMvBJkiRJUkHtdNfwSZIkSWq5DRs2sGzZMtavX9/WpWgLOnbsSK9evWjfvv0Ot2HgkyRJknZBy5YtY88996RPnz5ERFuXoyYyk1WrVrFs2TIOPvjgHW7HUzolSZKkXdD69evp3r27Ya9ORQTdu3dv8QisgU+SJEnaRRn26ltr/H0MfJIkSZJUUF7DJ0mSJIlBE+7imbUvt1p7+3bpwJxxJ291nfPPP5/p06fTo0cP5s+f3zh/9erVnH322SxZsoQ+ffowdepUunXr1mq17YguXbqwdu3aNq1hRzjCJ0mSJKlVw1617Y0ePZo77rhjs/kTJ05k6NChLFq0iKFDhzJx4sRWrW1XYuCTJEmS1CZOPPFE9tlnn83m33777YwaNQqAUaNGcdttt222zoIFCzj22GN5+9vfTv/+/Vm0aBEA73vf+xg4cCBHHnkk1113XeP6Xbp04ZJLLuHII4/k3e9+N7Nnz6ahoYE3v/nNTJs2DYBJkyYxYsQIGhoaOPTQQxk/fnyzdX/961/nmGOOoX///lxxxRUAvPjii7z3ve9lwIAB9O3bl5tuuqllO6eVeEqnJEmSpLry5JNPsv/++wOw33778eSTT262zrXXXsvFF1/Mueeey8svv8yrr74KwA033MA+++zDunXrOOaYY/jABz5A9+7defHFFznppJP4+te/zvvf/37GjRvHXXfdxcMPP8yoUaMYPnw4ALNnz2b+/Pl07tyZY445hve+970MGjSo8XVnzpzJokWLmD17NpnJ8OHDufvuu3n66ac54IAD+MUvfgHAc889V+vdVBVH+CRJkiTVrYho9m6Vxx9/PF/+8pf56le/yhNPPEGnTp0A+M53vsOAAQM47rjjWLp0aePIX4cOHRg2bBgA/fr1413vehft27enX79+LFmypLHdk08+me7du9OpUyfOOOMMfv/732/yujNnzmTmzJkcddRRHH300TzyyCMsWrSIfv36cdddd3HppZfyu9/9jq5du9Zoj2wfR/gkSZIk1ZWePXuycuVK9t9/f1auXEmPHj02W+ef//mfGTx4ML/4xS847bTT+MEPfkC7du341a9+xT333EPnzp1paGhofI5d+/btG4Nju3bt2GOPPRp/f+WVVxrbbRoum05nJpdddhkf+9jHNqvp/vvvZ8aMGYwbN46hQ4dy+eWXt2xHtAJH+CRJkiTVleHDhzN58mQAJk+ezIgRIzZb5/HHH+fNb34zn/rUpxgxYgQPPfQQzz33HN26daNz58488sgj3Hvvvdv92nfddRerV69m3bp13HbbbZxwwgmbLD/llFO44YYbGu/YuXz5cp566ilWrFhB586dOe+887jkkku4//77d+Cdtz5H+CRJkiSxb5cOrf5Yhm0ZOXIks2bN4plnnqFXr16MHz+eCy64gLFjx3LWWWdx/fXX07t3b6ZOnbrZtlOnTuU///M/ad++Pfvttx//+q//yhve8AauvfZaDj/8cA477DCOO+647a772GOP5QMf+ADLli3jvPPO2+T6PYD3vOc9LFy4kOOPPx4o3Qzmxz/+MYsXL+aSSy6hXbt2tG/fnu9///vb/dq1YOCTJEmStM1n5tXCjTfe2Oz87t278+tf/3qr244dO5axY8duNv+Xv/xls+tXPkPvyiuv3OKyXr16NXtX0Mp1Lr74Yi6++OJNlr/lLW/hlFNO2WrNbcFTOiVJkiSpoBzhkyRJkiRKD4IfPXp0W5fRqhzhkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQ3rRFkiRJEnz9UHjxqdZr7w094JJFW13l/PPPZ/r06fTo0YP58+c3zl+9ejVnn302S5YsoU+fPkydOpVu3bqRmVx88cXMmDGDzp07M2nSJI4++ujWq3kHNDQ08I1vfGOz5/XVC0f4JEmSJLVu2KuyvdGjR3PHHXdsNn/ixIkMHTqURYsWMXToUCZOnAiUnrG3aNEiFi1axHXXXccnPvGJ1q25gAx8kiRJktrEiSeeyD777LPZ/Ntvv51Ro0YBMGrUqMYHod9+++18+MMfJiI47rjjePbZZ1m5cuUm27744ou8973vZcCAAfTt25ebbroJgKuuuopjjjmGvn37cuGFF5KZQGmE7jOf+QyDBg3i8MMP57777uOMM87g0EMPZdy4cQAsWbKEt73tbZx77rkcfvjhnHnmmfz973/frO6ZM2dy/PHHc/TRR/PBD36w8WHtY8eO5YgjjqB///587nOfa6W9Vx0DnyRJkqS68uSTT7L//vsDsN9++/Hkk08CsHz5cg466KDG9Xr16sXy5cs32faOO+7ggAMO4MEHH2T+/PkMGzYMgDFjxnDfffcxf/581q1bx/Tp0xu36dChA3PmzOHjH/84I0aM4JprrmH+/PlMmjSJVatWAfDoo4/yyU9+koULF7LXXnvxve99b5PXfeaZZ5gwYQK/+tWvuP/++xk0aBBXX301q1at4tZbb2XBggU89NBDjSHy9WLgkyRJklS3IoKIqHr9fv36cdddd3HppZfyu9/9jq5duwLw29/+lsGDB9OvXz9+85vfsGDBgsZthg8f3rjtkUceyf77788ee+zBm9/8ZpYuXQrAQQcdxAknnADAeeedx+9///tNXvfee+/l4Ycf5oQTTuDtb387kydP5oknnqBr16507NiRCy64gJ/97Gd07ty5Rftjexn4JEmSJNWVnj17Np6quXLlSnr06AHAgQce2BjAAJYtW8aBBx64ybZvfetbuf/+++nXrx/jxo3jqquuYv369Xzyk5/klltuYd68eXz0ox9l/fr1jdvsscceALRr167x943Tr7zyCsBmobPpdGZy8skn88ADD/DAAw/w8MMPc/3117P77rsze/ZszjzzTKZPn9444vh6MfBJkiRJqivDhw9n8uTJAEyePJkRI0Y0zv/Rj35EZnLvvffStWvXxlM/N1qxYgWdO3fmvPPO45JLLuH+++9vDHf77rsva9eu5ZZbbtnumv76179yzz33APDTn/6Ud7zjHZssP+644/if//kfFi9eDJSuJfzzn//M2rVree655zjttNP41re+xYMPPrjdr90SPpZBkiRJUukxCq39WIZtGDlyJLNmzeKZZ56hV69ejB8/ngsuuICxY8dy1llncf3119O7d2+mTp0KwGmnncaMGTM45JBD6Ny5Mz/84Q83a3PevHlccskltGvXjvbt2/P973+fvffem49+9KP07duX/fbbj2OOOWa7385hhx3GNddcw/nnn88RRxyx2R1C3/jGNzJp0iRGjhzJSy+9BMCECRPYc889GTFiBOvXryczufrqq7f7tVvCwCdJkiRpm8/Mq4Ubb7yx2fndu3fn17/+9WbzI4Jrrrlmq22ecsopnHLKKZvNnzBhAhMmTNhs/qxZsxp/b2hooKGhYbNlS5YsYffdd+fHP/7xVrc/6aSTuO+++zZbZ/bs2VutuZY8pVOSJEmSCsrAJ0mSJElb0adPH+bPn9/WZeyQmgW+iLghIp6KiGb3TJR8JyIWR8RDEXF0rWqRJEmSpF1RLUf4JgFbu+foqcCh5Z8Lge/XsBZJkiRJ2uXULPBl5t3A6q2sMgL4UZbcC+wdEftvZX1JkiRJ0naIzKxd4xF9gOmZ2beZZdOBiZn5+/L0r4FLM3NOM+teSGkUkJ49ew6cMmVK47K1a9fSpUuXmtS/PeY99BAvb9jQ1mXUlQ7t29Ovf/+2LgOon36i+lZP/eSheQ+x4WWPKZXad2hP/34eU7TzsJ+oGm3ZT7p27cohhxzSJq+t6i1evJjnnntuk74yZMiQuZk5qJrtd4rHMmTmdcB1AIMGDcqmt0qtnG4rQ4YMIa/Yq63LqCsx/nlq+Q8K26Ne+onqWz31kyFDhtB30mb/VrZLmz96vscU7VTsJ6pGW/aThQsXsueeezZON9zUwKr1q1qt/e4duzPr7FlbXef8889n+vTp9OjRY5OboqxevZqzzz6bJUuW0KdPH6ZOnUq3bt3ITC6++GJmzJhB586dmTRpEkcfXboVyOTJkxsfuzBu3DhGjRrVau9lR1x55ZV06dKFz33ucy1qp2PHjhx11FE73Ffa8i6dy4GDKqZ7ledJkiRJep21Ztirtr3Ro0dzxx13bDZ/4sSJDB06lEWLFjF06FAmTpwIwC9/+UsWLVrEokWLuO666xoffr569WrGjx/PH//4R2bPns348eNZs2ZNq76fnVVbBr5pwIfLd+s8DnguM1e2YT2SJEmSXkcnnngi++yzz2bzb7/99sYRulGjRnHbbbc1zv/whz9MRHDcccfx7LPPsnLlSu68805OPvlk9tlnH7p168bJJ5/cbJAcO3YsRxxxBP37928cefv5z3/O4MGDOeqoo3j3u9/Nk08+CZRG6EaNGsU73/lOevfuzc9+9jM+//nP069fP4YNG8aG8uVcffr0aZx/7LHHsnjx4s1e97HHHmPYsGEMHDiQd77znTzyyCMA3HzzzfTt25cBAwZw4okntsIe3VwtH8twI3APcFhELIuICyLi4xHx8fIqM4DHgcXAvwOfrFUtkiRJknYeTz75JPvvX7qf43777dcYwpYvX85BB712kmCvXr1Yvnz5FudXWrVqFbfeeisLFizgoYceYty4cQC84x3v4N577+VPf/oT55xzDl/72tcat3nsscf4zW9+w7Rp0zjvvPMYMmQI8+bNo1OnTvziF79oXK9r167MmzePMWPG8OlPf3qz93PhhRfyb//2b8ydO5dvfOMbfPKTpehz1VVXceedd/Lggw8ybdq0lu62ZtXsGr7MHLmN5Qn871q9viRJkqSdX0QQES1up2vXrnTs2JELLriA008/ndNPPx2AZcuWcfbZZ7Ny5UpefvllDj744MZtTj31VNq3b0+/fv149dVXGTas9NS5fv36sWTJksb1Ro4c2fjfz3zmM5u87tq1a/nDH/7ABz/4wcZ5L730EgAnnHACo0eP5qyzzuKMM85o8XtsTlue0ilJkiRJm+nZsycrV5au9lq5ciU9evQA4MADD2Tp0qWN6y1btowDDzxwi/Mr7b777syePZszzzyT6dOnN4a3iy66iDFjxjBv3jx+8IMfsH79+sZt9thjDwDatWtH+/btG4Nnu3bteOWVVxrXqwykTcPpP/7xD/bee28eeOCBxp+FCxcCcO211zJhwgSWLl3KwIEDWbWqda+jBAOfJEmSpDozfPhwJk+eDJTuvjlixIjG+T/60Y/ITO699166du3K/vvvzymnnMLMmTNZs2YNa9asYebMmZxyyimbtLl27Vqee+45TjvtNL71rW/x4IMPAvDcc881hsONr7m9brrppsb/Hn/88Zss22uvvTj44IO5+eabAcjMxtd+7LHHGDx4MFdddRVvfOMbNwmtrWWneCyDJEmSpNrq3rF7qz+WYVtGjhzJrFmzeOaZZ+jVqxfjx4/nggsuYOzYsZx11llcf/319O7dm6lTpwJw2mmnMWPGDA455BA6d+7MD3/4QwD22WcfvvjFL3LMMccAcPnll292M5gXXniBESNGsH79ejKTq6++GijdnOWDH/wg3bp146STTuIvf/nLdr/XNWvW0L9/f/bYYw9uvPHGzZb/5Cc/4ROf+AQTJkxgw4YNnHPOOQwYMIBLLrmERYsWkZkMHTqUAQMGbPdrb0tNH7xeC4MGDco5c157Nnu9POMmInwOXxM+h087m3rqJxHhc/ia8Dl82tnYT1SNtn4O3+GHH94mr10kffr0Yc6cOey77741aX/j36myr0RE1Q9e95ROSZIkSSooT+mUJEmSpB1UebfOeuQInyRJkrSLqpdT5dW81vj7GPgkSZKkXVDHjh1ZtWqVoa9OZSarVq2iY8eOLWrHUzolSZKkXVCvXr1YtmwZTz/9dFuXoi3o2LEjvXr1alEbBj5JkiRpF9S+fXsOPvjgti5DNeYpnZIkSZJUUAY+SZIkSSooA58kSZIkFZSBT5IkSZIKysAnSZIkSQVl4JMkSZKkgjLwSZIkSVJBGfgkSZIkqaAMfJIkSZJUUAY+SZIkSSooA58kSZIkFZSBT5IkSZIKysAnSZIkSQVl4JMkSZKkgjLwSZIkSVJBGfgkSZIkqaAMfJIkSZJUUAY+SZIkSSooA58kSZIkFZSBT5IkSZIKysAnSZIkSQVl4JMkSZKkgjLwSZIkSVJBGfgkSZIkqaAMfJIkSZJUUAY+SZIkSSooA58kSZIkFZSBT5IkSZIKysAnSZIkSQVl4JMkSZKkgjLwSZIkSVJBGfgkSZIkqaAMfJIkSZJUUAY+SZIkSSooA58kSZIkFZSBT5IkSZIKysAnSZIkSQVl4JMkSZKkgjLwSZIkSVJBGfgkSZIkqaAMfJIkSZJUUAY+SZIkSSooA58kSZIkFZSBT5IkSZIKysAnSZIkSQVl4JMkSaCHkBAAACAASURBVJKkgjLwSZIkSVJBGfgkSZIkqaAMfJIkSZJUUAY+SZIkSSooA58kSZIkFZSBT5IkSZIKysAnSZIkSQVl4JMkSZKkgjLwSZIkSVJBGfgkSZIkqaAMfJIkSZJUUAY+SZIkSSooA58kSZIkFVRNA19EDIuIRyNicUSMbWZ574j4dUQ8FBGzIqJXLeuRJEmSpF1JzQJfROwGXAOcChwBjIyII5qs9g3gR5nZH7gK+Eqt6pEkSZKkXU0tR/iOBRZn5uOZ+TIwBRjRZJ0jgN+Uf/9tM8slSZIkSTsoMrM2DUecCQzLzI+Upz8EDM7MMRXr/BT4Y2Z+OyLOAP4L2DczVzVp60LgQoCePXsOnDJlSuOytWvX0qVLl5q8h+0xd+5cBh6wW1uXUVfmrniVgQMHtnUZQP30E9W3euonc+fOpVOfTm1dRl1Zt2SdxxTtVOwnqob9RNWq7CtDhgyZm5mDqtmurQPfAcB3gYOBu4EPAH0z89kttTto0KCcM2dO4/SsWbNoaGioyXvYHhFBXrFXW5dRV2L889Sqf22veuknqm/11E8igr6T+rZ1GXVl/uj5HlO0U7GfqBr2E1Wrsq9ERNWBb/ca1rQcOKhiuld5XqPMXAGcARARXYAPbC3sSZIkSZKqV8tr+O4DDo2IgyOiA3AOMK1yhYjYNyI21nAZcEMN65EkSZKkXUrNAl9mvgKMAe4EFgJTM3NBRFwVEcPLqzUAj0bEn4GewJdqVY8kSZIk7WpqeUonmTkDmNFk3uUVv98C3FLLGiRJkiRpV1XTB69LkiRJktqOgU+SJEmSCsrAJ0mSJEkFZeCTJEmSpIIy8EmSJElSQRn4JEmSJKmgDHySJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCsrAJ0mSJEkFZeCTJEmSpIIy8EmSJElSQRn4JEmSJKmgDHySJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCsrAJ0mSJEkFZeCTJEmSpIIy8EmSJElSQRn4JEmSJKmgDHySJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCsrAJ0mSJEkFZeCTJEmSpIIy8EmSJElSQRn4JEmSJKmgDHySJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCsrAJ0mSJEkFZeCTJEmSpIIy8EmSJElSQRn4JEmSJKmgDHySJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCsrAJ0mSJEkFZeCTJEmSpIIy8EmSJElSQRn4JEmSJKmgDHySJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCsrAJ0mSJEkFZeCTJEmSpIIy8EmSJElSQRn4JEmSJKmgDHySJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCsrAJ0mSJEkFZeCTJEmSpIIy8EmSJElSQRn4JEmSJKmgDHySJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCsrAJ0mSJEkFZeCTJEmSpIKqaeCLiGER8WhELI6Isc0sf1NE/DYi/hQRD0XEabWsR5IkSZJ2JTULfBGxG3ANcCpwBDAyIo5osto4YGpmHgWcA3yvVvVIkiRJ0q6mliN8xwKLM/PxzHwZmAKMaLJOAnuVf+8KrKhhPZIkSZK0S9m9hm0fCCytmF4GDG6yzpXAzIi4CHgD8O4a1iNJkiRJu5TIzNo0HHEmMCwzP1Ke/hAwODPHVKzzf8o1fDMijgeuB/pm5j+atHUhcCFAz549B06ZMqVx2dq1a+nSpUtN3sP2mHv/3NJ4pV4T1M0+6dWrF8uWLWvrMoiAGn3kdmrtAo46emBbl1E3xxOAuXPn0qlPp7Yuo66sX7KuXg4pdXNM6dC+Pf3692/rMrQF9XRMUf2yn6halX1lyJAhczNzUDXb1TLwHQ9cmZmnlKcvA8jMr1Sss4BSKFxann4cOC4zn9pSu4MGDco5c+Y0Ts+aNYuGhoaavIftERH0ndS3rcuoK/NHzyev2GvbK74OZh02noZHr2jrMojxz9fNPqknMf55anUs2h71cjwBjynN8ZiyuXr57Kh59XRMUf2yn6halX0lIqoOfLW8hu8+4NCIODgiOlC6Kcu0Juv8FRgKEBGHAx2Bp2tYkyRJkiTtMmoW+DLzFWAMcCewkNLdOBdExFURMby82meBj0bEg8CNwOj0nyolSZIkqVXU8qYtZOYMYEaTeZdX/P4wcEIta5AkSZKkXVVNH7wuSZIkSWo7Bj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBVXTwBcRwyLi0YhYHBFjm1n+rYh4oPzz54h4tpb1SJIkSdKuZPdaNRwRuwHXACcDy4D7ImJaZj68cZ3M/EzF+hcBR9WqHkmSJEna1dRyhO9YYHFmPp6ZLwNTgBFbWX8kcGMN65EkSZKkXUpkZm0ajjgTGJaZHylPfwgYnJljmlm3N3Av0CszX21m+YXAhQA9e/YcOGXKlMZla9eupUuXLjV5D9tj7ty5dOrTqa3LqCvrlqxj4AG7tXUZAKzd4wC6vLSirctg7opX62af1JO5K15l4MCBbV1G3RxPwGNKczymbK5ePjtqXj0dU1S/7CeqVmVfGTJkyNzMHFTNdvUS+C6lFPYu2la7gwYNyjlz5jROz5o1i4aGhlare0dFBH0n9W3rMurK/NHzySv2ausyAJh12HgaHr2ircsgxj9fN/uknsT456nVsWh71MvxBDymNMdjyubq5bOj5tXTMUX1y36ialX2lYioOvDV8pTO5cBBFdO9yvOacw6ezilJkiRJraqWge8+4NCIODgiOlAKddOarhQRbwO6AffUsBZJkiRJ2uXULPBl5ivAGOBOYCEwNTMXRMRVETG8YtVzgCnpOSmSJEmS1Kpq9lgGgMycAcxoMu/yJtNX1rIGSZIkSdpV1fTB65IkSZKktmPgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQBj5JkiRJKigDnyRJkiQVlIFPkiRJkgrKwCdJkiRJBWXgkyRJkqSCMvBJkiRJUkEZ+CRJkiSpoAx8kiRJklRQNQ18ETEsIh6NiMURMXYL65wVEQ9HxIKI+Gkt65EkSZKkXcnutWo4InYDrgFOBpYB90XEtMx8uGKdQ4HLgBMyc01E9KhVPZIkSZK0q6nlCN+xwOLMfDwzXwamACOarPNR4JrMXAOQmU/VsB5JkiRJ2qVEZtam4YgzgWGZ+ZHy9IeAwZk5pmKd24A/AycAuwFXZuYdzbR1IXAhQM+ePQdOmTKlcdnatWvp0qVLTd7D9pg7dy6d+nRq6zLqyrol64Ha9K/t1atXL5YtW9bWZQDBwAO8dLapuSteZeDAgW1dRt0cTwDunzu3Tj49dSQCavT/rO1VV8eUgUe3dRHagno6psx76CFe3rChrcuoKx3at6df//5tXYb9pM7VSz+BTfvKkCFD5mbmoGq2a+vANx3YAJwF9ALuBvpl5rNbanfQoEE5Z86cxulZs2bR0NBQk/ewPSKCvpP6tnUZdWX+6Pn0vnR6W5cBwGf7vcI359XsDOaqPfHV08kr9mrrMupOjH+eWh2Ltke9HE+gdEyxr2wqxj/vMaWJJ756el18dtQ8jyn1zf/3bM5+srl66SewaV+JiKoDXy2HGpYDB1VM9yrPq7QMmJaZGzLzL5RG+w6tYU2SJEmStMuoZeC7Dzg0Ig6OiA7AOcC0JuvcBjQARMS+wFuBx2tYkyRJkiTtMmoW+DLzFWAMcCewEJiamQsi4qqIGF5e7U5gVUQ8DPwWuCQzV9WqJkmSJEnaldT0AoTMnAHMaDLv8orfE/g/5R9JkiRJUivydoGSJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCsrAJ0mSJEkFZeCTJEmSpIIy8EmSJElSQRn4JEmSJKmgDHySJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCsrAJ0mSJEkFZeCTJEmSpIIy8EmSJElSQRn4JEmSJKmgDHySJEmSVFAGPkmSJEkqKAOfJEmSJBWUgU+SJEmSCmqbgS9KzouIy8vTb4qIY2tfmiRJkiSpJaoZ4fsecDwwsjz9AnBNzSqSJEmSJLWK3atYZ3BmHh0RfwLIzDUR0aHGdUmSJEmSWqiaEb4NEbEbkAAR8UbgHzWtSpIkSZLUYtUEvu8AtwI9IuJLwO+Br9S0KkmSJElSi23zlM7M/ElEzAWGAgG8LzMX1rwySZIkSVKLbDPwRcR/ZuaHgEeamSdJkiRJqlPVnNJ5ZOVE+Xq+gbUpR5IkSZLUWrYY+CLisoh4AegfEc9HxAvl6aeA21+3CiVJkiRJO2SLgS8zv5KZewJfz8y9MnPP8k/3zLzsdaxRkiRJkrQDqrlpy2UR0Q04FOhYMf/uWhYmSZIkSWqZam7a8hHgYqAX8ABwHHAPcFJtS5MkSZIktUQ1N225GDgGeCIzhwBHAc/WtCpJkiRJUotVE/jWZ+Z6gIjYIzMfAQ6rbVmSJEmSpJba5imdwLKI2Bu4DbgrItYAT9S2LEmSJElSS1Vz05b3l3+9MiJ+C3QF7qhpVZIkSZKkFttq4Cs/ZH1BZr4NIDP/+3WpSpIkSZLUYlu9hi8zXwUejYg3vU71SJIkSZJaSTXX8HUDFkTEbODFjTMzc3jNqpIkSZIktVg1ge+LNa9CkiRJktTqqrlpi9ftSZIkSdJOqJrn8EmSJEmSdkIGPkmSJEkqqG0Gvoj4p4gwGEqSJEnSTqaaIHc2sCgivhYRb6t1QZIkSZKk1rHNwJeZ5wFHAY8BkyLinoi4MCL2rHl1kiRJkqQdVtWpmpn5PHALMAXYH3g/cH9EXFTD2iRJkiRJLVDNNXwjIuJWYBbQHjg2M08FBgCfrW15kiRJkqQdVc2D198PfCsz766cmZl/j4gLalOWJEmSJKmltjrCFxG7Ab2bhr2NMvPXNalKkiRJktRiWw18mfkq8I+I6Po61SNJkiRJaiXVnNK5FpgXEXcBL26cmZmfqllVkiRJkqQWqybw/az8I0mSJEnaiWwz8GXm5IjoBLwpMx99HWqSJEmSJLWCah7L8E/AA8Ad5em3R8S0WhcmSZIkSWqZah68fiVwLPAsQGY+ALy5hjVJkiRJklpBNYFvQ2Y+12TeP2pRjCRJkiSp9VRz05YFEfHPwG4RcSjwKeAPtS1LkiRJktRS1YzwXQQcCbwE/BR4Dvh0LYuSJEmSJLVcNSN8b8vMLwBfqHUxkiRJkqTWU80I3zcjYmFE/N+I6FvziiRJkiRJrWKbgS8zhwBDgKeBH0TEvIgYV/PKJEmSJEktUs0IH5n5t8z8DvBxSs/ku7ymVUmSJEmSWqyaB68fHhFXRsR84N8o3aGzV80rkyRJkiS1SDU3bbkBmAK8JzNX1LgeSZIkSVIr2Wbgy8zjI6ID8NaI2Ad4NDM31L40SZIkSVJLbDPwRcS7gB8BS4AADoqIUZl5d41rkyRJkiS1QDWndF5N6XTORwEi4q3AjcDAWhYmSZIkSWqZau7S2X5j2APIzD8D7atpPCKGRcSjEbE4IsY2s3x0RDwdEQ+Ufz5SfemSJEmSpK2pZoRvTkT8B/Dj8vS5wJxtbRQRuwHXACcDy4D7ImJaZj7cZNWbMnPMdtQsSZIkSapCNSN8nwAeBj5V/nm4PG9bjgUWZ+bjmfkypTt9jtjRQiVJkiRJ26eaEb7dgW9n5tXQOHK3RxXbHQgsrZheBgxuZr0PRMSJwJ+Bz2Tm0mbWkSRJkiRtp8jMra8QcS/w7sxcW57uAszMzP+1je3OBIZl5kfK0x8CBleevhkR3YG1mflSRHwMODszT2qmrQuBCwF69uw5cMqUKY3L1q5dS5cuXap6s7U0d+5cOvXp1NZl1JV1S9bRYb9D2roMAHp2gifXtXUV8PLfFjPwgN3auoy6M3fFqwwc2Pb3gaqX4wmUjin2lU3NXfGqx5QmXv7b4rr47Kh5HlPqm//v2Zz9ZHP10k9g074yZMiQuZk5qJrtqgl8D2Tm27c1r5ntjgeuzMxTytOXAWTmV7aw/m7A6szsurV2Bw0alHPmvHYJ4axZs2hoaNjqe3g9RAR9J/Vt6zLqyvzR8+l96fS2LgOAz/Z7hW/Oq2ZAu7ae+Orp5BV7tXUZdSfGP8+2jkWvh3o5nkDpmGJf2VSMf95jShNPfPX0uvjsqHkeU+qb/+/ZnP1kc/XST2DTvhIRVQe+aq7hezEijt44EREDgWr+XfM+4NCIOLj84PZzgGmVK0TE/hWTw4GFVbQrSZIkSapCNf88+Wng5ohYQenB6/sBZ29ro8x8JSLGAHcCuwE3ZOaCiLgKmJOZ04BPRcRw4BVgNTB6x96GJEmSJKmpbQa+zLwvIt4GHFae9Whmbqim8cycAcxoMu/yit8vAy6rvlxJkiRJUrW2eUpnRHQGLgUuzsz5QJ+IOL3mlUmSJEmSWqSaa/h+CLwMHF+eXg5MqFlFkiRJkqRWUU3ge0tmfg3YAJCZf6d0LZ8kSZIkqY5VE/hejohOQAJExFuAl2palSRJkiSpxf5/e/cfbHld33f89c4iSrP+mMbMqlkKzEidIeCvu4Kp02QxtsGGQqbSCSYx0lFJM93WjqbRNlMJJv9gxrRppM0P42DSpIs/MumWkhJb3bHOVMpeNLpImGwMNIBoYgx0k6245N0/7oHcvd6Fs8jZ8+VzH4+ZHe853+89533vfM7H++Scc+88v6XzqiT/LcnpVfXrSV4Rv00TAABg8h41+Kqqkvxekn+Q5OVZeynnm7v7T07CbAAAAHwDHjX4urur6sbuPi/Jfz1JMwEAAPAEmOc9fLdW1csWPgkAAABPqHnew3dBkh+sqruS/HnWXtbZ3f3ChU4GAADAN2Se4PuehU8BAADAE+4xg6+77zoZgwAAAPDEmuc9fAAAADwJCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBCT4AAIBBLTT4quqiqrqjqg5V1dsf5bzXVFVX1a5FzgMAALCVLCz4qmpbkmuTvDrJOUleW1XnbHLe05O8OcnNi5oFAABgK1rkM3znJznU3Z/v7geT7E1y6Sbn/VSSa5L8vwXOAgAAsOVUdy/mhqsuS3JRd79xdvl1SS7o7j3rznlpkp/o7tdU1f4kP9bdBza5rSuTXJkkO3bsWNm7d+8jxw4fPpzt27cv5Gs4EaurqzntzNOWPcakHLnzSE59zvOXPUaSZMdpyRePLHuK5MH7/iDJYh5zT26VlZWXLnuIyewnydqesvK8bcseY1JW733InrLBg/cdWvYIk/NNlbzkpSvLHiOJPWXqVu99KCsry18rk1ont676MWWjSlYmuKdceOGFq90919vhlhZ8VfVNST6a5IruvvPRgm+9Xbt29YEDf3XK/v37s3v37oV8DSeiqnLudecue4xJOXjFwZzxthuWPUaS5K3nHc27P3vKssfIXddcPJnvyZTcdc3FWdRedCKmsp8ka3tKX/WMZY8xKXX1A5N5/ExpT7FOjlVXPzCJ/SSxp0zdVNbK1NaJn2ePdfCKg5NYJ8mxa6Wq5g6+Rb6k854kp6+7vHN23cOenuTcJPur6s4kL0+yzy9uAQAAeGIsMvhuSXJ2VZ1VVacmuTzJvocPdvf93f3s7j6zu89M8skklzzWM3wAAADMZ2HB191Hk+xJclOS25N8oLtvq6p3VtUli7pfAAAA1iz0DQjdfWOSGzdc947jnLt7kbMAAABsNQv9w+sAAAAsj+ADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAY1EKDr6ouqqo7qupQVb19k+P/uKo+W1WfrqpPVNU5i5wHAABgK1lY8FXVtiTXJnl1knOSvHaToPuN7j6vu1+c5F1JfnZR8wAAAGw1i3yG7/wkh7r78939YJK9SS5df0J3P7Du4jcn6QXOAwAAsKVU92Iaq6ouS3JRd79xdvl1SS7o7j0bzvsnSd6S5NQkr+zu39/ktq5McmWS7NixY2Xv3r2PHDt8+HC2b9++kK/hRKyurua0M09b9hiTcuTOIzn1Oc9f9hhJkh2nJV88suwpkgfvOzSZ78mUPHjfoaysrCx7jMnsJ8nanrLyvG3LHmNSVu99aDKPnyntKdbJsVbvfWgS+0liT5m6qayVqa0TP88e68idRyaxTpJj18qFF1642t275vm8pQffuvN/IMn3dPfrH+12d+3a1QcOHHjk8v79+7N79+4nbO7Hq6py7nXnLnuMSTl4xcGc8bYblj1GkuSt5x3Nuz97yrLHyF3XXDyZ78mU3HXNxVnUXnQiprKfJGt7Sl/1jGWPMSl19QOTefxMaU+xTo5VVz8wif0ksadM3VTWytTWiZ9nj3XwioOTWCfJsWulquYOvkW+pPOeJKevu7xzdt3x7E3yfQucBwAAYEtZZPDdkuTsqjqrqk5NcnmSfetPqKqz11383iRf93JOAAAAHp+FvR6lu49W1Z4kNyXZluR93X1bVb0zyYHu3pdkT1W9KsnXknwlyaO+nBMAAID5LfQNCN19Y5IbN1z3jnUfv3mR9w8AALCVLfQPrwMAALA8gg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AfYeLRAAAEQVJREFUAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQgg8AAGBQCw2+qrqoqu6oqkNV9fZNjr+lqj5XVZ+pqv9RVWcsch4AAICtZGHBV1Xbklyb5NVJzkny2qo6Z8Npn0qyq7tfmORDSd61qHkAAAC2mkU+w3d+kkPd/fnufjDJ3iSXrj+huz/W3X8xu/jJJDsXOA8AAMCWUt29mBuuuizJRd39xtnl1yW5oLv3HOf89yS5r7t/epNjVya5Mkl27Nixsnfv3keOHT58ONu3b1/AV3BiVldvTbKY7+WT2anPef6yR0iS7Dgt+eKRZU+RPHjfocl8T6bkwfsOZWVlZdljTGY/SewpxzOVx8+U9pSV521b9hiTsnrvQ5PYT5KJ7Sm3rtpSNqhKFvRj8AnZuXNn7r777mWPMVOxUDaqrKy8dNlDJDl2T7nwwgtXu3vXPJ83ieCrqh9KsifJd3X3Vx/tdnft2tUHDhx45PL+/fuze/fuJ3L0x6Wqcsbbblj2GJNy1zUXT+Z78tbzjubdnz1l2WNM6nsyJXddc3EWtRediKnsJ4k9ZTNTevxMaU/pq56x7DEmpa5+YBL7STK9PeXc685d9hiTcvCKg5N4/Ox/wdXZfcdVyx4jydrjZyr77FRM5WeU5Ng9parmDr5F/r/VPUlOX3d55+y6Y1TVq5L8ROaIPQAAAOa3yPfw3ZLk7Ko6q6pOTXJ5kn3rT6iqlyT5xSSXdPeXFjgLAADAlrOw4Ovuo1l7meZNSW5P8oHuvq2q3llVl8xO+5kk25N8sKo+XVX7jnNzAAAAnKCFvgGhu29McuOG696x7uNXLfL+AQAAtrKF/uF1AAAAlkfwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADErwAQAADGqhwVdVF1XVHVV1qKrevsnx76yqW6vqaFVdtshZAAAAtpqFBV9VbUtybZJXJzknyWur6pwNp/2fJFck+Y1FzQEAALBVnbLA2z4/yaHu/nySVNXeJJcm+dzDJ3T3nbNjf7nAOQAAALak6u7F3PDaSzQv6u43zi6/LskF3b1nk3OvS3JDd3/oOLd1ZZIrk2THjh0re/fufeTY4cOHs3379if+CzhBq6urOfU5z1/2GJPy4H2HJvM92XFa8sUjy55iWt+TKXnwvkNZWVlZ9hiT2U8Se8pmpvT4mdKesvK8bcseY1JW731oEvtJMr095bQzT1v2GJNy5M4jk3j8HH7q87L9q/cue4wka4+fqeyzUzGVn1GSY/eUCy+8cLW7d83zeU+K4Ftv165dfeDAgUcu79+/P7t3736ixn7cqipnvO2GZY8xKXddc/FkvidvPe9o3v3ZRT6hPZ8pfU+m5K5rLs6i9qITMZX9JLGnbGZKj58p7Sl91TOWPcak1NUPTGI/Saa3p5x73bnLHmNSDl5xcBKPn/0vuDq777hq2WMkWXv8TGWfnYqp/IySHLunVNXcwbfIX9pyT5LT113eObsOAACAk2CRwXdLkrOr6qyqOjXJ5Un2LfD+AAAAWGdhwdfdR5PsSXJTktuTfKC7b6uqd1bVJUlSVS+rqruT/MMkv1hVty1qHgAAgK1moW9A6O4bk9y44bp3rPv4lqy91BMAAIAn2EL/8DoAAADLI/gAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGJfgAAAAGtdDgq6qLquqOqjpUVW/f5PhTq+r62fGbq+rMRc4DAACwlSws+KpqW5Jrk7w6yTlJXltV52w47Q1JvtLdz0/yb5Jcs6h5AAAAtppFPsN3fpJD3f357n4wyd4kl24459Ik7599/KEk311VtcCZAAAAtozq7sXccNVlSS7q7jfOLr8uyQXdvWfdOQdn59w9u/wHs3P+ZMNtXZnkytnFFyS5Y93hZyc55nzYhHXCPKwT5mWtMA/rhHlYJ8xr/Vo5o7u/dZ5POmVx8zxxuvuXkvzSZseq6kB37zrJI/EkY50wD+uEeVkrzMM6YR7WCfN6vGtlkS/pvCfJ6esu75xdt+k5VXVKkmcm+fICZwIAANgyFhl8tyQ5u6rOqqpTk1yeZN+Gc/Ylef3s48uSfLQX9RpTAACALWZhL+ns7qNVtSfJTUm2JXlfd99WVe9McqC79yX5lSS/VlWHkvxp1qLwRG36Uk/YwDphHtYJ87JWmId1wjysE+b1uNbKwn5pCwAAAMu10D+8DgAAwPIIPgAAgEE9KYKvqt5XVV+a/d2+zY7vrqr7q+rTs3/vONkzsnxVdXpVfayqPldVt1XVmzc5p6rq31XVoar6TFW9dBmzsjxzrhN7yhZXVU+rqv9dVb87WydXb3LOU6vq+tl+cnNVnXnyJ2XZ5lwrV1TVH6/bU964jFlZvqraVlWfqqobNjlmTyHJY66TE95PnhR/hy/JdUnek+RXH+Wc/9ndF5+ccZioo0ne2t23VtXTk6xW1Ue6+3Prznl1krNn/y5I8h9m/8vWMc86SewpW91Xk7yyuw9X1VOSfKKqfru7P7nunDck+Up3P7+qLk9yTZLvX8awLNU8ayVJru/uPUuYj2l5c5Lbkzxjk2P2FB72aOskOcH95EnxDF93fzxrv8UTjqu7v9Ddt84+/r9Ze6B824bTLk3yq73mk0meVVXPPcmjskRzrhO2uNkecXh28Smzfxt/y9mlSd4/+/hDSb67quokjchEzLlWIFW1M8n3JnnvcU6xpzDPOjlhT4rgm9N3zF5O8dtV9e3LHoblmr0M4iVJbt5w6NuS/NG6y3fHD/tb1qOsk8SesuXNXlLz6SRfSvKR7j7uftLdR5Pcn+RbTu6UTMEcayVJXjN7K8GHqur0kzwi0/Bvk/x4kr88znF7Csljr5PkBPeTUYLv1iRndPeLkvx8kt9a8jwsUVVtT/LhJP+8ux9Y9jxM02OsE3sK6e6HuvvFSXYmOb+qzl32TEzTHGvlvyQ5s7tfmOQj+atncdgiquriJF/q7tVlz8J0zblOTng/GSL4uvuBh19O0d03JnlKVT17yWOxBLP3T3w4ya93929ucso9Sdb/l5Cds+vYQh5rndhTWK+7/yzJx5JctOHQI/tJVZ2S5JlJvnxyp2NKjrdWuvvL3f3V2cX3Jlk52bOxdK9IcklV3Zlkb5JXVtV/3HCOPYXHXCePZz8ZIviq6jkPv8a5qs7P2tflAbLFzNbAryS5vbt/9jin7Uvyw7Pf1vnyJPd39xdO2pAs3TzrxJ5CVX1rVT1r9vFpSf5Okt/bcNq+JK+ffXxZko92t/dubTHzrJUN7xW/JGvvHWYL6e5/2d07u/vMJJdnbb/4oQ2n2VO2uHnWyePZT54Uv6Wzqv5Tkt1Jnl1Vdye5Kmtvik53/0LWHhQ/WlVHkxxJcrkHyJb0iiSvS/LZ2XspkuRfJfkbySNr5cYkfy/JoSR/keQfLWFOlmuedWJP4blJ3l9V27IW/B/o7huq6p1JDnT3vqz9h4Nfq6pDWfvFYpcvb1yWaJ618s+q6pKs/ZbgP01yxdKmZVLsKczjG91Pys8wAAAAYxriJZ0AAAB8PcEHAAAwKMEHAAAwKMEHAAAwKMEHAAAwKMEHAHOqqkuq6u2Pcc5PVtWPbXL9mVV1cHHTAcDXe1L8HT4AWLaqOmX2N5D2LXsWAJiXZ/gAeNKbPXt2e1X9clXdVlW/U1WnbTjnmVV1V1V90+zyN1fVH1XVU6rqTVV1S1X9blV9uKr+2uyc66rqF6rq5iTvqqorquo9s2N/v6purqpPVdV/r6od6+7uRVX1v6rq96vqTZvMu62qfmZ2n5+pqh+ZXf/cqvp4VX26qg5W1d9e1PcMgK1B8AEwirOTXNvd357kz5K8Zv3B7r4/yaeTfNfsqouT3NTdX0vym939su5+UZLbk7xh3afuTPK3uvstG+7vE0le3t0vSbI3yY+vO/bCJK9M8h1J3lFVz9vwuW9Icn93vyzJy5K8qarOSvIDs5lenORFs3kB4HHzkk4ARvGH3f1wIK0mOXOTc65P8v1JPpbk8iT/fnb9uVX100melWR7kpvWfc4Hu/uhTW5rZ5Lrq+q5SU5N8ofrjv3n7j6S5EhVfSzJ+Tk23v5ukhdW1WWzy8/MWrDekuR9VfWUJL+17usBgMfFM3wAjOKr6z5+KJv/R819SS6qqr+eZCXJR2fXX5dkT3efl+TqJE9b9zl/fpz7+/kk75l9zo9s+JzecO7Gy5Xkn3b3i2f/zuru3+nujyf5ziT3JLmuqn74OPcNAHMRfABsGd19OGvPov1ckhvWPXP39CRfmD2z9oNz3twzsxZmSfL6DccuraqnVdW3JNk9u8/1bkryo7P7S1X9zdl7Cs9I8sXu/uUk703y0vm/OgD4el7SCcBWc32SD2YtxB72r5PcnOSPZ//79Dlu5yeTfLCqvpK1ZwrPWnfsM1l72eizk/xUd99bVWeuO/7erL3k9Naqqtn9ft9spn9RVV9LcjiJZ/gA+IZU98ZXmQAAADACL+kEAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAYlOADAAAY1P8Hx6ABD0SFZnMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "barwidth = 1/4\n",
    "a = np.arange(-1, 2) / 4\n",
    "colors = ['C0', 'C1', 'C2']\n",
    "ecolors = ['C3', 'C4', 'C5']\n",
    "# colors = [1, 2, 3]\n",
    "patches = []        \n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(3):\n",
    "    patches.append(mpatches.Patch(color=colors[i], label=str(10**(i + 1)) + \" samples\"))\n",
    "# n_variables = 4\n",
    "# # for n_variables in range(2, 5):\n",
    "# for powers_\n",
    "# for m_samples in [1000, 100, 10]:\n",
    "#     plt.bar(a + n_variables, results[m_samples][n_variables], width=1/4, yerr=1.96 * se[m_samples][n_variables],\n",
    "#             color=colors[m_samples], edgecolor = 'black', capsize=4, alpha=0.5)   \n",
    "\n",
    "\n",
    "for powers_type in range(3):    \n",
    "    heights_a = [pd.DataFrame(results).loc[:, 10][i][powers_type] for i in (2, 3, 4)]\n",
    "    heights_b = [pd.DataFrame(results).loc[:, 100][i][powers_type] for i in (2, 3, 4)]\n",
    "    heights_c = [pd.DataFrame(results).loc[:, 1000][i][powers_type] for i in (2, 3, 4)]\n",
    "    \n",
    "    se_a = [pd.DataFrame(se).loc[:, 10][i][powers_type] for i in (2, 3, 4)]\n",
    "    se_b = [pd.DataFrame(se).loc[:, 100][i][powers_type] for i in (2, 3, 4)]\n",
    "    se_c = [pd.DataFrame(se).loc[:, 1000][i][powers_type] for i in (2, 3, 4)]\n",
    "    \n",
    "\n",
    "    position = np.arange(2, 5) + (powers_type - 1) / 4\n",
    "\n",
    "    for x, ha, hb, hc, sea, seb, sec in zip(position, heights_a, heights_b, heights_c,\n",
    "                                            se_a, se_b, se_c):\n",
    "        for i, (h, serr, c, ec) in enumerate(sorted(zip([ha, hb, hc], [sea, seb, sec], colors, ecolors))):\n",
    "            plt.bar(x, h,  color=c,  zorder=-i, width=barwidth, edgecolor = 'black')\n",
    "\n",
    "plt.xlabel('n variables')\n",
    "plt.ylabel('recovery rate')\n",
    "# plt.xticks([2 - 0.25, 2, 2 + 0.25, \n",
    "#            3 - 0.25, 3, 3 + 0.25, \n",
    "#            4 - 0.25, 4, 4 + 0.25], \n",
    "#            [\"integer powers\", \"half-integer\\n powers\\n2\", \"powers with \\ndenominator 12\",\n",
    "#            \"integer powers\", \"half-integer\\n powers\\n3\", \"powers with \\ndenominator 12\"\n",
    "#            \"integer powers\", \"half-integer\\n powers\\n4\", \"powers with \\ndenominator 12\"])\n",
    "plt.yticks(np.linspace(0, 1, 11))\n",
    "plt.grid()\n",
    "plt.title(\"NestedFormula experiments, 5 for each configuration\")\n",
    "plt.legend(handles=patches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "barwidth = 1/4\n",
    "a = np.arange(-1, 2) / 4\n",
    "colors = ['C0', 'C1', 'C2']\n",
    "ecolors = ['C3', 'C4', 'C5']\n",
    "# colors = [1, 2, 3]\n",
    "patches = []        \n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(3):\n",
    "    patches.append(mpatches.Patch(color=colors[i], label=str(10**(i + 1)) + \" samples\"))\n",
    "    patches.append(mpatches.Patch(color=ecolors[i], label=str(10**(i + 1)) + \" samples 95% confidence interval\"))\n",
    "# n_variables = 4\n",
    "# # for n_variables in range(2, 5):\n",
    "# for powers_\n",
    "# for m_samples in [1000, 100, 10]:\n",
    "#     plt.bar(a + n_variables, results[m_samples][n_variables], width=1/4, yerr=1.96 * se[m_samples][n_variables],\n",
    "#             color=colors[m_samples], edgecolor = 'black', capsize=4, alpha=0.5)   \n",
    "\n",
    "\n",
    "for powers_type in range(3):    \n",
    "    heights_a = [pd.DataFrame(results).loc[:, 10][i][powers_type] for i in (2, 3, 4)]\n",
    "    heights_b = [pd.DataFrame(results).loc[:, 100][i][powers_type] for i in (2, 3, 4)]\n",
    "    heights_c = [pd.DataFrame(results).loc[:, 1000][i][powers_type] for i in (2, 3, 4)]\n",
    "    \n",
    "    se_a = [pd.DataFrame(se).loc[:, 10][i][powers_type] for i in (2, 3, 4)]\n",
    "    se_b = [pd.DataFrame(se).loc[:, 100][i][powers_type] for i in (2, 3, 4)]\n",
    "    se_c = [pd.DataFrame(se).loc[:, 1000][i][powers_type] for i in (2, 3, 4)]\n",
    "    \n",
    "\n",
    "    position = np.arange(2, 5) + (powers_type - 1) / 4\n",
    "\n",
    "    for x, ha, hb, hc, sea, seb, sec in zip(position, heights_a, heights_b, heights_c,\n",
    "                                            se_a, se_b, se_c):\n",
    "        for i, (h, serr, c, ec) in enumerate(sorted(zip([ha, hb, hc], [sea, seb, sec], colors, ecolors))):\n",
    "            plt.bar(x, h, yerr=1.96 * serr, capsize=4, color=c, ecolor=ec, zorder=-i, width=barwidth, edgecolor = 'black')\n",
    "\n",
    "plt.xlabel('n variables')\n",
    "plt.ylabel('recovery rate')\n",
    "plt.xticks([2, 3, 4])\n",
    "plt.yticks(np.linspace(0, 1, 11))\n",
    "plt.grid()\n",
    "plt.title(\"NestedFormula experiments, 5 for each configuration, with 95% confidence intervals\")\n",
    "plt.legend(handles=patches)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "demonstration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
