{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import dirname\n",
    "current_location = sys.path[0]\n",
    "sys.path.append(dirname(dirname(current_location)) + \"/lib\")\n",
    "sys.path.append(dirname(current_location) + \"/lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.nn import MSELoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import time\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "import pickle\n",
    "import nested_formula\n",
    "import explore\n",
    "import auxiliary_functions\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear combination of 3 variables and bias with standard-normally distributed coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0449, current formula \\left(-11.424x_1^{-0.027} + 10.731x_2^{-0.015} + 0.915x_3^{1.071} + 0.819\\right)\n",
      "  Finished run #1, loss 0.04426300898194313, best loss 0.04426300898194313\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.011057988740503788, best loss 0.011057988740503788\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 7.58524076882594e-10, best loss 7.58524076882594e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "38 seconds passed from the start, the iteration took 38 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.276x_{1}^{1}-0.65x_{2}^{1}+0.9x_{3}^{1}-0.344$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.276x_1^{1.000}-0.650x_2^{1.000} + 0.900x_3^{1.000}-0.344\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.2181853367313319e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.01343916542828083, best loss 0.01343916542828083\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0015267726266756654, best loss 0.0015267726266756654\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.013873125426471233, best loss 0.0015267726266756654\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.011437230743467808, best loss 0.0015267726266756654\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 0.00028848694637417793, best loss 0.00028848694637417793\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 0.011361205950379372, best loss 0.00028848694637417793\n",
      "  Initialization #7\n",
      "  Finished run #7, loss 0.012482903897762299, best loss 0.00028848694637417793\n",
      "  Initialization #8\n",
      "    Epoch 5000, current loss 0.00934, current formula \\left(5.719x_1^{-0.029}-0.210x_2^{1.102} + 1.330x_3^{-0.024}-6.305\\right)\n",
      "  Finished run #8, loss 0.00918937474489212, best loss 0.00028848694637417793\n",
      "  Initialization #9\n",
      "  Finished run #9, loss 0.011318389326334, best loss 0.00028848694637417793\n",
      "  Initialization #10\n",
      "  Finished run #10, loss 0.00027836591470986605, best loss 0.00027836591470986605\n",
      "1 minutes 34 seconds passed from the start, the iteration took 56 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.675x_{1}^{1}-0.208x_{2}^{1}-0.127x_{3}^{1}+1.352$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.674x_1^{0.997}-0.211x_2^{0.978}-1.659x_3^{0.021} + 2.916\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.8217513293213506\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0004741509328596294, best loss 0.0004741509328596294\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.00046852396917529404, best loss 0.00046852396917529404\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.000554167025256902, best loss 0.00046852396917529404\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.823388856043607e-09, best loss 2.823388856043607e-09\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 49 seconds passed from the start, the iteration took 15 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.58x_{1}^{1}-1.201x_{2}^{1}+0.161x_{3}^{1}-1.495$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.580x_1^{1.000}-1.201x_2^{1.000} + 0.161x_3^{1.002}-1.495\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.0111635002463e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.996097672879898e-10, best loss 7.996097672879898e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 51 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.571x_{1}^{1}-0.64x_{2}^{1}-0.373x_{3}^{1}+0.536$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.571x_1^{1.000}-0.640x_2^{1.000}-0.373x_3^{1.000} + 0.536\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.000738325021205e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.119, current formula \\left(0.060x_1^{5.802}-9.050x_2^{-0.051}-1.181x_3^{0.991} + 9.822\\right)\n",
      "    Epoch 10000, current loss 0.114, current formula \\left(0.059x_1^{5.951}-14.402x_2^{-0.034}-1.188x_3^{0.977} + 15.199\\right)\n",
      "  Finished run #1, loss 0.11366713047027588, best loss 0.11366713047027588\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.2134427624109776e-08, best loss 2.2134427624109776e-08\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 32 seconds passed from the start, the iteration took 41 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.065x_{1}^{1}+2.196x_{2}^{1}-1.213x_{3}^{1}-0.766$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.065x_1^{0.993} + 2.195x_2^{1.000}-1.213x_3^{0.999}-0.765\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.7070178810246794e-06\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #6----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.651099422796733e-09, best loss 3.651099422796733e-09\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 34 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.423x_{1}^{1}-0.364x_{2}^{1}-0.849x_{3}^{1}-0.66$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.424x_1^{1.000}-0.365x_2^{0.999}-0.849x_3^{1.000}-0.660\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.073016812444556e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #7----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.012222030200064182, best loss 0.012222030200064182\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.1197285704488422e-08, best loss 2.1197285704488422e-08\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 38 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.847x_{1}^{1}+0.59x_{2}^{1}+0.205x_{3}^{1}+1.124$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.847x_1^{0.999} + 0.590x_2^{0.999} + 0.206x_3^{0.996} + 1.123\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.166313272906507e-06\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #8----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 5.693628679637186e-09, best loss 5.693628679637186e-09\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 40 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.68x_{1}^{1}+0.608x_{2}^{1}-0.857x_{3}^{1}+0.342$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.679x_1^{1.001} + 0.608x_2^{0.999}-0.857x_3^{1.001} + 0.341\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.9255488898599943e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #9----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0002396345662418753, best loss 0.0002396345662418753\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0001678973058005795, best loss 0.0001678973058005795\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.002253648592159152, best loss 0.0001678973058005795\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0036190208047628403, best loss 0.0001678973058005795\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 4.4747611172013535e-10, best loss 4.4747611172013535e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 52 seconds passed from the start, the iteration took 13 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.421x_{1}^{1}-0.371x_{2}^{1}+0.112x_{3}^{1}-1.21$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.421x_1^{1.000}-0.371x_2^{1.000} + 0.112x_3^{1.001}-1.210\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.1145637650400927e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #10----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.012512505054473877, best loss 0.012512505054473877\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.011847813613712788, best loss 0.011847813613712788\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.04677753150463104, best loss 0.011847813613712788\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.9658236977425645e-10, best loss 2.9658236977425645e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 6 seconds passed from the start, the iteration took 13 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.744x_{1}^{1}-0.694x_{2}^{1}-0.945x_{3}^{1}+0.209$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.744x_1^{1.000}-0.694x_2^{1.000}-0.945x_3^{1.000} + 0.209\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.622096477786857e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.2181853367313319e-08, 0.8217513293213506, 7.0111635002463e-07, 5.000738325021205e-08, 6.7070178810246794e-06, 3.073016812444556e-07, 3.166313272906507e-06, 1.9255488898599943e-07, 2.1145637650400927e-07, 7.622096477786857e-09]\n",
      "For 9 formulas out of 10 the error is less than 1e-05.\n"
     ]
    }
   ],
   "source": [
    "explore.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear combination of 3 squared variables and bias with standard-normally distributed coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.19504092633724213, best loss 0.19504092633724213\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.007013747934252024, best loss 0.007013747934252024\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.009375261142849922, best loss 0.007013747934252024\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.009800040163099766, best loss 0.007013747934252024\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 1.8762023185070476e-12, best loss 1.8762023185070476e-12\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "15 seconds passed from the start, the iteration took 15 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -2.118x_{1}^{2}-2.121x_{2}^{2}+0.462x_{3}^{2}+0.852$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.118x_1^{2.000}-2.121x_2^{2.000} + 0.462x_3^{2.000} + 0.852\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.69699216717033e-12\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.5127137743701242e-12, best loss 3.5127137743701242e-12\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "16 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.787x_{1}^{2}-0.506x_{2}^{2}-1.607x_{3}^{2}+1.722$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.787x_1^{2.000}-0.506x_2^{2.000}-1.607x_3^{2.000} + 1.722\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.412026548081485e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.1483605057001114, best loss 0.1483605057001114\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.02518836408853531, best loss 0.02518836408853531\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.3154793226943795e-11, best loss 1.3154793226943795e-11\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "32 seconds passed from the start, the iteration took 15 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.043x_{1}^{2}-1.52x_{2}^{2}-0.755x_{3}^{2}-0.242$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.043x_1^{2.000}-1.520x_2^{2.000}-0.755x_3^{2.000}-0.242\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.558649565503304e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.5556061647159503e-11, best loss 1.5556061647159503e-11\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "33 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.549x_{1}^{2}+0.916x_{2}^{2}+1.277x_{3}^{2}+0.891$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.549x_1^{2.000} + 0.916x_2^{2.000} + 1.277x_3^{2.000} + 0.891\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.6123866630815817e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0013860539766028523, best loss 0.0013860539766028523\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0016387712676078081, best loss 0.0013860539766028523\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 5.024526801566953e-12, best loss 5.024526801566953e-12\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "38 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.11x_{1}^{2}-2.128x_{2}^{2}+0.169x_{3}^{2}-0.251$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.110x_1^{2.000}-2.128x_2^{2.000} + 0.169x_3^{2.000}-0.251\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.520428805612953e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #6----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.03510764613747597, best loss 0.03510764613747597\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.03426942229270935, best loss 0.03426942229270935\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.035176824778318405, best loss 0.03426942229270935\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.023263581097126007, best loss 0.023263581097126007\n",
      "  Initialization #5\n",
      "    Epoch 5000, current loss 0.054, current formula \\left(0.879x_1^{1.832}-8.612x_2^{-0.023} + 8.933x_3^{-0.019}-1.041\\right)\n",
      "    Epoch 10000, current loss 0.0535, current formula \\left(0.879x_1^{1.835}-12.666x_2^{-0.016} + 12.986x_3^{-0.013}-1.041\\right)\n",
      "  Finished run #5, loss 0.05348413810133934, best loss 0.023263581097126007\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 8.06729336111367e-12, best loss 8.06729336111367e-12\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "1 minutes 29 seconds passed from the start, the iteration took 51 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.917x_{1}^{2}+0.782x_{2}^{2}-0.866x_{3}^{2}-0.72$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.917x_1^{2.000} + 0.782x_2^{2.000}-0.866x_3^{2.000}-0.720\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.1134510842483516e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #7----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.010849709622561932, best loss 0.010849709622561932\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.038911230862140656, best loss 0.010849709622561932\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.009395286440849304, best loss 0.009395286440849304\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0017017177306115627, best loss 0.0017017177306115627\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 0.03575057163834572, best loss 0.0017017177306115627\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 0.011514522135257721, best loss 0.0017017177306115627\n",
      "  Initialization #7\n",
      "    Epoch 5000, current loss 0.0114, current formula \\left(-5.762x_1^{-0.020} + 0.945x_2^{1.895} + 3.524x_3^{-0.011} + 3.652\\right)\n",
      "  Finished run #7, loss 0.011352745816111565, best loss 0.0017017177306115627\n",
      "  Initialization #8\n",
      "  Finished run #8, loss 1.14887084221027e-11, best loss 1.14887084221027e-11\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "2 minutes 46 seconds passed from the start, the iteration took 1 minutes 17 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.517x_{1}^{2}+0.938x_{2}^{2}-0.182x_{3}^{2}+1.244$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.517x_1^{2.000} + 0.938x_2^{2.000}-0.182x_3^{2.000} + 1.244\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.36695601003672e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #8----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.00043949144310317934, best loss 0.00043949144310317934\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "2 minutes 48 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.118x_{1}^{2}-0.574x_{2}^{2}-0.106x_{3}^{2}+2.927$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.118x_1^{1.944}-0.576x_2^{2.009} + 2.378x_3^{-0.010} + 0.491\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.306655452500273\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #9----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.1731370175581688e-11, best loss 2.1731370175581688e-11\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "2 minutes 50 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.098x_{1}^{2}+0.082x_{2}^{2}-1.988x_{3}^{2}-0.771$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.098x_1^{2.000} + 0.082x_2^{1.999}-1.988x_3^{2.000}-0.771\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.782828465030533e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #10----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.292567591465904e-12, best loss 7.292567591465904e-12\n",
      "loss is smaller than 0.001, terminating learning process\n",
      "2 minutes 55 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.726x_{1}^{2}-0.951x_{2}^{2}+0.516x_{3}^{2}-0.259$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.726x_1^{2.000}-0.951x_2^{2.000} + 0.516x_3^{2.000}-0.259\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.295644557788495e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[6.69699216717033e-12, 7.412026548081485e-11, 3.558649565503304e-10, 4.6123866630815817e-10, 3.520428805612953e-09, 3.1134510842483516e-10, 6.36695601003672e-09, 2.306655452500273, 7.782828465030533e-08, 5.295644557788495e-10]\n",
      "For 9 formulas out of 10 the error is less than 1e-05.\n"
     ]
    }
   ],
   "source": [
    "explore(min_power=2, max_power=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear combination of 3 variables with powers uniformly distributed over {1, 2 ,3 ,4, 5} and standard-normally distributed coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.06304360181093216, best loss 0.06304360181093216\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.004367060959339142, best loss 0.004367060959339142\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.3601357019832339e-11, best loss 1.3601357019832339e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "6 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.126x_{1}^{2}-1.236x_{2}^{2}+0.312x_{3}^{3}+0.729$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.126x_1^{2.000}-1.236x_2^{2.000} + 0.312x_3^{3.000} + 0.729\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.667260058065235e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.08279216289520264, best loss 0.08279216289520264\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.7293509289514897e-12, best loss 1.7293509289514897e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "10 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.937x_{1}^{4}-0.922x_{2}^{4}+1.209x_{3}^{5}+1.655$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.937x_1^{4.000}-0.922x_2^{4.000} + 1.209x_3^{5.000} + 1.655\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1465926620855628e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.422276226791424e-13, best loss 7.422276226791424e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "14 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.539x_{1}^{6}-1.276x_{2}^{3}-0.967x_{3}^{6}-0.346$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.539x_1^{6.000}-1.276x_2^{3.000}-0.967x_3^{6.000}-0.346\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1858755247625855e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.002982549136504531, best loss 0.002982549136504531\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.033160265535116196, best loss 0.002982549136504531\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.09207728505134583, best loss 0.002982549136504531\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.03271259367465973, best loss 0.002982549136504531\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 0.0027095582336187363, best loss 0.0027095582336187363\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 2.9511610169508096e-12, best loss 2.9511610169508096e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "36 seconds passed from the start, the iteration took 22 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.452x_{1}^{4}-0.316x_{2}^{1}-0.89x_{3}^{6}-1.062$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.452x_1^{4.000}-0.316x_2^{1.000}-0.890x_3^{6.000}-1.062\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.3764445208005004e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0621, current formula \\left(-7.449x_1^{-0.011}-0.163x_2^{3.560} + 6.996x_3^{-0.015} + 0.764\\right)\n",
      "  Finished run #1, loss 0.06207393482327461, best loss 0.06207393482327461\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0622, current formula \\left(-7.718x_1^{-0.011}-0.163x_2^{3.565} + 6.194x_3^{-0.017} + 1.836\\right)\n",
      "  Finished run #2, loss 0.06211938336491585, best loss 0.06207393482327461\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.208213824127613e-11, best loss 1.208213824127613e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 25 seconds passed from the start, the iteration took 49 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.526x_{1}^{4}-0.143x_{2}^{2}-1.118x_{3}^{6}+0.4$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.526x_1^{4.000}-0.143x_2^{2.000}-1.118x_3^{6.000} + 0.400\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.4469741119579486e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #6----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.08188065886497498, best loss 0.08188065886497498\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.182, current formula \\left(-9.522x_1^{-0.026} + 1.402x_2^{4.533} + 2.577x_3^{0.022} + 8.277\\right)\n",
      "  Finished run #2, loss 0.18087251484394073, best loss 0.08188065886497498\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0822642371058464, best loss 0.08188065886497498\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.086057455247259e-12, best loss 2.086057455247259e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 3 seconds passed from the start, the iteration took 38 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.963x_{1}^{5}+1.38x_{2}^{5}+0.423x_{3}^{6}+0.658$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.963x_1^{5.000} + 1.380x_2^{5.000} + 0.423x_3^{6.000} + 0.658\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.5023411086596232e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #7----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0009585803491063416, best loss 0.0009585803491063416\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.016282297670841217, best loss 0.0009585803491063416\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.016563350334763527, best loss 0.0009585803491063416\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 6.829097292000708e-13, best loss 6.829097292000708e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 31 seconds passed from the start, the iteration took 28 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.571x_{1}^{5}+0.15x_{2}^{5}-0.613x_{3}^{2}+1.084$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.571x_1^{5.000} + 0.150x_2^{5.000}-0.613x_3^{2.000} + 1.084\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.4865421660867923e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #8----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0010126919951289892, best loss 0.0010126919951289892\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 5.297980804064295e-12, best loss 5.297980804064295e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 34 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.154x_{1}^{5}-0.309x_{2}^{3}+1.08x_{3}^{1}+0.952$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.154x_1^{5.000}-0.309x_2^{3.000} + 1.080x_3^{1.000} + 0.952\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1178741107390318e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #9----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.05849596858024597, best loss 0.05849596858024597\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.000568809628020972, best loss 0.000568809628020972\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0352, current formula \\left(-1.289x_1^{-0.011}-5.506x_2^{-0.024} + 0.662x_3^{3.975} + 5.457\\right)\n",
      "  Finished run #3, loss 0.03520870953798294, best loss 0.000568809628020972\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.034622740000486374, best loss 0.000568809628020972\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 0.0006225152174010873, best loss 0.000568809628020972\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 5.907022267159778e-12, best loss 5.907022267159778e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 3 seconds passed from the start, the iteration took 29 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.11x_{1}^{3}+0.842x_{2}^{3}+0.655x_{3}^{4}-1.72$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.110x_1^{3.000} + 0.842x_2^{3.000} + 0.655x_3^{4.000}-1.720\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.363041794779213e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #10----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.005140147637575865, best loss 0.005140147637575865\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.1832983377868533e-11, best loss 1.1832983377868533e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 6 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.014x_{1}^{3}+0.342x_{2}^{2}-0.814x_{3}^{6}+0.378$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.014x_1^{2.997} + 0.342x_2^{2.000}-0.814x_3^{6.000} + 0.378\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.018604936760181e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[5.667260058065235e-09, 1.1465926620855628e-10, 1.1858755247625855e-10, 3.3764445208005004e-10, 1.4469741119579486e-08, 1.5023411086596232e-10, 3.4865421660867923e-10, 1.1178741107390318e-08, 2.363041794779213e-08, 9.018604936760181e-07]\n",
      "For 10 formulas out of 10 the error is less than 1e-05.\n"
     ]
    }
   ],
   "source": [
    "explore.explore(max_power=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0005649023805744946, best loss 0.0005649023805744946\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 3.363373165046757e-12, best loss 3.363373165046757e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.049x_{1}^{3.333}+0.114x_{2}^{4.667}+1.084x_{3}^{1.667}-0.099$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.049x_1^{3.333} + 0.114x_2^{4.667} + 1.084x_3^{1.667}-0.099\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0837911044804726e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.043854933232069016, best loss 0.043854933232069016\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 5.613911113755421e-09, best loss 5.613911113755421e-09\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "15 seconds passed from the start, the iteration took 12 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.221x_{1}^{2.0}-1.776x_{2}^{0.667}-1.643x_{3}^{1.333}+1.616$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.221x_1^{2.000}-1.776x_2^{0.667}-1.643x_3^{1.334} + 1.615\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.233614190178222e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.028962085023522377, best loss 0.028962085023522377\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 4.988416549167596e-05, best loss 4.988416549167596e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.026912150904536247, best loss 4.988416549167596e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.14470908045768738, best loss 4.988416549167596e-05\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 5.1276245358167216e-05, best loss 4.988416549167596e-05\n",
      "  Initialization #6\n",
      "    Epoch 5000, current loss 0.153, current formula \\left(0.061x_1^{14.948} + 13.875x_2^{-0.027}-12.422x_3^{-0.014}-2.685\\right)\n",
      "  Finished run #6, loss 0.15167467296123505, best loss 4.988416549167596e-05\n",
      "  Initialization #7\n",
      "  Finished run #7, loss 5.1009068556595594e-05, best loss 4.988416549167596e-05\n",
      "  Initialization #8\n",
      "  Finished run #8, loss 0.029082538560032845, best loss 4.988416549167596e-05\n",
      "  Initialization #9\n",
      "  Finished run #9, loss 0.02650262415409088, best loss 4.988416549167596e-05\n",
      "  Initialization #10\n",
      "  Finished run #10, loss 0.13250789046287537, best loss 4.988416549167596e-05\n",
      "1 minutes 27 seconds passed from the start, the iteration took 1 minutes 12 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.033x_{1}^{3.667}-1.803x_{2}^{1.667}+0.798x_{3}^{2.333}-0.584$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.351x_1^{-0.004}-1.803x_2^{1.664} + 0.799x_3^{2.329} + 0.779\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.464195771728083\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.00016132325981743634, best loss 0.00016132325981743634\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 5.5267452940543915e-12, best loss 5.5267452940543915e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 31 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.232x_{1}^{2.333}+0.259x_{2}^{4.0}-0.06x_{3}^{2.667}-0.169$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.232x_1^{2.333} + 0.259x_2^{4.000}-0.060x_3^{2.666}-0.169\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.936620335265317e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.017211973667144775, best loss 0.017211973667144775\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.972271304606643e-12, best loss 1.972271304606643e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 39 seconds passed from the start, the iteration took 9 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.623x_{1}^{2.0}-1.421x_{2}^{2.667}+1.193x_{3}^{2.333}-1.313$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.623x_1^{2.000}-1.421x_2^{2.667} + 1.193x_3^{2.333}-1.313\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.349257627594592e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #6----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0459, current formula \\left(-8.472x_1^{-0.034} + 7.621x_2^{-0.010}-2.173x_3^{3.907} + 1.297\\right)\n",
      "  Finished run #1, loss 0.045699264854192734, best loss 0.045699264854192734\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.03883028030395508, best loss 0.03883028030395508\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.010128953494131565, best loss 0.010128953494131565\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.225, current formula \\left(1.250x_1^{0.741}-0.498x_2^{3.728} + 7.295x_3^{-0.041}-8.444\\right)\n",
      "    Epoch 10000, current loss 0.223, current formula \\left(1.254x_1^{0.735}-0.498x_2^{3.743} + 11.863x_3^{-0.026}-13.029\\right)\n",
      "  Finished run #4, loss 0.2226993441581726, best loss 0.010128953494131565\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 4.736817708905772e-12, best loss 4.736817708905772e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 55 seconds passed from the start, the iteration took 1 minutes 16 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.241x_{1}^{1.0}-0.46x_{2}^{3.667}-2.218x_{3}^{4.0}-0.299$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.241x_1^{1.000}-0.460x_2^{3.667}-2.218x_3^{4.000}-0.299\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.099755621237688e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #7----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 4.2805082395291905e-12, best loss 4.2805082395291905e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 57 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 3.203x_{1}^{2.333}-1.724x_{2}^{4.333}-0.757x_{3}^{1.667}-1.98$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(3.203x_1^{2.333}-1.724x_2^{4.333}-0.757x_3^{1.667}-1.980\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 8.138962519816622e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #8----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.016357822343707085, best loss 0.016357822343707085\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 6.806492820032872e-06, best loss 6.806492820032872e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 60 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.609x_{1}^{4.667}+0.781x_{2}^{5.0}-0.898x_{3}^{0.333}+1.012$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.608x_1^{4.660} + 0.780x_2^{4.990}-0.940x_3^{0.310} + 1.056\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.0006299513376686962\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #9----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.62283077601022e-12, best loss 1.62283077601022e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 1 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.027x_{1}^{4.667}+1.451x_{2}^{2.333}-1.368x_{3}^{2.667}-0.876$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.027x_1^{4.667} + 1.451x_2^{2.333}-1.368x_3^{2.667}-0.876\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.5763519957680336e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #10----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.805804489180446e-05, best loss 7.805804489180446e-05\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.04445670545101166, best loss 7.805804489180446e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 7.458134496118873e-05, best loss 7.458134496118873e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 6.3320629124064e-05, best loss 6.3320629124064e-05\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 0.04257139191031456, best loss 6.3320629124064e-05\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 0.04354075714945793, best loss 6.3320629124064e-05\n",
      "  Initialization #7\n",
      "  Finished run #7, loss 0.04352091625332832, best loss 6.3320629124064e-05\n",
      "  Initialization #8\n",
      "  Finished run #8, loss 6.833985389675945e-05, best loss 6.3320629124064e-05\n",
      "  Initialization #9\n",
      "    Epoch 5000, current loss 0.19, current formula \\left(-7.580x_1^{-0.043}-0.033x_2^{1.028} + 1.034x_3^{4.753} + 8.133\\right)\n",
      "  Finished run #9, loss 0.18901683390140533, best loss 6.3320629124064e-05\n",
      "  Initialization #10\n",
      "  Finished run #10, loss 0.24506711959838867, best loss 6.3320629124064e-05\n",
      "3 minutes 57 seconds passed from the start, the iteration took 56 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.913x_{1}^{3.333}-0.043x_{2}^{1.667}+0.953x_{3}^{4.333}-0.265$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.913x_1^{3.330}-2.160x_2^{0.005} + 0.954x_3^{4.325} + 1.869\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.6850588041040635\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.0837911044804726e-09, 7.233614190178222e-08, 2.464195771728083, 3.936620335265317e-08, 6.349257627594592e-11, 6.099755621237688e-11, 8.138962519816622e-11, 0.0006299513376686962, 4.5763519957680336e-11, 1.6850588041040635]\n",
      "For 7 formulas out of 10 the error is less than 1e-05.\n"
     ]
    }
   ],
   "source": [
    "explore.explore(max_power=15, divide_powers_by=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0942, current formula \\left(-16.218x_1^{-0.017} + 14.928x_2^{-0.021} + 1.766x_3^{0.021} + 1.120x_4^{2.003}-0.748\\right)\n",
      "  Finished run #1, loss 0.0930163636803627, best loss 0.0930163636803627\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0951, current formula \\left(-12.279x_1^{-0.022} + 13.479x_2^{-0.023}-0.602x_3^{-0.045} + 1.120x_4^{2.003}-0.878\\right)\n",
      "    Epoch 10000, current loss 0.0946, current formula \\left(-13.577x_1^{-0.020} + 14.814x_2^{-0.021}-0.647x_3^{-0.042} + 1.120x_4^{2.003}-0.870\\right)\n",
      "  Finished run #2, loss 0.09464673697948456, best loss 0.0930163636803627\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0474, current formula \\left(-4.589x_1^{-0.053}-1.287x_2^{1.368}-0.519x_3^{-0.052} + 1.140x_4^{1.980} + 5.665\\right)\n",
      "  Finished run #3, loss 0.046409040689468384, best loss 0.046409040689468384\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.1, current formula \\left(1.143x_1^{1.339} + 12.331x_2^{-0.026} + 0.332x_3^{5.156}-13.906x_4^{-0.018} + 1.078\\right)\n",
      "    Epoch 10000, current loss 0.0988, current formula \\left(1.144x_1^{1.343} + 18.714x_2^{-0.018} + 0.332x_3^{5.143}-20.276x_4^{-0.013} + 1.062\\right)\n",
      "  Finished run #4, loss 0.09879747033119202, best loss 0.046409040689468384\n",
      "  Initialization #5\n",
      "    Epoch 5000, current loss 0.0532, current formula \\left(1.160x_1^{1.292}-1.310x_2^{1.280} + 0.301x_3^{3.468}-5.114x_4^{-0.046} + 5.475\\right)\n",
      "    Epoch 10000, current loss 0.052, current formula \\left(1.159x_1^{1.300}-1.311x_2^{1.279} + 0.301x_3^{3.467}-8.301x_4^{-0.030} + 8.680\\right)\n",
      "  Finished run #5, loss 0.05199287459254265, best loss 0.046409040689468384\n",
      "  Initialization #6\n",
      "  Finished run #6, loss 7.338774032916717e-11, best loss 7.338774032916717e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "4 minutes 3 seconds passed from the start, the iteration took 4 minutes 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.136x_{1}^{1.333}-1.342x_{2}^{1.25}+0.295x_{3}^{3.083}+1.159x_{4}^{1.917}-0.244$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.136x_1^{1.333}-1.342x_2^{1.250} + 0.295x_3^{3.083} + 1.159x_4^{1.917}-0.244\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.3299586704439434e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0011191540397703648, best loss 0.0011191540397703648\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.001156878424808383, best loss 0.0011191540397703648\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0633557066321373, best loss 0.0011191540397703648\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0646, current formula \\left(-0.155x_1^{1.299}-6.539x_2^{-0.044}-2.509x_3^{0.649}-1.934x_4^{1.843} + 8.407\\right)\n",
      "    Epoch 10000, current loss 0.0624, current formula \\left(-0.159x_1^{1.085}-10.400x_2^{-0.029}-2.516x_3^{0.645}-1.935x_4^{1.843} + 12.296\\right)\n",
      "  Finished run #4, loss 0.06237761676311493, best loss 0.0011191540397703648\n",
      "  Initialization #5\n",
      "    Epoch 5000, current loss 0.168, current formula \\left(-0.488x_1^{0.047} + 1.332x_2^{1.668}-2.287x_3^{0.731} + 18.646x_4^{-0.021}-18.460\\right)\n",
      "    Epoch 10000, current loss 0.165, current formula \\left(-0.521x_1^{0.045} + 1.332x_2^{1.666}-2.287x_3^{0.731} + 30.321x_4^{-0.014}-30.114\\right)\n",
      "  Finished run #5, loss 0.164914071559906, best loss 0.0011191540397703648\n",
      "  Initialization #6\n",
      "    Epoch 5000, current loss 0.178, current formula \\left(-3.719x_1^{0.005} + 1.329x_2^{1.699}-2.316x_3^{0.706} + 7.729x_4^{-0.046}-4.231\\right)\n",
      "    Epoch 10000, current loss 0.172, current formula \\left(-6.899x_1^{0.003} + 1.331x_2^{1.676}-2.292x_3^{0.726} + 11.487x_4^{-0.033}-4.863\\right)\n",
      "  Finished run #6, loss 0.17245455086231232, best loss 0.0011191540397703648\n",
      "  Initialization #7\n",
      "    Epoch 5000, current loss 0.221, current formula \\left(-0.335x_1^{0.161}-18.382x_2^{-0.018}-2.383x_3^{0.703} + 19.902x_4^{-0.020}-0.604\\right)\n",
      "    Epoch 10000, current loss 0.218, current formula \\left(-0.373x_1^{0.141}-24.744x_2^{-0.013}-2.383x_3^{0.704} + 26.302x_4^{-0.015}-0.607\\right)\n",
      "  Finished run #7, loss 0.21840810775756836, best loss 0.0011191540397703648\n",
      "  Initialization #8\n",
      "    Epoch 5000, current loss 0.178, current formula \\left(-3.591x_1^{0.005} + 1.330x_2^{1.697}-2.315x_3^{0.707} + 7.812x_4^{-0.045}-4.445\\right)\n",
      "  Finished run #8, loss 0.1738404929637909, best loss 0.0011191540397703648\n",
      "  Initialization #9\n",
      "    Epoch 5000, current loss 0.0724, current formula \\left(-8.389x_1^{0.001} + 1.331x_2^{1.632} + 11.748x_3^{-0.045}-1.975x_4^{1.966}-4.453\\right)\n",
      "    Epoch 10000, current loss 0.0707, current formula \\left(-10.230x_1^{0.001} + 1.332x_2^{1.628} + 13.701x_3^{-0.040}-1.975x_4^{1.967}-4.573\\right)\n",
      "  Finished run #9, loss 0.07067271322011948, best loss 0.0011191540397703648\n",
      "  Initialization #10\n",
      "    Epoch 5000, current loss 0.0776, current formula \\left(-4.134x_1^{0.001} + 1.327x_2^{1.663} + 8.133x_3^{-0.062}-1.974x_4^{1.955}-5.063\\right)\n",
      "    Epoch 10000, current loss 0.0709, current formula \\left(-9.018x_1^{0.001} + 1.331x_2^{1.628} + 13.352x_3^{-0.041}-1.975x_4^{1.967}-5.434\\right)\n",
      "  Finished run #10, loss 0.07094106823205948, best loss 0.0011191540397703648\n",
      "10 minutes 8 seconds passed from the start, the iteration took 6 minutes 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.163x_{1}^{4.0}+1.352x_{2}^{1.5}-2.43x_{3}^{0.667}-1.985x_{4}^{1.833}+0.952$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.169x_1^{0.023} + 1.350x_2^{1.496}-2.425x_3^{0.667}-1.980x_4^{1.832} + 2.058\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.0063896865672595\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.207, current formula \\left(-0.154x_1^{0.389}-7.613x_2^{-0.043}-0.251x_3^{1.166}-2.744x_4^{-0.048} + 10.734\\right)\n",
      "  Finished run #1, loss 0.2074088603258133, best loss 0.2074088603258133\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0717, current formula \\left(-0.093x_1^{7.623} + 1.774x_2^{2.433} + 7.794x_3^{-0.010}-9.239x_4^{-0.019} + 0.696\\right)\n",
      "  Finished run #2, loss 0.07172449678182602, best loss 0.07172449678182602\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 2.259490247524809e-05, best loss 2.259490247524809e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 3.4714398022828163e-11, best loss 3.4714398022828163e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "11 minutes 8 seconds passed from the start, the iteration took 1 minutes 0 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.029x_{1}^{1.333}+1.801x_{2}^{2.417}-0.361x_{3}^{2.083}+1.207x_{4}^{3.417}-1.003$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.029x_1^{1.332} + 1.801x_2^{2.417}-0.361x_3^{2.083} + 1.207x_4^{3.417}-1.003\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.8310162592125474e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.146, current formula \\left(1.570x_1^{2.314}-5.034x_2^{-0.051}-0.235x_3^{3.021} + 0.117x_4^{6.323} + 5.976\\right)\n",
      "  Finished run #1, loss 0.14529700577259064, best loss 0.14529700577259064\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0028159967623651028, best loss 0.0028159967623651028\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.00048364687245339155, best loss 0.00048364687245339155\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.003353861393406987, best loss 0.00048364687245339155\n",
      "  Initialization #5\n",
      "  Finished run #5, loss 6.656671307919693e-12, best loss 6.656671307919693e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "12 minutes 2 seconds passed from the start, the iteration took 54 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.585x_{1}^{2.083}+1.683x_{2}^{3.0}-0.242x_{3}^{2.667}+0.109x_{4}^{1.917}+0.174$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.585x_1^{2.083} + 1.683x_2^{3.000}-0.242x_3^{2.667} + 0.109x_4^{1.917} + 0.174\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.067346564489643e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0636, current formula \\left(-1.213x_1^{0.641} + 0.128x_2^{1.892}-9.821x_3^{-0.020} + 8.572x_4^{-0.034}-0.525\\right)\n",
      "    Epoch 10000, current loss 0.062, current formula \\left(-1.212x_1^{0.641} + 0.129x_2^{1.852}-17.596x_3^{-0.012} + 16.359x_4^{-0.018}-0.544\\right)\n",
      "  Finished run #1, loss 0.06200076639652252, best loss 0.06200076639652252\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0556, current formula \\left(3.211x_1^{-0.071} + 0.134x_2^{2.998} + 0.898x_3^{2.649} + 3.351x_4^{-0.079}-9.748\\right)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5fd5fc00a897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexplore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_power\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivide_powers_by\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/zybinmikhail/Documents/personal github projects/LearningFormulas/explore.py\u001b[0m in \u001b[0;36mexplore\u001b[0;34m(n_variables, m_samples, min_power, max_power, number_of_tested_formulas, recovery_threshold, divide_powers_by)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mcoeffs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpowers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_power\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivide_powers_by\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mcnt_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mregressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNestedFormula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearnFormula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_for_formula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mprint_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ground truth and obtained formula\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zybinmikhail/Documents/personal github projects/LearningFormulas/NestedFormula.py\u001b[0m in \u001b[0;36mLearnFormula\u001b[0;34m(X, y, optimizer_for_formula, device, n_init, max_iter, lr, depth, verbose, verbose_frequency, max_epochs_without_improvement, minimal_acceptable_improvement, max_tol, use_swa)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mminimal_acceptable_improvement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0mepochs_without_improvement\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "explore.explore(\n",
    "    n_variables=4,\n",
    "    max_power=48,\n",
    "    divide_powers_by=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.0261449407144028e-08, best loss 2.0261449407144028e-08\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.491x_{1}^{4.0}-0.935x_{2}^{2.0}-0.006$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.492x_1^{4.028}-0.936x_2^{1.994}-0.005\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.00016596720811166494\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 5.672545766444159e-13, best loss 5.672545766444159e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.327x_{1}^{4.0}-1.245x_{2}^{3.0}+0.028$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.327x_1^{4.000}-1.245x_2^{3.000} + 0.028\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.684466607338898e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.00852009654045105, best loss 0.00852009654045105\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.1039375797116122e-10, best loss 2.1039375797116122e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "8 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.326x_{1}^{5.0}-0.401x_{2}^{2.0}-0.041$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.324x_1^{4.996}-0.401x_2^{2.001}-0.041\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.194146757048988e-06\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0006071350071579218, best loss 0.0006071350071579218\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.004937557503581047, best loss 0.0006071350071579218\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.01582016795873642, best loss 0.0006071350071579218\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.015445942990481853, best loss 0.0006071350071579218\n",
      "19 seconds passed from the start, the iteration took 11 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.426x_{1}^{3.0}+0.256x_{2}^{3.0}+0.506$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.933x_1^{1.418}-3.500x_2^{110.691} + 0.681\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2322.8296425815106\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0788, current formula \\left(6.687x_1^{-0.268} + 1.010x_2^{1.068}-8.812\\right)\n",
      "    Epoch 10000, current loss 0.0764, current formula \\left(9.039x_1^{-0.205} + 1.018x_2^{1.063}-11.178\\right)\n",
      "  Finished run #1, loss 0.07638335973024368, best loss 0.07638335973024368\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 8.344080634770101e-12, best loss 8.344080634770101e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "30 seconds passed from the start, the iteration took 12 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.941x_{1}^{5.0}+1.112x_{2}^{1.0}-0.765$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.941x_1^{5.000} + 1.112x_2^{1.000}-0.765\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.3002791610670103e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[0.00016596720811166494, 2.684466607338898e-11, 3.194146757048988e-06, 2322.8296425815106, 3.3002791610670103e-10]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.012539874762296677, best loss 0.012539874762296677\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.01325070858001709, best loss 0.012539874762296677\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.011086439713835716, best loss 0.011086439713835716\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.01105429232120514, best loss 0.01105429232120514\n",
      "29 seconds passed from the start, the iteration took 29 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.141x_{1}^{2.5}+0.763x_{2}^{3.0}-0.803$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.261x_1^{1.212}-2.017x_2^{-0.180} + 1.684\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.13898947510706\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0015452116494998336, best loss 0.0015452116494998336\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.5867130526148188e-11, best loss 1.5867130526148188e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "35 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.098x_{1}^{4.0}+0.319x_{2}^{4.5}-0.663$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.098x_1^{4.002} + 0.319x_2^{4.499}-0.663\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.613262348939777e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00281, current formula \\left(-0.890x_1^{0.020} + 0.843x_2^{-0.061}-1.068\\right)\n",
      "  Finished run #1, loss 0.0028045806102454662, best loss 0.0028045806102454662\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.6033041214114085e-11, best loss 1.6033041214114085e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "47 seconds passed from the start, the iteration took 12 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.23x_{1}^{3.5}-0.253x_{2}^{4.5}-0.997$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.230x_1^{3.498}-0.253x_2^{4.500}-0.997\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.359365282675554e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.005440554115921259, best loss 0.005440554115921259\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0020946164149791002, best loss 0.0020946164149791002\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0002347720437683165, best loss 0.0002347720437683165\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.005405937787145376, best loss 0.0002347720437683165\n",
      "54 seconds passed from the start, the iteration took 7 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.339x_{1}^{4.5}-0.382x_{2}^{3.5}+0.126$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.377x_1^{5.546} + 0.113x_2^{-0.468}-0.094\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.4266497131602223\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0009635782917030156, best loss 0.0009635782917030156\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00628, current formula \\left(-1.583x_1^{-0.040}-0.043x_2^{1.707} + 0.152\\right)\n",
      "    Epoch 10000, current loss 0.00623, current formula \\left(-2.185x_1^{-0.030}-0.043x_2^{1.715} + 0.755\\right)\n",
      "  Finished run #2, loss 0.0062287310138344765, best loss 0.0009635782917030156\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.006213583517819643, best loss 0.0009635782917030156\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0009628385887481272, best loss 0.0009628385887481272\n",
      "1 minutes 16 seconds passed from the start, the iteration took 22 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.842x_{1}^{5.0}-0.158x_{2}^{5.5}-1.58$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.476x_1^{2.648}-0.968x_2^{0.007}-0.668\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.465098012900606\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[5.13898947510706, 9.613262348939777e-07, 5.359365282675554e-07, 3.4266497131602223, 7.465098012900606]\n",
      "For 2 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0004746333579532802, best loss 0.0004746333579532802\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.8544620616012253e-05, best loss 1.8544620616012253e-05\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.00092, current formula \\left(-0.309x_1^{0.726}-1.517x_2^{-0.180} + 3.212\\right)\n",
      "  Finished run #3, loss 0.0008934688521549106, best loss 1.8544620616012253e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0006942421314306557, best loss 1.8544620616012253e-05\n",
      "19 seconds passed from the start, the iteration took 19 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.359x_{1}^{0.667}+1.813x_{2}^{0.25}-0.034$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.364x_1^{0.701} + 1.531x_2^{0.314} + 0.252\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.03338729402236941\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 7.836091526769451e-07, best loss 7.836091526769451e-07\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "21 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.572x_{1}^{0.083}+1.742x_{2}^{5.833}-1.244$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.090x_1^{0.040} + 1.741x_2^{5.830}-1.763\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.10777169353995039\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.2248513795175562e-11, best loss 2.2248513795175562e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "24 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.256x_{1}^{0.667}+0.766x_{2}^{4.167}-0.533$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.256x_1^{0.667} + 0.766x_2^{4.167}-0.533\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.141286945648972e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 9.789586329134181e-05, best loss 9.789586329134181e-05\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.308902426444547e-07, best loss 1.308902426444547e-07\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "27 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.562x_{1}^{2.75}-0.257x_{2}^{1.667}+0.111$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.559x_1^{2.700}-0.265x_2^{1.753} + 0.108\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.002012487476838143\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.900595471617585e-11, best loss 3.900595471617585e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "29 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.74x_{1}^{4.25}-0.345x_{2}^{2.167}-1.24$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.740x_1^{4.250}-0.345x_2^{2.166}-1.240\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1107936419563202e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[0.03338729402236941, 0.10777169353995039, 6.141286945648972e-09, 0.002012487476838143, 1.1107936419563202e-07]\n",
      "For 2 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.009570987895131111, best loss 0.009570987895131111\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 9.90989701676881e-06, best loss 9.90989701676881e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "8 seconds passed from the start, the iteration took 8 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.036x_{1}^{3.0}+0.131x_{2}^{3.0}-0.632x_{3}^{2.0}-0.0$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.220x_1^{0.037} + 0.099x_2^{2.240}-0.632x_3^{2.002} + 0.203\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.3478706979263448\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.9820915742041478e-10, best loss 1.9820915742041478e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "10 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.152x_{1}^{6.0}+0.28x_{2}^{6.0}-0.67x_{3}^{2.0}-0.207$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.151x_1^{5.978} + 0.280x_2^{6.001}-0.670x_3^{1.999}-0.206\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.065537805235016e-05\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.00044768533552996814, best loss 0.00044768533552996814\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.006539390422403812, best loss 0.00044768533552996814\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0505, current formula \\left(3.683x_1^{-0.118}-2.020x_2^{-0.114}-3.268x_3^{0.010}-1.035\\right)\n",
      "    Epoch 10000, current loss 0.0485, current formula \\left(6.688x_1^{-0.070}-2.035x_2^{-0.116}-6.131x_3^{0.005}-1.172\\right)\n",
      "  Finished run #3, loss 0.048523370176553726, best loss 0.00044768533552996814\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.005677252076566219, best loss 0.00044768533552996814\n",
      "36 seconds passed from the start, the iteration took 27 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.007x_{1}^{6.0}+0.328x_{2}^{1.0}-1.0x_{3}^{5.0}-2.357$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.985x_1^{4.477}-2.435x_2^{-0.053}-1.108x_3^{6.455} + 0.373\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.949076359196186\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.1024070111637085e-12, best loss 1.1024070111637085e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "39 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.867x_{1}^{3.0}-1.141x_{2}^{4.0}+0.571x_{3}^{5.0}+0.798$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.867x_1^{3.000}-1.141x_2^{4.000} + 0.571x_3^{5.000} + 0.798\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.226351249655376e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.026694979518651962, best loss 0.026694979518651962\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.011165634728968143, best loss 0.011165634728968143\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.017392152920365334, best loss 0.011165634728968143\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.025807542726397514, best loss 0.011165634728968143\n",
      "53 seconds passed from the start, the iteration took 14 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.604x_{1}^{6.0}-0.349x_{2}^{1.0}-0.95x_{3}^{3.0}+1.092$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.008x_1^{-0.507} + 0.775x_2^{1.315}-2.005x_3^{1.586}-2.155\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 10.058998564018404\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.3478706979263448, 7.065537805235016e-05, 2.949076359196186, 3.226351249655376e-10, 10.058998564018404]\n",
      "For 1 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0032837269827723503, best loss 0.0032837269827723503\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0029850767459720373, best loss 0.0029850767459720373\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.005138542503118515, best loss 0.0029850767459720373\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.002051868010312319, best loss 0.002051868010312319\n",
      "13 seconds passed from the start, the iteration took 13 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.037x_{1}^{5.0}+0.335x_{2}^{4.5}+0.413x_{3}^{3.5}+2.244$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.000x_1^{-1.777} + 2.430x_2^{0.039} + 0.508x_3^{3.308}-0.052\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 10.791518390106434\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0026381555944681168, best loss 0.0026381555944681168\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0044603003188967705, best loss 0.0026381555944681168\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0026, current formula \\left(-0.636x_1^{0.023} + 0.862x_2^{0.076} + 0.984x_3^{6.076} + 1.130\\right)\n",
      "  Finished run #3, loss 0.002601208630949259, best loss 0.002601208630949259\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0027385230641812086, best loss 0.002601208630949259\n",
      "36 seconds passed from the start, the iteration took 23 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.157x_{1}^{5.0}+0.4x_{2}^{1.5}+0.392x_{3}^{4.0}+1.14$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.635x_1^{0.022} + 0.843x_2^{0.078} + 0.984x_3^{6.078} + 1.150\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.98202402279256\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0003939237794838846, best loss 0.0003939237794838846\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.4053114574807957e-11, best loss 1.4053114574807957e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "40 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.12x_{1}^{5.0}+1.231x_{2}^{3.5}+1.578x_{3}^{4.0}-1.497$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.120x_1^{4.999} + 1.231x_2^{3.500} + 1.578x_3^{4.000}-1.497\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.616922627247347e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 8.501180559505883e-07, best loss 8.501180559505883e-07\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "44 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.817x_{1}^{2.0}-0.341x_{2}^{1.5}+0.166x_{3}^{0.5}-0.41$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.818x_1^{1.991}-0.340x_2^{1.485} + 1.406x_3^{0.048}-1.654\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.46973675187538627\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.08620265871286392, best loss 0.08620265871286392\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0012681969674304128, best loss 0.0012681969674304128\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.08738066256046295, best loss 0.0012681969674304128\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.08765256404876709, best loss 0.0012681969674304128\n",
      "1 minutes 7 seconds passed from the start, the iteration took 22 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.334x_{1}^{5.0}-1.704x_{2}^{3.0}-0.536x_{3}^{1.0}-1.358$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.849x_1^{-0.038}-1.511x_2^{3.699}-0.253x_3^{4.909} + 1.368\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 8.404091825861311\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[10.791518390106434, 4.98202402279256, 2.616922627247347e-07, 0.46973675187538627, 8.404091825861311]\n",
      "For 1 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.00800520833581686, best loss 0.00800520833581686\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00627, current formula \\left(0.833x_1^{0.720}-1.014x_2^{-0.281}-0.268x_3^{-0.302} + 1.868\\right)\n",
      "  Finished run #2, loss 0.006221104878932238, best loss 0.006221104878932238\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 7.298266427824274e-05, best loss 7.298266427824274e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0030978957656770945, best loss 7.298266427824274e-05\n",
      "17 seconds passed from the start, the iteration took 17 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.369x_{1}^{4.5}+0.792x_{2}^{5.5}+0.074x_{3}^{1.167}+0.454$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.346x_1^{4.631} + 0.821x_2^{5.782} + 0.673x_3^{0.029}-0.163\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.3043596496627718\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.042, current formula \\left(-5.537x_1^{-0.055}-0.516x_2^{0.082} + 0.546x_3^{11.214} + 7.087\\right)\n",
      "    Epoch 10000, current loss 0.0414, current formula \\left(-7.570x_1^{-0.041}-0.522x_2^{0.081} + 0.520x_3^{10.162} + 9.129\\right)\n",
      "  Finished run #1, loss 0.04137333855032921, best loss 0.04137333855032921\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 6.524211926262069e-08, best loss 6.524211926262069e-08\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "36 seconds passed from the start, the iteration took 19 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.063x_{1}^{3.333}+0.087x_{2}^{5.75}-0.407x_{3}^{0.083}+0.828$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.063x_1^{3.327} + 0.087x_2^{5.760}-2.430x_3^{0.013} + 2.852\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.170800244115396\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.141, current formula \\left(7.315x_1^{-0.023}-10.318x_2^{-0.015} + 4.569x_3^{-0.074}-1.011\\right)\n",
      "  Finished run #1, loss 0.14049272239208221, best loss 0.14049272239208221\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.055378176271915436, best loss 0.055378176271915436\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.003071073442697525, best loss 0.003071073442697525\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.05516880005598068, best loss 0.003071073442697525\n",
      "1 minutes 2 seconds passed from the start, the iteration took 26 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.752x_{1}^{5.917}-0.777x_{2}^{4.083}-1.682x_{3}^{5.0}+1.624$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.815x_1^{9.052} + 0.766x_2^{-0.220}-1.930x_3^{3.212} + 0.680\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.98324109651808\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00137, current formula \\left(0.035x_1^{-1.242} + 7.794x_2^{-0.004}-0.200x_3^{-1.072}-6.142\\right)\n",
      "  Finished run #1, loss 0.0013736301334574819, best loss 0.0013736301334574819\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 9.973423584597185e-05, best loss 9.973423584597185e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.001434842823073268, best loss 9.973423584597185e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0004524136602412909, best loss 9.973423584597185e-05\n",
      "1 minutes 21 seconds passed from the start, the iteration took 19 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.572x_{1}^{0.833}-0.063x_{2}^{0.583}+0.392x_{3}^{1.75}+1.621$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.984x_1^{3.457} + 2.837x_2^{-0.003} + 0.689x_3^{11.939}-1.281\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 18.305740298875143\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.351311007535827e-10, best loss 1.351311007535827e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 24 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.536x_{1}^{2.25}+0.908x_{2}^{1.667}+2.276x_{3}^{4.0}-0.525$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.536x_1^{2.250} + 0.908x_2^{1.667} + 2.275x_3^{3.999}-0.525\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8373740268933553e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[0.3043596496627718, 1.170800244115396, 4.98324109651808, 18.305740298875143, 1.8373740268933553e-07]\n",
      "For 1 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0291, current formula \\left(3.645x_1^{-0.163}-0.618x_2^{0.265}-2.342x_3^{-0.115} + 3.618x_4^{0.024}-3.620\\right)\n",
      "  Finished run #1, loss 0.028747325763106346, best loss 0.028747325763106346\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00522, current formula \\left(0.002x_1^{-3.888} + 0.759x_2^{-0.251} + 0.949x_3^{1.015}-0.363x_4^{2.230}-0.580\\right)\n",
      "  Finished run #2, loss 0.00502643920481205, best loss 0.00502643920481205\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.006181525997817516, best loss 0.00502643920481205\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0338, current formula \\left(-3.483x_1^{0.174} + 3.440x_2^{-0.050}-2.889x_3^{-0.108}-2.126x_4^{53.415} + 3.622\\right)\n",
      "    Epoch 10000, current loss 0.0327, current formula \\left(-4.385x_1^{0.135} + 5.211x_2^{-0.034}-3.793x_3^{-0.085}-2.706x_4^{58.443} + 3.658\\right)\n",
      "  Finished run #4, loss 0.032736483961343765, best loss 0.00502643920481205\n",
      "59 seconds passed from the start, the iteration took 59 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.271x_{1}^{6.0}-1.666x_{2}^{2.0}+1.601x_{3}^{2.0}-0.972x_{4}^{1.0}+1.302$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.001x_1^{-4.574} + 0.801x_2^{-0.244} + 0.946x_3^{1.014}-0.391x_4^{1.942}-0.590\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 14.35657187139502\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00111, current formula \\left(0.963x_1^{-0.205} + 1.114x_2^{14.160} + 0.291x_3^{0.569}-0.573x_4^{0.159}-0.974\\right)\n",
      "  Finished run #1, loss 0.0010969496797770262, best loss 0.0010969496797770262\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0001767244830261916, best loss 0.0001767244830261916\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.00023427676933351904, best loss 0.0001767244830261916\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0003635585308074951, best loss 0.0001767244830261916\n",
      "1 minutes 15 seconds passed from the start, the iteration took 15 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.329x_{1}^{3.0}+0.906x_{2}^{5.0}+0.377x_{3}^{2.0}-0.219x_{4}^{4.0}-0.125$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.737x_1^{0.589} + 1.029x_2^{15.271} + 0.773x_3^{0.163}-0.374x_4^{0.177} + 0.029\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 14.408309340146177\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.002155545400455594, best loss 0.002155545400455594\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0001032429063343443, best loss 0.0001032429063343443\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.00366, current formula \\left(-1.373x_1^{4.687}-2.155x_2^{3.231} + 0.000x_3^{-1.710}-1.746x_4^{23.427}-0.531\\right)\n",
      "    Epoch 10000, current loss 0.003, current formula \\left(-1.375x_1^{4.680}-2.158x_2^{3.229} + 0.000x_3^{-1.710}-1.746x_4^{23.427}-0.529\\right)\n",
      "  Finished run #3, loss 0.0030046370811760426, best loss 0.0001032429063343443\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0015292409807443619, best loss 0.0001032429063343443\n",
      "1 minutes 42 seconds passed from the start, the iteration took 27 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.389x_{1}^{5.0}-2.099x_{2}^{2.0}-0.137x_{3}^{1.0}+0.532x_{4}^{4.0}-0.261$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.318x_1^{4.698}-1.990x_2^{1.970} + 0.087x_3^{-0.140} + 0.553x_4^{4.997}-0.466\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.27729158786088637\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.019236039370298386, best loss 0.019236039370298386\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0019627721048891544, best loss 0.0019627721048891544\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.019136006012558937, best loss 0.0019627721048891544\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.00616, current formula \\left(125546.969x_1^{71.652}-0.739x_2^{1.205}-0.602x_3^{4.655}-1.824x_4^{-0.107} + 1.590\\right)\n",
      "  Finished run #4, loss 0.006041194312274456, best loss 0.0019627721048891544\n",
      "2 minutes 1 seconds passed from the start, the iteration took 19 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.618x_{1}^{4.0}-1.27x_{2}^{2.0}-0.474x_{3}^{5.0}+0.516x_{4}^{3.0}-0.606$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.255x_1^{0.480} + 1.201x_2^{-0.182}-2.358x_3^{39.567} + 1.304x_4^{0.375}-3.000\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 137.30073655488735\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.008604031056165695, best loss 0.008604031056165695\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.002040989464148879, best loss 0.002040989464148879\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.005556877702474594, best loss 0.002040989464148879\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.00854, current formula \\left(-0.903x_1^{3.111}-2.276x_2^{0.064} + 0.003x_3^{-1.783}-0.296x_4^{-0.266} + 2.652\\right)\n",
      "    Epoch 10000, current loss 0.00839, current formula \\left(-0.895x_1^{3.074}-2.830x_2^{0.051} + 0.003x_3^{-1.768}-0.415x_4^{-0.207} + 3.328\\right)\n",
      "  Finished run #4, loss 0.008386553265154362, best loss 0.002040989464148879\n",
      "2 minutes 28 seconds passed from the start, the iteration took 27 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.541x_{1}^{2.0}+0.14x_{2}^{4.0}+1.573x_{3}^{5.0}+1.213x_{4}^{6.0}+0.024$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.449x_1^{0.081}-0.108x_2^{-0.399} + 2.837x_3^{5.672} + 0.957x_4^{3.288} + 1.297\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.889591606950337\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[14.35657187139502, 14.408309340146177, 0.27729158786088637, 137.30073655488735, 3.889591606950337]\n",
      "For 0 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.5174880963495525e-07, best loss 3.5174880963495525e-07\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.075x_{1}^{4.0}-0.777x_{2}^{4.0}+0.005x_{3}^{2.5}-1.749x_{4}^{4.0}-1.502$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.074x_1^{3.993}-0.777x_2^{4.055}-0.054x_3^{-0.018}-1.746x_4^{4.017}-1.451\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.705387268501682\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0405, current formula \\left(15409.301x_1^{38.937}-2.113x_2^{4.172}-2.379x_3^{-0.166}-1.676x_4^{0.155} + 3.964\\right)\n",
      "  Finished run #1, loss 0.04034990817308426, best loss 0.04034990817308426\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0006833169027231634, best loss 0.0006833169027231634\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.03735480085015297, best loss 0.0006833169027231634\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.038, current formula \\left(0.002x_1^{-1.932} + 0.129x_2^{-0.488}-2.442x_3^{-0.190}-2.956x_4^{-0.079} + 5.354\\right)\n",
      "  Finished run #4, loss 0.03743605315685272, best loss 0.0006833169027231634\n",
      "34 seconds passed from the start, the iteration took 32 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.189x_{1}^{4.5}+1.206x_{2}^{4.5}+1.736x_{3}^{2.5}-0.711x_{4}^{4.5}-1.137$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(8500.469x_1^{41.414}-0.046x_2^{-0.219} + 1.392x_3^{2.950}-1.433x_4^{0.049} + 0.581\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 8028462.971131046\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0008673677803017199, best loss 0.0008673677803017199\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0024793297052383423, best loss 0.0008673677803017199\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.00196, current formula \\left(-0.677x_1^{3.686} + 0.465x_2^{0.590}-0.551x_3^{0.148}-0.158x_4^{0.968}-1.011\\right)\n",
      "  Finished run #3, loss 0.0008043718407861888, best loss 0.0008043718407861888\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.006009235978126526, best loss 0.0008043718407861888\n",
      "54 seconds passed from the start, the iteration took 20 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.675x_{1}^{6.0}+0.834x_{2}^{5.0}-0.273x_{3}^{2.5}-0.168x_{4}^{5.5}-1.323$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.634x_1^{5.114} + 0.730x_2^{5.856}-0.511x_3^{0.104}-0.109x_4^{0.986}-0.873\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.100673363762327\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.017, current formula \\left(-1.095x_1^{0.008}-0.631x_2^{-0.020}-3.946x_3^{-0.047} + 2.960x_4^{-0.093} + 0.169\\right)\n",
      "    Epoch 10000, current loss 0.0165, current formula \\left(-1.096x_1^{0.007}-0.647x_2^{-0.023}-6.417x_3^{-0.030} + 5.454x_4^{-0.053} + 0.169\\right)\n",
      "  Finished run #1, loss 0.01646966114640236, best loss 0.01646966114640236\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.00028700969414785504, best loss 0.00028700969414785504\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0065, current formula \\left(-10.548x_1^{9.211} + 4499.714x_2^{23.424}-1.660x_3^{-0.150}-0.652x_4^{2.847}-0.372\\right)\n",
      "  Finished run #3, loss 0.005906354170292616, best loss 0.00028700969414785504\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.00040338258258998394, best loss 0.00028700969414785504\n",
      "1 minutes 27 seconds passed from the start, the iteration took 33 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.23x_{1}^{3.5}+0.333x_{2}^{2.5}+0.559x_{3}^{2.0}-1.099x_{4}^{0.5}-1.938$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.081x_1^{1.755}-1.011x_2^{-0.055} + 0.554x_3^{2.249}-1.006x_4^{0.609}-0.900\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.3957320973185927\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00828, current formula \\left(1.888x_1^{-0.163}-2.401x_2^{-0.132}-14.462x_3^{47.749} + 1.669x_4^{-0.079}-0.678\\right)\n",
      "    Epoch 10000, current loss 0.0078, current formula \\left(3.197x_1^{-0.102}-3.704x_2^{-0.091}-19.120x_3^{52.662} + 1.667x_4^{-0.079}-0.682\\right)\n",
      "  Finished run #1, loss 0.007797351572662592, best loss 0.007797351572662592\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.010641127824783325, best loss 0.007797351572662592\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0061689335852861404, best loss 0.0061689335852861404\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.004517701454460621, best loss 0.004517701454460621\n",
      "2 minutes 3 seconds passed from the start, the iteration took 36 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.659x_{1}^{4.5}+1.29x_{2}^{0.5}-0.511x_{3}^{6.0}+0.181x_{4}^{5.5}-0.299$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.596x_1^{3.255}-2.044x_2^{-0.134}-0.354x_3^{4.665} + 2.922x_4^{0.007} + 0.079\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.857286266897303\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[0.705387268501682, 8028462.971131046, 3.100673363762327, 1.3957320973185927, 5.857286266897303]\n",
      "For 0 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 8.156694093486294e-06, best loss 8.156694093486294e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.021x_{1}^{3.5}-0.652x_{2}^{0.917}-1.225x_{3}^{1.5}-0.724x_{4}^{1.083}+0.227$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.075x_1^{3.711}-0.654x_2^{0.737}-1.221x_3^{1.743}-0.612x_4^{1.164} + 0.187\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.017707679007974778\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.9745422125415644e-06, best loss 2.9745422125415644e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "5 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.852x_{1}^{0.083}-1.334x_{2}^{1.75}-0.412x_{3}^{3.75}-1.055x_{4}^{1.833}-1.068$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.994x_1^{0.166}-1.337x_2^{1.741}-0.409x_3^{3.528}-1.057x_4^{1.800}-0.198\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.17237976601615165\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.00030915127717889845, best loss 0.00030915127717889845\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 6.80158264003694e-05, best loss 6.80158264003694e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 9.218080231221393e-05, best loss 6.80158264003694e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.005383823998272419, best loss 6.80158264003694e-05\n",
      "18 seconds passed from the start, the iteration took 14 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.657x_{1}^{4.583}-0.213x_{2}^{1.083}-0.158x_{3}^{1.25}-0.192x_{4}^{2.833}+0.695$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.568x_1^{4.553}-3.187x_2^{0.030} + 2.174x_3^{-0.013}-0.167x_4^{1.300} + 1.468\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.2163256800399616\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0008296475280076265, best loss 0.0008296475280076265\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.001235198462381959, best loss 0.0008296475280076265\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.001962666865438223, best loss 0.0008296475280076265\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0009860638529062271, best loss 0.0008296475280076265\n",
      "27 seconds passed from the start, the iteration took 9 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.401x_{1}^{5.5}-0.277x_{2}^{2.583}+0.636x_{3}^{1.0}-2.125x_{4}^{3.75}+1.018$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.131x_1^{0.103}-0.118x_2^{4.102} + 0.877x_3^{0.593}-2.216x_4^{4.163} + 2.602\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.152183407276323\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.004211184568703175, best loss 0.004211184568703175\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0007072753505781293, best loss 0.0007072753505781293\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0006538288434967399, best loss 0.0006538288434967399\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.00453972676768899, best loss 0.0006538288434967399\n",
      "42 seconds passed from the start, the iteration took 15 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.17x_{1}^{4.167}-1.502x_{2}^{1.0}+1.422x_{3}^{2.667}+0.472x_{4}^{4.167}-1.726$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.549x_1^{-0.007}-1.506x_2^{1.509} + 1.718x_3^{2.973}-0.154x_4^{-0.151}-0.063\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.617771779615031\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[0.017707679007974778, 0.17237976601615165, 2.2163256800399616, 4.152183407276323, 4.617771779615031]\n",
      "For 0 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.4090917324647307e-06, best loss 3.4090917324647307e-06\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.382x_{1}^{6.0}-0.008x_{2}^{3.0}-0.649$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.382x_1^{6.002}-0.459x_2^{0.004}-0.194\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8777209149811191\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.4197531998948474e-12, best loss 2.4197531998948474e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.038x_{1}^{2.0}-0.586x_{2}^{3.0}-0.606$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.038x_1^{1.999}-0.586x_2^{3.000}-0.606\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.882841998567813e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00976, current formula \\left(-1.645x_1^{6.686}-1.710x_2^{-0.065} + 1.105\\right)\n",
      "    Epoch 10000, current loss 0.00961, current formula \\left(-1.645x_1^{6.677}-2.500x_2^{-0.046} + 1.898\\right)\n",
      "  Finished run #1, loss 0.00960551667958498, best loss 0.00960551667958498\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.718962754256037e-12, best loss 1.718962754256037e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "17 seconds passed from the start, the iteration took 14 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.578x_{1}^{6.0}+0.48x_{2}^{3.0}-0.82$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.578x_1^{6.000} + 0.480x_2^{3.000}-0.820\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.703615440528665e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.02499689720571041, best loss 0.02499689720571041\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.812683354454226e-13, best loss 2.812683354454226e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "23 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.089x_{1}^{5.0}+0.711x_{2}^{6.0}+0.675$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.089x_1^{5.000} + 0.711x_2^{6.000} + 0.675\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.87335261034616e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.183, current formula \\left(7.112x_1^{-0.068}-0.982x_2^{2.767}-7.657\\right)\n",
      "    Epoch 10000, current loss 0.181, current formula \\left(10.286x_1^{-0.049}-0.983x_2^{2.784}-10.845\\right)\n",
      "  Finished run #1, loss 0.18068772554397583, best loss 0.18068772554397583\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.8358869112444776e-12, best loss 1.8358869112444776e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "37 seconds passed from the start, the iteration took 14 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -2.443x_{1}^{4.0}-0.731x_{2}^{4.0}+0.265$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.443x_1^{4.000}-0.731x_2^{4.000} + 0.265\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.364796606954769e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.8777209149811191, 6.882841998567813e-08, 6.703615440528665e-11, 4.87335261034616e-09, 5.364796606954769e-10]\n",
      "For 4 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0242, current formula \\left(-3.030x_1^{-0.055}-0.223x_2^{-0.104} + 2.038\\right)\n",
      "  Finished run #1, loss 0.023716280236840248, best loss 0.023716280236840248\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.000835, current formula \\left(0.864x_1^{1.530}-1.128x_2^{-0.022}-0.608\\right)\n",
      "    Epoch 10000, current loss 0.000822, current formula \\left(0.863x_1^{1.531}-1.536x_2^{-0.017}-0.200\\right)\n",
      "  Finished run #2, loss 0.0008216925198212266, best loss 0.0008216925198212266\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0233934223651886, best loss 0.0008216925198212266\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0225, current formula \\left(-5.104x_1^{-0.036} + 0.180x_2^{0.860} + 3.771\\right)\n",
      "    Epoch 10000, current loss 0.0221, current formula \\left(-6.750x_1^{-0.028} + 0.178x_2^{0.894} + 5.423\\right)\n",
      "  Finished run #4, loss 0.022116536274552345, best loss 0.0008216925198212266\n",
      "45 seconds passed from the start, the iteration took 45 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.872x_{1}^{1.5}+0.151x_{2}^{1.0}-1.848$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.863x_1^{1.531}-1.536x_2^{-0.017}-0.200\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.3198060815706925\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0348, current formula \\left(1.172x_1^{2.370}-4.409x_2^{-0.046} + 3.798\\right)\n",
      "    Epoch 10000, current loss 0.0346, current formula \\left(1.171x_1^{2.372}-5.670x_2^{-0.036} + 5.062\\right)\n",
      "  Finished run #1, loss 0.03458832949399948, best loss 0.03458832949399948\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0351, current formula \\left(1.173x_1^{2.368}-3.471x_2^{-0.056} + 2.857\\right)\n",
      "    Epoch 10000, current loss 0.0347, current formula \\left(1.171x_1^{2.372}-5.119x_2^{-0.040} + 4.510\\right)\n",
      "  Finished run #2, loss 0.034674424678087234, best loss 0.03458832949399948\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 9.36140054363932e-13, best loss 9.36140054363932e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 13 seconds passed from the start, the iteration took 28 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.14x_{1}^{2.5}+0.885x_{2}^{5.0}-0.918$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.140x_1^{2.500} + 0.885x_2^{5.000}-0.918\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.5777922019187825e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.057, current formula \\left(4.566x_1^{-0.070}-1.281x_2^{0.066}-2.596\\right)\n",
      "  Finished run #1, loss 0.05693826079368591, best loss 0.05693826079368591\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0571, current formula \\left(4.438x_1^{-0.072}-6.704x_2^{0.011} + 2.960\\right)\n",
      "  Finished run #2, loss 0.05569102242588997, best loss 0.05569102242588997\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.05753617361187935, best loss 0.05569102242588997\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0008146733161993325, best loss 0.0008146733161993325\n",
      "1 minutes 35 seconds passed from the start, the iteration took 22 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.311x_{1}^{2.0}-0.153x_{2}^{1.5}+1.607$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.316x_1^{1.983}-2.392x_2^{0.016} + 3.903\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.4987212086194384\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.010390237905085087, best loss 0.010390237905085087\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0114, current formula \\left(-3.648x_1^{-0.032} + 2.518x_2^{0.030} + 1.865\\right)\n",
      "  Finished run #2, loss 0.011386478319764137, best loss 0.010390237905085087\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0113, current formula \\left(-1.916x_1^{-0.056} + 0.840x_2^{0.111} + 1.817\\right)\n",
      "  Finished run #3, loss 0.010218576528131962, best loss 0.010218576528131962\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.1695889442646665e-12, best loss 2.1695889442646665e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 57 seconds passed from the start, the iteration took 22 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.496x_{1}^{3.0}+0.275x_{2}^{1.0}+0.295$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.496x_1^{3.000} + 0.275x_2^{1.000} + 0.295\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.044382854815012e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00846, current formula \\left(-1.445x_1^{-0.049} + 0.472x_2^{5.354} + 1.359\\right)\n",
      "    Epoch 10000, current loss 0.0084, current formula \\left(-2.057x_1^{-0.035} + 0.472x_2^{5.355} + 1.973\\right)\n",
      "  Finished run #1, loss 0.008401645347476006, best loss 0.008401645347476006\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0138, current formula \\left(-1.392x_1^{-0.054}-1.264x_2^{-0.052} + 2.703\\right)\n",
      "  Finished run #2, loss 0.013807040639221668, best loss 0.008401645347476006\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.014181237667798996, best loss 0.008401645347476006\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.013584158383309841, best loss 0.008401645347476006\n",
      "2 minutes 25 seconds passed from the start, the iteration took 28 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.489x_{1}^{5.0}+0.51x_{2}^{5.0}-0.241$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.058x_1^{-0.035} + 0.472x_2^{5.355} + 1.973\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.372894793892085\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.3198060815706925, 2.5777922019187825e-10, 2.4987212086194384, 7.044382854815012e-10, 7.372894793892085]\n",
      "For 2 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0268, current formula \\left(3.086x_1^{-0.045} + 0.414x_2^{1.553}-4.024\\right)\n",
      "    Epoch 10000, current loss 0.0265, current formula \\left(4.558x_1^{-0.032} + 0.413x_2^{1.574}-5.499\\right)\n",
      "  Finished run #1, loss 0.026512235403060913, best loss 0.026512235403060913\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.7064572411379375e-12, best loss 1.7064572411379375e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "15 seconds passed from the start, the iteration took 15 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.81x_{1}^{3.833}+0.354x_{2}^{2.917}-0.546$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.810x_1^{3.833} + 0.354x_2^{2.917}-0.546\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.3229153590118585e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 4.063878140253552e-12, best loss 4.063878140253552e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "17 seconds passed from the start, the iteration took 1 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.434x_{1}^{5.167}+1.04x_{2}^{2.083}+1.391$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.434x_1^{5.167} + 1.040x_2^{2.083} + 1.391\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.033232249232242e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.022878427058458328, best loss 0.022878427058458328\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.048666179180145264, best loss 0.022878427058458328\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.0565481866134374e-12, best loss 1.0565481866134374e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "26 seconds passed from the start, the iteration took 9 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.665x_{1}^{5.333}+0.986x_{2}^{3.167}-0.288$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.665x_1^{5.333} + 0.986x_2^{3.167}-0.288\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8959429581855148e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.942576065834146e-05, best loss 2.942576065834146e-05\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.6883933969656937e-05, best loss 2.6883933969656937e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.008942930959165096, best loss 2.6883933969656937e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.009095248766243458, best loss 2.6883933969656937e-05\n",
      "32 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.446x_{1}^{5.0}+0.027x_{2}^{2.333}-0.163$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.444x_1^{4.994} + 0.105x_2^{0.076}-0.252\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0220143211032928\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0056528570130467415, best loss 0.0056528570130467415\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 8.95591923105038e-13, best loss 8.95591923105038e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "35 seconds passed from the start, the iteration took 3 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.128x_{1}^{4.167}+0.359x_{2}^{3.5}-0.144$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.128x_1^{4.167} + 0.359x_2^{3.500}-0.144\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.809483605290211e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[4.3229153590118585e-10, 2.033232249232242e-10, 1.8959429581855148e-10, 1.0220143211032928, 5.809483605290211e-09]\n",
      "For 4 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0935, current formula \\left(-0.263x_1^{0.998} + 2.036x_2^{-0.028}-4.713x_3^{-0.076} + 3.186\\right)\n",
      "  Finished run #1, loss 0.09333398938179016, best loss 0.09333398938179016\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.001231847913004458, best loss 0.001231847913004458\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0015028244815766811, best loss 0.001231847913004458\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0012362035922706127, best loss 0.001231847913004458\n",
      "14 seconds passed from the start, the iteration took 14 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.152x_{1}^{5.0}-0.095x_{2}^{5.0}+1.692x_{3}^{3.0}-0.277$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.746x_1^{-0.013}-0.066x_2^{3.434} + 1.685x_3^{2.969}-2.077\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.917898946688601\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.951221728276666e-12, best loss 3.951221728276666e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "16 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.351x_{1}^{5.0}+0.111x_{2}^{3.0}-0.46x_{3}^{6.0}-0.827$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.351x_1^{5.000} + 0.111x_2^{3.000}-0.460x_3^{6.000}-0.827\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.612923682450031e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.1, current formula \\left(0.938x_1^{3.226}-1.563x_2^{6.264} + 4.455x_3^{-0.054}-6.242\\right)\n",
      "    Epoch 10000, current loss 0.099, current formula \\left(0.936x_1^{3.186}-1.566x_2^{6.281} + 7.181x_3^{-0.035}-8.977\\right)\n",
      "  Finished run #1, loss 0.09898222237825394, best loss 0.09898222237825394\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.4510348218116365e-12, best loss 1.4510348218116365e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "36 seconds passed from the start, the iteration took 20 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.754x_{1}^{5.0}-1.296x_{2}^{3.0}-1.607x_{3}^{6.0}-1.085$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.754x_1^{5.000}-1.296x_2^{3.000}-1.607x_3^{6.000}-1.085\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.789185087135202e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.004938783124089241, best loss 0.004938783124089241\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 3.3244962772266407e-12, best loss 3.3244962772266407e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "40 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.271x_{1}^{4.0}-0.458x_{2}^{2.0}-0.432x_{3}^{5.0}+0.562$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.271x_1^{4.000}-0.458x_2^{2.000}-0.432x_3^{5.000} + 0.562\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.6264444146029616e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0164964497089386, best loss 0.0164964497089386\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.2766676821610035e-12, best loss 1.2766676821610035e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "49 seconds passed from the start, the iteration took 9 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.183x_{1}^{4.0}+0.561x_{2}^{4.0}+0.759x_{3}^{4.0}+0.602$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.183x_1^{4.000} + 0.561x_2^{4.000} + 0.759x_3^{4.000} + 0.602\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1951029372474815e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[4.917898946688601, 3.612923682450031e-09, 6.789185087135202e-11, 3.6264444146029616e-09, 1.1951029372474815e-09]\n",
      "For 4 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.03418006747961044, best loss 0.03418006747961044\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 6.128512194253366e-12, best loss 6.128512194253366e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "6 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.511x_{1}^{3.5}-0.95x_{2}^{3.5}-0.373x_{3}^{2.0}-0.056$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.511x_1^{3.500}-0.950x_2^{3.500}-0.373x_3^{2.000}-0.056\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.407409162891965e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.023181748343373e-12, best loss 3.023181748343373e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "8 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.177x_{1}^{6.0}-1.362x_{2}^{2.5}+0.13x_{3}^{1.5}-0.749$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.177x_1^{6.000}-1.362x_2^{2.500} + 0.130x_3^{1.500}-0.749\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.3159584533184443e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.124, current formula \\left(-1.400x_1^{1.028}-11.486x_2^{-0.017}-0.805x_3^{0.253} + 12.123\\right)\n",
      "    Epoch 10000, current loss 0.123, current formula \\left(-1.401x_1^{1.028}-14.721x_2^{-0.014}-0.806x_3^{0.252} + 15.362\\right)\n",
      "  Finished run #1, loss 0.12325240671634674, best loss 0.12325240671634674\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0673, current formula \\left(5.356x_1^{-0.041} + 1.594x_2^{4.154} + 0.402x_3^{-0.155}-7.278\\right)\n",
      "    Epoch 10000, current loss 0.0655, current formula \\left(7.097x_1^{-0.032} + 1.594x_2^{4.155} + 0.543x_3^{-0.125}-9.172\\right)\n",
      "  Finished run #2, loss 0.06552641093730927, best loss 0.06552641093730927\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 4.75849394609984e-11, best loss 4.75849394609984e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "43 seconds passed from the start, the iteration took 35 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.356x_{1}^{1.0}+1.611x_{2}^{4.0}-0.322x_{3}^{1.5}-0.453$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.356x_1^{1.000} + 1.611x_2^{4.000}-0.322x_3^{1.500}-0.453\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.957373642015032e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0102, current formula \\left(2.635x_1^{-0.033} + 0.487x_2^{1.794} + 1.444x_3^{2.429}-1.951\\right)\n",
      "    Epoch 10000, current loss 0.01, current formula \\left(4.114x_1^{-0.022} + 0.488x_2^{1.791} + 1.445x_3^{2.429}-3.434\\right)\n",
      "  Finished run #1, loss 0.010007391683757305, best loss 0.010007391683757305\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 5.832774367664495e-12, best loss 5.832774367664495e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 2 seconds passed from the start, the iteration took 18 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.499x_{1}^{1.5}+0.499x_{2}^{1.5}+1.439x_{3}^{2.5}+0.965$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.499x_1^{1.500} + 0.499x_2^{1.500} + 1.439x_3^{2.500} + 0.965\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.215349256687919e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.028248224407434464, best loss 0.028248224407434464\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0282, current formula \\left(1.050x_1^{5.473} + 3.103x_2^{-0.049} + 0.401x_3^{6.421}-2.705\\right)\n",
      "    Epoch 10000, current loss 0.0279, current formula \\left(1.049x_1^{5.446} + 4.500x_2^{-0.035} + 0.401x_3^{6.411}-4.108\\right)\n",
      "  Finished run #2, loss 0.02792559564113617, best loss 0.02792559564113617\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0284, current formula \\left(1.051x_1^{5.488} + 2.595x_2^{-0.058} + 0.402x_3^{6.430}-2.196\\right)\n",
      "    Epoch 10000, current loss 0.028, current formula \\left(1.049x_1^{5.455} + 3.930x_2^{-0.040} + 0.401x_3^{6.414}-3.537\\right)\n",
      "  Finished run #3, loss 0.02801743894815445, best loss 0.02792559564113617\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0282, current formula \\left(1.050x_1^{5.474} + 3.073x_2^{-0.050} + 0.402x_3^{6.423}-2.676\\right)\n",
      "    Epoch 10000, current loss 0.028, current formula \\left(1.049x_1^{5.450} + 4.278x_2^{-0.037} + 0.401x_3^{6.412}-3.885\\right)\n",
      "  Finished run #4, loss 0.027958739548921585, best loss 0.02792559564113617\n",
      "1 minutes 56 seconds passed from the start, the iteration took 55 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.943x_{1}^{5.0}-0.872x_{2}^{3.5}+0.24x_{3}^{2.5}+0.742$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.049x_1^{5.446} + 4.500x_2^{-0.035} + 0.401x_3^{6.411}-4.108\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 11.487333458090148\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[2.407409162891965e-09, 1.3159584533184443e-10, 5.957373642015032e-09, 3.215349256687919e-10, 11.487333458090148]\n",
      "For 4 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0605, current formula \\left(-0.254x_1^{23.335}-3.777x_2^{-0.036} + 1.405x_3^{1.177} + 3.704\\right)\n",
      "    Epoch 10000, current loss 0.0597, current formula \\left(-0.252x_1^{23.381}-6.517x_2^{-0.022} + 1.403x_3^{1.170} + 6.449\\right)\n",
      "  Finished run #1, loss 0.0596839003264904, best loss 0.0596839003264904\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 6.382316983938319e-12, best loss 6.382316983938319e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "17 seconds passed from the start, the iteration took 17 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.229x_{1}^{4.667}+1.108x_{2}^{3.583}+1.242x_{3}^{1.667}-0.261$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.229x_1^{4.667} + 1.108x_2^{3.583} + 1.242x_3^{1.667}-0.261\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.760592421324759e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 5.732856152462773e-05, best loss 5.732856152462773e-05\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.01712324656546116, best loss 5.732856152462773e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.061319757252931595, best loss 5.732856152462773e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 5.620526644634083e-05, best loss 5.620526644634083e-05\n",
      "29 seconds passed from the start, the iteration took 12 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.269x_{1}^{2.75}+0.587x_{2}^{4.083}-0.037x_{3}^{6.0}+0.786$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.269x_1^{2.753} + 0.588x_2^{4.108} + 0.323x_3^{-0.018} + 0.452\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.208362354073666\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.730811024017176e-12, best loss 1.730811024017176e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "31 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.045x_{1}^{5.417}-0.724x_{2}^{4.0}-0.391x_{3}^{4.75}-0.913$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.045x_1^{5.416}-0.724x_2^{4.000}-0.391x_3^{4.750}-0.913\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.953134778451288e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0012736439239233732, best loss 0.0012736439239233732\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.093, current formula \\left(10.889x_1^{-0.014} + 2.435x_2^{0.015}-8.062x_3^{-0.027}-3.382\\right)\n",
      "    Epoch 10000, current loss 0.0924, current formula \\left(14.561x_1^{-0.011} + 2.435x_2^{0.016}-11.736x_3^{-0.019}-3.380\\right)\n",
      "  Finished run #2, loss 0.09235882014036179, best loss 0.0012736439239233732\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0489, current formula \\left(4.639x_1^{-0.030} + 0.212x_2^{3.160} + 1.124x_3^{3.368}-3.334\\right)\n",
      "    Epoch 10000, current loss 0.0482, current formula \\left(6.926x_1^{-0.021} + 0.212x_2^{3.144} + 1.123x_3^{3.354}-5.628\\right)\n",
      "  Finished run #3, loss 0.048210203647613525, best loss 0.0012736439239233732\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.05291248857975006, best loss 0.0012736439239233732\n",
      "1 minutes 9 seconds passed from the start, the iteration took 38 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.075x_{1}^{2.25}+0.255x_{2}^{1.167}+0.968x_{3}^{3.0}+1.749$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.094x_1^{2.135} + 1.624x_2^{0.043} + 0.955x_3^{2.850} + 0.324\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.7433172437591453\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0555, current formula \\left(-0.814x_1^{0.080} + 2.483x_2^{0.010}-2.884x_3^{-0.093} + 1.801\\right)\n",
      "    Epoch 10000, current loss 0.0547, current formula \\left(-1.107x_1^{0.059} + 2.646x_2^{0.009}-4.072x_3^{-0.068} + 3.123\\right)\n",
      "  Finished run #1, loss 0.054698895663022995, best loss 0.054698895663022995\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.05578703060746193, best loss 0.054698895663022995\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0003465069457888603, best loss 0.0003465069457888603\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.00035562782431952655, best loss 0.0003465069457888603\n",
      "1 minutes 38 seconds passed from the start, the iteration took 29 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.103x_{1}^{5.833}-0.05x_{2}^{3.333}+1.247x_{3}^{5.333}+0.17$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.172x_1^{0.012}-0.054x_2^{2.456} + 1.259x_3^{5.349}-0.974\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.302069617446444\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[2.760592421324759e-09, 5.208362354073666, 3.953134778451288e-08, 0.7433172437591453, 5.302069617446444]\n",
      "For 2 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0662, current formula \\left(-0.758x_1^{3.180} + 6.517x_2^{-0.011} + 0.474x_3^{1.080}-6.287x_4^{-0.017} + 0.005\\right)\n",
      "    Epoch 10000, current loss 0.0661, current formula \\left(-0.759x_1^{3.184} + 8.178x_2^{-0.009} + 0.474x_3^{1.079}-7.953x_4^{-0.014} + 0.010\\right)\n",
      "  Finished run #1, loss 0.06606684625148773, best loss 0.06606684625148773\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.04072442278265953, best loss 0.04072442278265953\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0185, current formula \\left(-0.973x_1^{4.612}-0.408x_2^{0.607}-4.857x_3^{-0.016} + 1.094x_4^{5.045} + 5.436\\right)\n",
      "    Epoch 10000, current loss 0.0184, current formula \\left(-0.973x_1^{4.614}-0.407x_2^{0.610}-5.666x_3^{-0.014} + 1.093x_4^{5.043} + 6.244\\right)\n",
      "  Finished run #3, loss 0.01841145008802414, best loss 0.01841145008802414\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0792, current formula \\left(5.321x_1^{-0.016}-0.403x_2^{1.696} + 0.526x_3^{1.505}-6.201x_4^{-0.015} + 1.089\\right)\n",
      "  Finished run #4, loss 0.07908178865909576, best loss 0.01841145008802414\n",
      "1 minutes 25 seconds passed from the start, the iteration took 1 minutes 25 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.879x_{1}^{4.0}-0.34x_{2}^{2.0}+0.572x_{3}^{3.0}+1.155x_{4}^{5.0}+0.206$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.973x_1^{4.614}-0.407x_2^{0.610}-5.666x_3^{-0.014} + 1.093x_4^{5.043} + 6.244\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.641907502679462\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.8980088334341616e-11, best loss 1.8980088334341616e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 30 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.913x_{1}^{5.0}-0.444x_{2}^{5.0}+1.805x_{3}^{5.0}-1.283x_{4}^{2.0}-1.456$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.913x_1^{5.000}-0.444x_2^{5.000} + 1.805x_3^{5.000}-1.283x_4^{2.000}-1.456\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.2715799611698153e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.102, current formula \\left(2.911x_1^{-0.064} + 0.553x_2^{16.652}-1.474x_3^{0.838} + 0.252x_4^{0.658}-5.287\\right)\n",
      "  Finished run #1, loss 0.10202406346797943, best loss 0.10202406346797943\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.136, current formula \\left(3.026x_1^{-0.065}-3.653x_2^{-0.008} + 3.655x_3^{-0.094} + 0.228x_4^{0.972}-6.485\\right)\n",
      "  Finished run #2, loss 0.13502369821071625, best loss 0.10202406346797943\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.026026593521237373, best loss 0.026026593521237373\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 4.156675004196586e-12, best loss 4.156675004196586e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 54 seconds passed from the start, the iteration took 1 minutes 24 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.603x_{1}^{6.0}+0.347x_{2}^{4.0}-1.271x_{3}^{1.0}+0.441x_{4}^{1.0}-2.15$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.603x_1^{6.000} + 0.347x_2^{4.000}-1.271x_3^{1.000} + 0.441x_4^{1.000}-2.150\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.0493592008582104e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.060171760618686676, best loss 0.060171760618686676\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0163, current formula \\left(0.631x_1^{5.671}-1.328x_2^{2.078} + 2.242x_3^{0.012}-1.946x_4^{-0.046}-0.583\\right)\n",
      "    Epoch 10000, current loss 0.0162, current formula \\left(0.631x_1^{5.676}-1.328x_2^{2.074} + 2.947x_3^{0.009}-2.681x_4^{-0.035}-0.552\\right)\n",
      "  Finished run #2, loss 0.016249803826212883, best loss 0.016249803826212883\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0162, current formula \\left(0.631x_1^{5.685}-1.328x_2^{2.073} + 1.140x_3^{0.023}-2.874x_4^{-0.033} + 1.449\\right)\n",
      "    Epoch 10000, current loss 0.0162, current formula \\left(0.631x_1^{5.682}-1.328x_2^{2.071} + 1.972x_3^{0.013}-3.722x_4^{-0.026} + 1.466\\right)\n",
      "  Finished run #3, loss 0.016179634258151054, best loss 0.016179634258151054\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.00018529107910580933, best loss 0.00018529107910580933\n",
      "4 minutes 5 seconds passed from the start, the iteration took 1 minutes 11 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.659x_{1}^{6.0}-1.33x_{2}^{2.0}+0.064x_{3}^{3.0}+0.691x_{4}^{5.0}-0.52$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.652x_1^{5.759}-1.327x_2^{1.999}-0.509x_3^{-0.026} + 0.682x_4^{5.029} + 0.019\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0925257669802715\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.029535925015807152, best loss 0.029535925015807152\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 3.8238036868809555e-12, best loss 3.8238036868809555e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "4 minutes 22 seconds passed from the start, the iteration took 17 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.642x_{1}^{4.0}+0.483x_{2}^{3.0}+1.622x_{3}^{4.0}+0.596x_{4}^{3.0}+0.291$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.642x_1^{4.000} + 0.483x_2^{3.000} + 1.622x_3^{4.000} + 0.596x_4^{3.000} + 0.291\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.400552104283128e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[9.641907502679462, 2.2715799611698153e-09, 2.0493592008582104e-10, 1.0925257669802715, 5.400552104283128e-10]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.8459046791097222e-11, best loss 1.8459046791097222e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "5 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.573x_{1}^{2.0}-1.865x_{2}^{2.0}-0.898x_{3}^{4.5}+0.479x_{4}^{1.0}-1.022$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.573x_1^{2.000}-1.865x_2^{2.000}-0.898x_3^{4.500} + 0.479x_4^{1.000}-1.022\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.5083941996686514e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.014089646749198437, best loss 0.014089646749198437\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.014221224002540112, best loss 0.014089646749198437\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 3.4404276649802057e-10, best loss 3.4404276649802057e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "27 seconds passed from the start, the iteration took 22 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.549x_{1}^{2.0}+0.669x_{2}^{2.0}+0.362x_{3}^{3.5}-0.682x_{4}^{0.5}+1.594$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.549x_1^{2.000} + 0.669x_2^{2.000} + 0.362x_3^{3.500}-0.682x_4^{0.500} + 1.594\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.4294731916682698e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0485, current formula \\left(5.662x_1^{-0.028}-6.053x_2^{-0.027}-3.678x_3^{0.014}-1.195x_4^{-0.013} + 4.296\\right)\n",
      "    Epoch 10000, current loss 0.048, current formula \\left(9.212x_1^{-0.018}-9.595x_2^{-0.018}-3.678x_3^{0.014}-1.202x_4^{-0.013} + 4.296\\right)\n",
      "  Finished run #1, loss 0.04801196604967117, best loss 0.04801196604967117\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0484, current formula \\left(6.586x_1^{-0.024}-4.825x_2^{-0.034}-2.038x_3^{0.026} + 1.731x_4^{0.010}-2.424\\right)\n",
      "    Epoch 10000, current loss 0.048, current formula \\left(9.800x_1^{-0.017}-8.042x_2^{-0.021}-2.034x_3^{0.025} + 1.730x_4^{0.010}-2.422\\right)\n",
      "  Finished run #2, loss 0.048002008348703384, best loss 0.048002008348703384\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.00586, current formula \\left(-0.960x_1^{3.590}-2.273x_2^{-0.062}-0.213x_3^{3.934} + 0.170x_4^{11.593} + 1.723\\right)\n",
      "    Epoch 10000, current loss 0.00562, current formula \\left(-0.960x_1^{3.580}-3.432x_2^{-0.043}-0.209x_3^{3.854} + 0.164x_4^{11.245} + 2.885\\right)\n",
      "  Finished run #3, loss 0.005615648813545704, best loss 0.005615648813545704\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 1.1201928273862904e-11, best loss 1.1201928273862904e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 27 seconds passed from the start, the iteration took 2 minutes 0 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.976x_{1}^{3.5}+0.596x_{2}^{1.0}-0.146x_{3}^{3.0}+0.065x_{4}^{3.0}-0.987$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.976x_1^{3.500} + 0.596x_2^{1.000}-0.146x_3^{3.000} + 0.065x_4^{3.000}-0.987\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0352136117466573e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0356, current formula \\left(-1.036x_1^{1.249} + 2.258x_2^{-0.071} + 0.542x_3^{0.353}-0.129x_4^{8.933}-1.815\\right)\n",
      "    Epoch 10000, current loss 0.0352, current formula \\left(-1.037x_1^{1.254} + 3.185x_2^{-0.053} + 0.597x_3^{0.308}-0.129x_4^{8.958}-2.805\\right)\n",
      "  Finished run #1, loss 0.035219721496105194, best loss 0.035219721496105194\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.003424225142225623, best loss 0.003424225142225623\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0772, current formula \\left(3.754x_1^{-0.042} + 1.219x_2^{-0.101} + 0.511x_3^{0.428}-0.030x_4^{-0.102}-5.086\\right)\n",
      "  Finished run #3, loss 0.07638367265462875, best loss 0.003424225142225623\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.03527706116437912, best loss 0.003424225142225623\n",
      "4 minutes 1 seconds passed from the start, the iteration took 1 minutes 34 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.968x_{1}^{1.5}-1.05x_{2}^{5.5}+0.37x_{3}^{2.0}-0.058x_{4}^{5.5}+0.936$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.964x_1^{1.478}-0.948x_2^{4.857} + 3.063x_3^{0.047} + 0.071x_4^{-0.064}-1.956\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.647364188708266\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.005949580576270819, best loss 0.005949580576270819\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.00013589805166702718, best loss 0.00013589805166702718\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0038584969006478786, best loss 0.00013589805166702718\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0168, current formula \\left(-0.018x_1^{-0.335}-0.122x_2^{-0.127}-3.530x_3^{-0.089} + 0.913x_4^{1.536} + 6.298\\right)\n",
      "    Epoch 10000, current loss 0.0159, current formula \\left(-0.023x_1^{-0.307}-0.197x_2^{-0.094}-4.771x_3^{-0.069} + 0.917x_4^{1.543} + 7.628\\right)\n",
      "  Finished run #4, loss 0.015860261395573616, best loss 0.00013589805166702718\n",
      "4 minutes 53 seconds passed from the start, the iteration took 52 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.054x_{1}^{2.5}+0.327x_{2}^{6.0}+1.496x_{3}^{0.5}+1.069x_{4}^{1.5}+1.112$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.575x_1^{0.005} + 0.322x_2^{6.220} + 1.504x_3^{0.496} + 1.063x_4^{1.487}-0.443\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.222595576033378\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.5083941996686514e-09, 1.4294731916682698e-08, 1.0352136117466573e-08, 5.647364188708266, 1.222595576033378]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.03141942247748375, best loss 0.03141942247748375\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0321, current formula \\left(-0.388x_1^{3.162}-0.000x_2^{-2.091}-2.500x_3^{-0.037} + 1.512x_4^{3.189} + 2.594\\right)\n",
      "  Finished run #2, loss 0.03191608935594559, best loss 0.03141942247748375\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.004320216365158558, best loss 0.004320216365158558\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.00015108135994523764, best loss 0.00015108135994523764\n",
      "23 seconds passed from the start, the iteration took 23 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.368x_{1}^{2.75}-0.055x_{2}^{4.5}+0.747x_{3}^{2.25}+1.491x_{4}^{3.333}-0.217$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.358x_1^{2.665} + 0.095x_2^{-0.082} + 0.745x_3^{2.259} + 1.482x_4^{3.307}-0.332\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.337323529384914\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0055180941708385944, best loss 0.0055180941708385944\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0005143257440067828, best loss 0.0005143257440067828\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.00596, current formula \\left(-1.292x_1^{-0.030}-2.258x_2^{-0.014}-0.242x_3^{8.621}-0.855x_4^{0.184} + 3.712\\right)\n",
      "    Epoch 10000, current loss 0.0059, current formula \\left(-2.045x_1^{-0.020}-2.214x_2^{-0.014}-0.244x_3^{8.704}-0.890x_4^{0.174} + 4.459\\right)\n",
      "  Finished run #3, loss 0.005904426332563162, best loss 0.0005143257440067828\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.00042744536767713726, best loss 0.00042744536767713726\n",
      "51 seconds passed from the start, the iteration took 28 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.405x_{1}^{4.833}+0.103x_{2}^{2.917}-0.19x_{3}^{5.5}-0.863x_{4}^{0.167}+0.023$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.401x_1^{4.891} + 0.937x_2^{0.027}-0.185x_3^{5.549}-0.765x_4^{0.199}-0.966\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.1151649070688856\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.14, current formula \\left(-6.612x_1^{-0.029}-0.423x_2^{7.885}-2.023x_3^{8.644}-1.146x_4^{-0.051} + 7.892\\right)\n",
      "    Epoch 10000, current loss 0.139, current formula \\left(-9.224x_1^{-0.021}-0.424x_2^{7.850}-2.024x_3^{8.640}-1.146x_4^{-0.051} + 10.508\\right)\n",
      "  Finished run #1, loss 0.13928255438804626, best loss 0.13928255438804626\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.146260604262352, best loss 0.13928255438804626\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.2850750982761383, best loss 0.13928255438804626\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.15091758966445923, best loss 0.13928255438804626\n",
      "1 minutes 28 seconds passed from the start, the iteration took 37 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.728x_{1}^{5.833}-0.441x_{2}^{5.25}-1.951x_{3}^{5.917}+0.327x_{4}^{5.5}-0.328$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-9.224x_1^{-0.021}-0.424x_2^{7.850}-2.024x_3^{8.640}-1.146x_4^{-0.051} + 10.508\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 35.42339697773912\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.105, current formula \\left(0.629x_1^{3.208} + 1.056x_2^{4.369} + 1.314x_3^{-0.061} + 4.830x_4^{-0.067}-6.703\\right)\n",
      "    Epoch 10000, current loss 0.103, current formula \\left(0.632x_1^{3.203} + 1.053x_2^{4.341} + 1.747x_3^{-0.049} + 6.183x_4^{-0.054}-8.502\\right)\n",
      "  Finished run #1, loss 0.10316217690706253, best loss 0.10316217690706253\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.117, current formula \\left(0.707x_1^{3.118}-10.670x_2^{-0.016}-0.751x_3^{2.360} + 10.931x_4^{-0.033}-0.232\\right)\n",
      "    Epoch 10000, current loss 0.116, current formula \\left(0.708x_1^{3.129}-16.962x_2^{-0.010}-0.756x_3^{2.394} + 17.236x_4^{-0.022}-0.254\\right)\n",
      "  Finished run #2, loss 0.11580738425254822, best loss 0.10316217690706253\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 5.6636206141602585e-12, best loss 5.6636206141602585e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 8 seconds passed from the start, the iteration took 40 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.544x_{1}^{3.167}+1.304x_{2}^{4.333}-0.826x_{3}^{2.667}-1.482x_{4}^{1.667}+0.666$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.544x_1^{3.167} + 1.304x_2^{4.333}-0.826x_3^{2.667}-1.482x_4^{1.667} + 0.666\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0335309891868545e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 4.7259817587130826e-12, best loss 4.7259817587130826e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 10 seconds passed from the start, the iteration took 2 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.167x_{1}^{2.583}+1.884x_{2}^{2.667}-1.306x_{3}^{3.417}+0.482x_{4}^{2.0}-0.372$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.167x_1^{2.583} + 1.884x_2^{2.667}-1.306x_3^{3.417} + 0.482x_4^{2.000}-0.372\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.6475117566490855e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[2.337323529384914, 1.1151649070688856, 35.42339697773912, 1.0335309891868545e-09, 1.6475117566490855e-11]\n",
      "For 2 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0204, current formula \\left(-2.114x_1^{-0.037} + 0.742x_2^{4.273} + 0.625\\right)\n",
      "    Epoch 10000, current loss 0.0203, current formula \\left(-2.977x_1^{-0.027} + 0.742x_2^{4.274} + 1.491\\right)\n",
      "  Finished run #1, loss 0.020256146788597107, best loss 0.020256146788597107\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.04669633507728577, best loss 0.020256146788597107\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.8036736383966745e-12, best loss 1.8036736383966745e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "53 seconds passed from the start, the iteration took 53 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.701x_{1}^{6.0}+0.737x_{2}^{4.0}-1.672$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.701x_1^{6.000} + 0.737x_2^{4.000}-1.672\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.5137759368808474e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0158, current formula \\left(3.843x_1^{-0.045}-1.130x_2^{0.956}-3.824\\right)\n",
      "    Epoch 10000, current loss 0.0152, current formula \\left(6.000x_1^{-0.030}-1.129x_2^{0.958}-5.990\\right)\n",
      "  Finished run #1, loss 0.015168736688792706, best loss 0.015168736688792706\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.4236549222487738e-12, best loss 1.4236549222487738e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 32 seconds passed from the start, the iteration took 39 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.802x_{1}^{1.0}-1.105x_{2}^{1.0}+0.577$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.802x_1^{1.000}-1.105x_2^{1.000} + 0.577\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.8522784961969594e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.3632695233106729e-12, best loss 1.3632695233106729e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 43 seconds passed from the start, the iteration took 11 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.442x_{1}^{6.0}-1.6x_{2}^{2.0}+0.752$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.442x_1^{6.000}-1.600x_2^{2.000} + 0.752\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.3496634920784346e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 6.793276878525045e-13, best loss 6.793276878525045e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 48 seconds passed from the start, the iteration took 5 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.802x_{1}^{4.0}+0.422x_{2}^{4.0}-0.541$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.802x_1^{4.000} + 0.422x_2^{4.000}-0.541\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8060237749750742e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0028919687028974295, best loss 0.0028919687028974295\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.3286687248630367e-12, best loss 2.3286687248630367e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 57 seconds passed from the start, the iteration took 9 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.249x_{1}^{4.0}+0.355x_{2}^{2.0}-0.084$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.249x_1^{4.000} + 0.355x_2^{2.000}-0.084\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.005481102353769e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[3.5137759368808474e-10, 3.8522784961969594e-11, 1.3496634920784346e-10, 1.8060237749750742e-10, 4.005481102353769e-09]\n",
      "For 5 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.003113966668024659, best loss 0.003113966668024659\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0031195797491818666, best loss 0.003113966668024659\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0029509728774428368, best loss 0.0029509728774428368\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 1.9503687131040143e-13, best loss 1.9503687131040143e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "21 seconds passed from the start, the iteration took 21 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.247x_{1}^{4.5}+0.727x_{2}^{4.0}+0.53$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.247x_1^{4.500} + 0.727x_2^{4.000} + 0.530\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.982279673740095e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0756, current formula \\left(-1.324x_1^{-0.018} + 2.883x_2^{-0.051}-0.847\\right)\n",
      "  Finished run #1, loss 0.07558725774288177, best loss 0.07558725774288177\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0006842242437414825, best loss 0.0006842242437414825\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 9.342518078603312e-13, best loss 9.342518078603312e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "55 seconds passed from the start, the iteration took 33 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.129x_{1}^{3.0}-1.293x_{2}^{6.0}+0.986$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.129x_1^{3.000}-1.293x_2^{6.000} + 0.986\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.9529327932588104e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0691, current formula \\left(0.669x_1^{3.034} + 6.420x_2^{-0.044}-8.410\\right)\n",
      "    Epoch 10000, current loss 0.0671, current formula \\left(0.669x_1^{3.028} + 9.799x_2^{-0.031}-11.799\\right)\n",
      "  Finished run #1, loss 0.06713587045669556, best loss 0.06713587045669556\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 6.550315845288424e-13, best loss 6.550315845288424e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 33 seconds passed from the start, the iteration took 38 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.655x_{1}^{3.0}-1.387x_{2}^{1.5}-1.129$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.655x_1^{3.000}-1.387x_2^{1.500}-1.129\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.5205614545266144e-12\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 4.845577064593876e-12, best loss 4.845577064593876e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 37 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.88x_{1}^{5.0}+0.609x_{2}^{1.5}+0.284$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.880x_1^{5.000} + 0.609x_2^{1.500} + 0.284\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.039307720584475e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.013, current formula \\left(3.717x_1^{-0.044}-0.960x_2^{3.526}-4.349\\right)\n",
      "    Epoch 10000, current loss 0.0125, current formula \\left(5.348x_1^{-0.032}-0.960x_2^{3.524}-5.985\\right)\n",
      "  Finished run #1, loss 0.01252511516213417, best loss 0.01252511516213417\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 3.688671763868445e-12, best loss 3.688671763868445e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 18 seconds passed from the start, the iteration took 41 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.734x_{1}^{1.0}-0.962x_{2}^{3.5}-0.096$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.734x_1^{1.000}-0.962x_2^{3.500}-0.096\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.7950454717948786e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.982279673740095e-10, 1.9529327932588104e-09, 1.5205614545266144e-12, 6.039307720584475e-10, 4.7950454717948786e-11]\n",
      "For 5 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 1.27e-05, current formula \\left(-0.401x_1^{0.572} + 0.537x_2^{4.056} + 0.073\\right)\n",
      "  Finished run #1, loss 5.771468719606432e-11, best loss 5.771468719606432e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "22 seconds passed from the start, the iteration took 22 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.425x_{1}^{0.5}+0.538x_{2}^{4.083}+0.102$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.425x_1^{0.500} + 0.538x_2^{4.083} + 0.102\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.486313752773753e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00583, current formula \\left(-1.811x_1^{0.035} + 0.263x_2^{2.285} + 1.614\\right)\n",
      "    Epoch 10000, current loss 0.00562, current formula \\left(-0.838x_1^{0.088} + 0.263x_2^{2.287} + 0.634\\right)\n",
      "  Finished run #1, loss 0.005615436937659979, best loss 0.005615436937659979\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 1.1618580446695614e-12, best loss 1.1618580446695614e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 1 seconds passed from the start, the iteration took 39 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.369x_{1}^{4.583}+0.272x_{2}^{2.167}-0.075$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.369x_1^{4.583} + 0.272x_2^{2.167}-0.075\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.5673759623524574e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.8962502968826742e-12, best loss 2.8962502968826742e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 5 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.387x_{1}^{1.417}+0.105x_{2}^{5.833}+0.562$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.387x_1^{1.417} + 0.105x_2^{5.833} + 0.562\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.130695712203149e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 3.053791811438722e-12, best loss 3.053791811438722e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 9 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.77x_{1}^{2.833}-1.164x_{2}^{3.583}+1.054$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.770x_1^{2.833}-1.164x_2^{3.583} + 1.054\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.9585649485852627e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0102, current formula \\left(0.481x_1^{2.615} + 3.380x_2^{-0.023}-4.383\\right)\n",
      "    Epoch 10000, current loss 0.0101, current formula \\left(0.481x_1^{2.617} + 4.298x_2^{-0.019}-5.302\\right)\n",
      "  Finished run #1, loss 0.010111363604664803, best loss 0.010111363604664803\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 8.277591936542428e-13, best loss 8.277591936542428e-13\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 53 seconds passed from the start, the iteration took 44 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.471x_{1}^{2.667}-0.447x_{2}^{3.0}-0.802$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.471x_1^{2.667}-0.447x_2^{3.000}-0.802\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.6268018043774646e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[6.486313752773753e-09, 1.5673759623524574e-09, 6.130695712203149e-08, 2.9585649485852627e-10, 1.6268018043774646e-10]\n",
      "For 5 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.05691345036029816, best loss 0.05691345036029816\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.102, current formula \\left(-1.077x_1^{3.747} + 5.188x_2^{-0.036}-0.606x_3^{2.713}-4.969\\right)\n",
      "    Epoch 10000, current loss 0.101, current formula \\left(-1.077x_1^{3.753} + 7.684x_2^{-0.025}-0.605x_3^{2.711}-7.471\\right)\n",
      "  Finished run #2, loss 0.10084150731563568, best loss 0.05691345036029816\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.102, current formula \\left(-1.077x_1^{3.745} + 4.713x_2^{-0.039}-0.606x_3^{2.713}-4.492\\right)\n",
      "    Epoch 10000, current loss 0.101, current formula \\left(-1.077x_1^{3.752} + 7.167x_2^{-0.027}-0.605x_3^{2.711}-6.953\\right)\n",
      "  Finished run #3, loss 0.10096649080514908, best loss 0.05691345036029816\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0197, current formula \\left(-1.093x_1^{4.191}-1.448x_2^{4.536} + 2.649x_3^{-0.038}-2.266\\right)\n",
      "    Epoch 10000, current loss 0.0194, current formula \\left(-1.093x_1^{4.191}-1.448x_2^{4.539} + 4.089x_3^{-0.026}-3.710\\right)\n",
      "  Finished run #4, loss 0.01938626356422901, best loss 0.01938626356422901\n",
      "2 minutes 11 seconds passed from the start, the iteration took 2 minutes 11 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.121x_{1}^{4.0}-1.494x_{2}^{5.0}-0.658x_{3}^{3.0}+0.653$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.093x_1^{4.191}-1.448x_2^{4.539} + 4.090x_3^{-0.026}-3.710\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.284223660660613\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00116, current formula \\left(1.534x_1^{4.015}-0.629x_2^{2.963} + 1.293x_3^{-0.044}-1.723\\right)\n",
      "    Epoch 10000, current loss 0.00112, current formula \\left(1.534x_1^{4.013}-0.629x_2^{2.966} + 1.826x_3^{-0.032}-2.257\\right)\n",
      "  Finished run #1, loss 0.0011180868605151772, best loss 0.0011180868605151772\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.131, current formula \\left(-8.834x_1^{-0.026} + 10.032x_2^{-0.014}-0.261x_3^{1.447}-1.207\\right)\n",
      "    Epoch 10000, current loss 0.13, current formula \\left(-12.321x_1^{-0.019} + 13.497x_2^{-0.011}-0.262x_3^{1.448}-1.181\\right)\n",
      "  Finished run #2, loss 0.13015246391296387, best loss 0.0011180868605151772\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.1831226102987369e-11, best loss 1.1831226102987369e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 43 seconds passed from the start, the iteration took 1 minutes 32 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.532x_{1}^{4.0}-0.629x_{2}^{3.0}-0.235x_{3}^{1.0}-0.254$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.532x_1^{4.000}-0.629x_2^{3.000}-0.235x_3^{1.000}-0.254\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.8741054298413768e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.009590733796358109, best loss 0.009590733796358109\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0296, current formula \\left(0.147x_1^{4.412} + 2.575x_2^{-0.033}-1.794x_3^{0.039}-1.107\\right)\n",
      "  Finished run #2, loss 0.029533421620726585, best loss 0.009590733796358109\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.00924820825457573, best loss 0.00924820825457573\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0088, current formula \\left(0.137x_1^{3.928}-0.713x_2^{6.172} + 2.194x_3^{-0.027}-2.329\\right)\n",
      "    Epoch 10000, current loss 0.00878, current formula \\left(0.137x_1^{3.926}-0.712x_2^{6.173} + 2.765x_3^{-0.022}-2.901\\right)\n",
      "  Finished run #4, loss 0.008777002803981304, best loss 0.008777002803981304\n",
      "5 minutes 7 seconds passed from the start, the iteration took 1 minutes 24 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.125x_{1}^{4.0}-0.69x_{2}^{6.0}-0.451x_{3}^{6.0}-0.005$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.137x_1^{3.926}-0.712x_2^{6.173} + 2.765x_3^{-0.022}-2.901\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.860626069213467\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0844, current formula \\left(-0.705x_1^{6.875}-4.978x_2^{-0.036}-0.495x_3^{3.912} + 6.128\\right)\n",
      "    Epoch 10000, current loss 0.0839, current formula \\left(-0.705x_1^{6.878}-7.043x_2^{-0.026}-0.495x_3^{3.904} + 8.198\\right)\n",
      "  Finished run #1, loss 0.08392179757356644, best loss 0.08392179757356644\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.019, current formula \\left(1.892x_1^{-0.037} + 1.453x_2^{4.881}-0.506x_3^{2.790}-1.302\\right)\n",
      "    Epoch 10000, current loss 0.0189, current formula \\left(2.765x_1^{-0.027} + 1.452x_2^{4.880}-0.506x_3^{2.789}-2.179\\right)\n",
      "  Finished run #2, loss 0.01885896734893322, best loss 0.01885896734893322\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 2.098837596775649e-12, best loss 2.098837596775649e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "6 minutes 29 seconds passed from the start, the iteration took 1 minutes 22 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.646x_{1}^{6.0}+1.456x_{2}^{5.0}-0.499x_{3}^{3.0}+0.753$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.646x_1^{6.000} + 1.456x_2^{5.000}-0.499x_3^{3.000} + 0.753\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.787675101081342e-11\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0014334492152556777, best loss 0.0014334492152556777\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 2.4498944539708134e-12, best loss 2.4498944539708134e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "6 minutes 38 seconds passed from the start, the iteration took 9 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.824x_{1}^{4.0}+0.19x_{2}^{6.0}-0.016x_{3}^{3.0}-2.408$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.824x_1^{4.000} + 0.190x_2^{6.000}-0.016x_3^{2.999}-2.408\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8221443969998474e-07\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[7.284223660660613, 2.8741054298413768e-09, 7.860626069213467, 5.787675101081342e-11, 1.8221443969998474e-07]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.163, current formula \\left(11.262x_1^{-0.022} + 1.216x_2^{3.285}-8.999x_3^{-0.008}-1.421\\right)\n",
      "    Epoch 10000, current loss 0.162, current formula \\left(12.917x_1^{-0.020} + 1.215x_2^{3.289}-10.613x_3^{-0.007}-1.464\\right)\n",
      "  Finished run #1, loss 0.16249462962150574, best loss 0.16249462962150574\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.236, current formula \\left(15.443x_1^{-0.018}-15.474x_2^{-0.013} + 2.936x_3^{0.029}-1.582\\right)\n",
      "  Finished run #2, loss 0.23535940051078796, best loss 0.16249462962150574\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.00216, current formula \\left(-1.751x_1^{3.555} + 1.236x_2^{3.960}-2.187x_3^{-0.028} + 3.705\\right)\n",
      "    Epoch 10000, current loss 0.00213, current formula \\left(-1.751x_1^{3.554} + 1.236x_2^{3.961}-2.704x_3^{-0.023} + 4.223\\right)\n",
      "  Finished run #3, loss 0.0021343270782381296, best loss 0.0021343270782381296\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 6.4904882683680665e-12, best loss 6.4904882683680665e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 58 seconds passed from the start, the iteration took 1 minutes 58 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.74x_{1}^{3.5}+1.241x_{2}^{4.0}+0.261x_{3}^{1.5}+1.354$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.740x_1^{3.500} + 1.241x_2^{4.000} + 0.261x_3^{1.500} + 1.354\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.949803272553773e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00965, current formula \\left(0.499x_1^{1.055} + 1.336x_2^{0.060}-1.412x_3^{3.412}-0.180\\right)\n",
      "  Finished run #1, loss 1.4278899243547194e-11, best loss 1.4278899243547194e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 31 seconds passed from the start, the iteration took 33 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.517x_{1}^{1.0}+0.508x_{2}^{6.0}-1.412x_{3}^{3.5}+0.99$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.517x_1^{1.000} + 0.508x_2^{6.000}-1.412x_3^{3.500} + 0.990\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.267395739698259e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00375, current formula \\left(1.700x_1^{2.516}-0.887x_2^{5.544}-2.721x_3^{-0.034} + 0.782\\right)\n",
      "    Epoch 10000, current loss 0.00366, current formula \\left(1.700x_1^{2.516}-0.887x_2^{5.541}-3.613x_3^{-0.027} + 1.676\\right)\n",
      "  Finished run #1, loss 0.003656453685835004, best loss 0.003656453685835004\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0324, current formula \\left(1.678x_1^{2.464} + 3.025x_2^{-0.040} + 0.392x_3^{1.044}-5.508\\right)\n",
      "    Epoch 10000, current loss 0.0322, current formula \\left(1.678x_1^{2.464} + 4.672x_2^{-0.027} + 0.393x_3^{1.038}-7.163\\right)\n",
      "  Finished run #2, loss 0.03215403109788895, best loss 0.003656453685835004\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 8.47295237443868e-12, best loss 8.47295237443868e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 56 seconds passed from the start, the iteration took 1 minutes 25 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.7x_{1}^{2.5}-0.883x_{2}^{5.5}+0.407x_{3}^{1.0}-2.239$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.700x_1^{2.500}-0.883x_2^{5.500} + 0.407x_3^{1.000}-2.239\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 7.519741020343775e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.151, current formula \\left(0.670x_1^{-0.036} + 5.401x_2^{-0.045}-0.494x_3^{1.335}-6.219\\right)\n",
      "  Finished run #1, loss 0.15001773834228516, best loss 0.15001773834228516\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 9.478900303561133e-12, best loss 9.478900303561133e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "4 minutes 31 seconds passed from the start, the iteration took 36 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.116x_{1}^{6.0}-1.843x_{2}^{3.5}-0.486x_{3}^{1.5}+0.504$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.116x_1^{5.999}-1.843x_2^{3.500}-0.486x_3^{1.500} + 0.504\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.702178610515588e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 1.4012577209676635e-10, best loss 1.4012577209676635e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "4 minutes 36 seconds passed from the start, the iteration took 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.0x_{1}^{1.5}-0.82x_{2}^{6.0}-0.152x_{3}^{0.5}-0.71$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.000x_1^{1.500}-0.820x_2^{6.000}-0.152x_3^{0.501}-0.710\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 6.027351532164208e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[6.949803272553773e-10, 9.267395739698259e-10, 7.519741020343775e-10, 9.702178610515588e-08, 6.027351532164208e-08]\n",
      "For 5 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0007867843960411847, best loss 0.0007867843960411847\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.00010512123844819143, best loss 0.00010512123844819143\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.0007041909266263247, best loss 0.00010512123844819143\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0001057800036505796, best loss 0.00010512123844819143\n",
      "20 seconds passed from the start, the iteration took 20 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.054x_{1}^{6.0}+1.905x_{2}^{4.5}+0.266x_{3}^{0.667}-0.129$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.796x_1^{0.009} + 1.901x_2^{4.487} + 0.267x_3^{0.668} + 0.653\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.294024172230482\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.006559659261256456, best loss 0.006559659261256456\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0222, current formula \\left(1.734x_1^{0.994} + 4.556x_2^{-0.050} + 0.421x_3^{5.221}-5.243\\right)\n",
      "    Epoch 10000, current loss 0.0212, current formula \\left(1.736x_1^{0.990} + 7.079x_2^{-0.034} + 0.422x_3^{5.222}-7.776\\right)\n",
      "  Finished run #2, loss 0.021222131326794624, best loss 0.006559659261256456\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.1340981105611991e-11, best loss 1.1340981105611991e-11\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "1 minutes 10 seconds passed from the start, the iteration took 50 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.731x_{1}^{1.0}-0.983x_{2}^{1.083}+0.425x_{3}^{5.583}+0.03$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.731x_1^{1.000}-0.983x_2^{1.083} + 0.425x_3^{5.583} + 0.030\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.809579445521786e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 4.2698968172771856e-05, best loss 4.2698968172771856e-05\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0001934144092956558, best loss 4.2698968172771856e-05\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.00015097047435119748, best loss 4.2698968172771856e-05\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 4.272081423550844e-05, best loss 4.2698968172771856e-05\n",
      "1 minutes 27 seconds passed from the start, the iteration took 18 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.201x_{1}^{0.417}-0.031x_{2}^{3.5}+0.715x_{3}^{5.417}-0.014$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.200x_1^{0.422}-0.553x_2^{0.011} + 0.716x_3^{5.401} + 0.527\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.8200460575808948\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.456, current formula \\left(6.511x_1^{-0.057} + 1.870x_2^{-0.078} + 1.077x_3^{0.443}-9.670\\right)\n",
      "    Epoch 10000, current loss 0.451, current formula \\left(8.395x_1^{-0.046} + 2.547x_2^{-0.062} + 1.130x_3^{0.407}-12.307\\right)\n",
      "  Finished run #1, loss 0.45144394040107727, best loss 0.45144394040107727\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.456, current formula \\left(6.565x_1^{-0.056} + 1.909x_2^{-0.077} + 1.076x_3^{0.444}-9.761\\right)\n",
      "    Epoch 10000, current loss 0.451, current formula \\left(8.740x_1^{-0.044} + 2.636x_2^{-0.060} + 1.131x_3^{0.406}-12.744\\right)\n",
      "  Finished run #2, loss 0.450878769159317, best loss 0.450878769159317\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 5.947567115072161e-05, best loss 5.947567115072161e-05\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0432, current formula \\left(-2.887x_1^{4.898} + 3.209x_2^{-0.053} + 1.505x_3^{0.244}-4.078\\right)\n",
      "    Epoch 10000, current loss 0.0423, current formula \\left(-2.886x_1^{4.890} + 4.482x_2^{-0.040} + 1.601x_3^{0.223}-5.455\\right)\n",
      "  Finished run #4, loss 0.04234626889228821, best loss 5.947567115072161e-05\n",
      "3 minutes 43 seconds passed from the start, the iteration took 2 minutes 16 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -2.852x_{1}^{4.917}-0.975x_{2}^{2.167}+1.529x_{3}^{0.25}-0.395$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.852x_1^{4.914}-0.974x_2^{2.157} + 1.779x_3^{0.201}-0.652\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.018735735447031825\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0013138848589733243, best loss 0.0013138848589733243\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0011716000735759735, best loss 0.0011716000735759735\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.6621925169602036e-07, best loss 1.6621925169602036e-07\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "3 minutes 59 seconds passed from the start, the iteration took 16 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.198x_{1}^{2.833}-0.086x_{2}^{0.083}+0.224x_{3}^{1.083}-2.165$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.197x_1^{2.833}-1.394x_2^{0.004} + 0.224x_3^{1.085}-0.857\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.489618906714437\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[5.294024172230482, 4.809579445521786e-09, 1.8200460575808948, 0.018735735447031825, 0.489618906714437]\n",
      "For 1 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.303, current formula \\left(1.419x_1^{1.237} + 1.314x_2^{0.010} + 17.299x_3^{-0.023}-17.286x_4^{-0.010} + 0.326\\right)\n",
      "    Epoch 10000, current loss 0.301, current formula \\left(1.420x_1^{1.236} + 1.299x_2^{0.010} + 22.993x_3^{-0.018}-22.956x_4^{-0.008} + 0.313\\right)\n",
      "  Finished run #1, loss 0.3013624846935272, best loss 0.3013624846935272\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.199, current formula \\left(1.407x_1^{1.098} + 0.070x_2^{2.570} + 8.998x_3^{-0.042} + 1.617x_4^{5.494}-7.819\\right)\n",
      "    Epoch 10000, current loss 0.196, current formula \\left(1.410x_1^{1.092} + 0.069x_2^{2.535} + 14.039x_3^{-0.028} + 1.617x_4^{5.502}-12.875\\right)\n",
      "  Finished run #2, loss 0.19641263782978058, best loss 0.19641263782978058\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.198, current formula \\left(1.414x_1^{1.086}-3.322x_2^{-0.005} + 10.918x_3^{-0.036} + 1.621x_4^{5.505}-6.394\\right)\n",
      "    Epoch 10000, current loss 0.196, current formula \\left(1.414x_1^{1.084}-3.404x_2^{-0.005} + 14.134x_3^{-0.028} + 1.621x_4^{5.507}-9.535\\right)\n",
      "  Finished run #3, loss 0.19647006690502167, best loss 0.19641263782978058\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 2.4426793970633298e-05, best loss 2.4426793970633298e-05\n",
      "2 minutes 54 seconds passed from the start, the iteration took 2 minutes 54 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.458x_{1}^{1.0}+0.025x_{2}^{6.0}-2.101x_{3}^{3.0}+1.508x_{4}^{5.0}+2.058$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.459x_1^{0.999}-0.956x_2^{-0.003}-2.101x_3^{3.000} + 1.510x_4^{5.000} + 3.019\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.213307420358695\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0823, current formula \\left(-0.841x_1^{4.317} + 0.286x_2^{-0.034} + 0.775x_3^{1.251}-4.474x_4^{-0.037} + 3.254\\right)\n",
      "  Finished run #1, loss 0.08215327560901642, best loss 0.08215327560901642\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.01826668716967106, best loss 0.01826668716967106\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0818, current formula \\left(-0.837x_1^{4.303}-0.108x_2^{4.175} + 0.775x_3^{1.242}-3.877x_4^{-0.042} + 2.972\\right)\n",
      "    Epoch 10000, current loss 0.0811, current formula \\left(-0.837x_1^{4.301}-0.108x_2^{4.090} + 0.773x_3^{1.247}-6.126x_4^{-0.028} + 5.228\\right)\n",
      "  Finished run #3, loss 0.08105306327342987, best loss 0.01826668716967106\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0156, current formula \\left(-0.814x_1^{3.936}-0.186x_2^{4.094}-3.805x_3^{-0.044} + 1.405x_4^{5.042} + 3.054\\right)\n",
      "    Epoch 10000, current loss 0.015, current formula \\left(-0.813x_1^{3.920}-0.186x_2^{4.025}-5.765x_3^{-0.030} + 1.405x_4^{5.045} + 5.021\\right)\n",
      "  Finished run #4, loss 0.015007313340902328, best loss 0.015007313340902328\n",
      "6 minutes 30 seconds passed from the start, the iteration took 3 minutes 36 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.81x_{1}^{4.0}-0.177x_{2}^{4.0}+0.789x_{3}^{1.0}+1.378x_{4}^{5.0}-1.322$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.813x_1^{3.920}-0.186x_2^{4.025}-5.765x_3^{-0.030} + 1.405x_4^{5.045} + 5.021\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.363136214211472\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0289, current formula \\left(3.001x_1^{1.972}-2.590x_2^{-0.037}-1.033x_3^{1.975} + 1.012x_4^{5.243} + 3.139\\right)\n",
      "    Epoch 10000, current loss 0.0286, current formula \\left(3.001x_1^{1.972}-4.500x_2^{-0.022}-1.033x_3^{1.976} + 1.013x_4^{5.243} + 5.055\\right)\n",
      "  Finished run #1, loss 0.028631271794438362, best loss 0.028631271794438362\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.438, current formula \\left(-11.093x_1^{-0.050} + 0.768x_2^{3.897}-1.044x_3^{2.230}-0.959x_4^{-0.085} + 14.178\\right)\n",
      "    Epoch 10000, current loss 0.43, current formula \\left(-14.565x_1^{-0.039} + 0.768x_2^{3.909}-1.040x_3^{2.211}-1.323x_4^{-0.068} + 18.038\\right)\n",
      "  Finished run #2, loss 0.4304814040660858, best loss 0.028631271794438362\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 1.9384923354015537e-12, best loss 1.9384923354015537e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "8 minutes 3 seconds passed from the start, the iteration took 1 minutes 33 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.985x_{1}^{2.0}+0.82x_{2}^{5.0}-1.015x_{3}^{2.0}+1.018x_{4}^{5.0}+0.317$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.985x_1^{2.000} + 0.820x_2^{5.000}-1.015x_3^{2.000} + 1.018x_4^{5.000} + 0.317\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.262710430043828e-10\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.063, current formula \\left(-2.632x_1^{-0.014} + 1.098x_2^{-0.018}-2.420x_3^{3.048}-6.648x_4^{-0.019} + 8.488\\right)\n",
      "    Epoch 10000, current loss 0.0627, current formula \\left(-2.621x_1^{-0.014} + 1.101x_2^{-0.018}-2.419x_3^{3.049}-9.862x_4^{-0.013} + 11.690\\right)\n",
      "  Finished run #1, loss 0.06274164468050003, best loss 0.06274164468050003\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 5.272420087326646e-12, best loss 5.272420087326646e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "8 minutes 49 seconds passed from the start, the iteration took 46 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.16x_{1}^{4.0}-0.132x_{2}^{6.0}-2.395x_{3}^{3.0}+1.199x_{4}^{6.0}-0.025$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.160x_1^{4.000}-0.132x_2^{6.000}-2.395x_3^{3.000} + 1.199x_4^{6.000}-0.025\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 3.529787864621338e-08\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0009949271334335208, best loss 0.0009949271334335208\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.0010267916368320584, best loss 0.0009949271334335208\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 4.683851397013772e-12, best loss 4.683851397013772e-12\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "9 minutes 20 seconds passed from the start, the iteration took 31 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.088x_{1}^{5.0}-0.657x_{2}^{1.0}+1.108x_{3}^{6.0}-0.15x_{4}^{5.0}-0.77$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.088x_1^{5.000}-0.657x_2^{1.000} + 1.108x_3^{6.000}-0.150x_4^{5.000}-0.770\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.523435571010294e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[4.213307420358695, 9.363136214211472, 1.262710430043828e-10, 3.529787864621338e-08, 9.523435571010294e-09]\n",
      "For 3 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.011352215893566608, best loss 0.011352215893566608\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.00213, current formula \\left(-1.189x_1^{-0.026} + 0.973x_2^{0.508}-0.210x_3^{5.569}-0.329x_4^{0.124} + 1.103\\right)\n",
      "  Finished run #2, loss 0.0006267574499361217, best loss 0.0006267574499361217\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.003621661802753806, best loss 0.0006267574499361217\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.0017877682112157345, best loss 0.0006267574499361217\n",
      "48 seconds passed from the start, the iteration took 48 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.128x_{1}^{2.0}+0.988x_{2}^{0.5}-0.205x_{3}^{6.0}-0.194x_{4}^{5.0}-0.437$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.465x_1^{-0.021} + 0.984x_2^{0.503}-0.204x_3^{6.028}-0.196x_4^{5.293} + 1.104\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.0092570517027788\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.148, current formula \\left(-13.512x_1^{-0.028}-1.568x_2^{1.439} + 13.479x_3^{-0.010} + 4.418x_4^{0.025}-3.409\\right)\n",
      "    Epoch 10000, current loss 0.147, current formula \\left(-19.639x_1^{-0.020}-1.568x_2^{1.440} + 19.587x_3^{-0.007} + 4.417x_4^{0.025}-3.384\\right)\n",
      "  Finished run #1, loss 0.14662125706672668, best loss 0.14662125706672668\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.103, current formula \\left(1.632x_1^{1.381} + 8.296x_2^{-0.036}-1.117x_3^{4.903} + 0.686x_4^{4.496}-9.281\\right)\n",
      "    Epoch 10000, current loss 0.1, current formula \\left(1.632x_1^{1.379} + 12.978x_2^{-0.024}-1.121x_3^{4.930} + 0.686x_4^{4.474}-13.978\\right)\n",
      "  Finished run #2, loss 0.10024882107973099, best loss 0.10024882107973099\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0499, current formula \\left(1.632x_1^{1.561}-1.581x_2^{1.536} + 3.369x_3^{-0.037} + 0.704x_4^{5.477}-3.647\\right)\n",
      "    Epoch 10000, current loss 0.0494, current formula \\left(1.633x_1^{1.559}-1.581x_2^{1.538} + 5.314x_3^{-0.025} + 0.704x_4^{5.463}-5.599\\right)\n",
      "  Finished run #3, loss 0.049419060349464417, best loss 0.049419060349464417\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.13412368297576904, best loss 0.049419060349464417\n",
      "3 minutes 12 seconds passed from the start, the iteration took 2 minutes 24 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.618x_{1}^{1.5}-1.606x_{2}^{1.5}-1.111x_{3}^{4.5}+0.674x_{4}^{4.5}+0.034$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.633x_1^{1.559}-1.581x_2^{1.538} + 5.314x_3^{-0.025} + 0.704x_4^{5.463}-5.599\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 10.491184355952758\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.188, current formula \\left(-0.146x_1^{3.287} + 5.842x_2^{-0.049} + 1.315x_3^{1.755}-0.661x_4^{1.104}-7.105\\right)\n",
      "  Finished run #1, loss 0.18713903427124023, best loss 0.18713903427124023\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0577, current formula \\left(-0.170x_1^{12.485}-2.039x_2^{3.091}-4.869x_3^{-0.053}-0.665x_4^{1.757} + 5.075\\right)\n",
      "  Finished run #2, loss 0.057617150247097015, best loss 0.057617150247097015\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0575, current formula \\left(2.473x_1^{-0.004}-2.039x_2^{3.081}-6.262x_3^{-0.042}-0.667x_4^{1.726} + 3.983\\right)\n",
      "  Finished run #3, loss 0.05688629299402237, best loss 0.05688629299402237\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0577, current formula \\left(2.311x_1^{-0.004}-2.039x_2^{3.081}-5.982x_3^{-0.044}-0.667x_4^{1.726} + 3.864\\right)\n",
      "    Epoch 10000, current loss 0.0567, current formula \\left(2.390x_1^{-0.004}-2.039x_2^{3.081}-7.815x_3^{-0.035}-0.668x_4^{1.722} + 5.624\\right)\n",
      "  Finished run #4, loss 0.05667022615671158, best loss 0.05667022615671158\n",
      "5 minutes 19 seconds passed from the start, the iteration took 2 minutes 7 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.165x_{1}^{4.5}-2.0x_{2}^{3.0}+1.28x_{3}^{1.5}-0.687x_{4}^{1.5}-0.543$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2.390x_1^{-0.004}-2.039x_2^{3.081}-7.815x_3^{-0.035}-0.668x_4^{1.722} + 5.624\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 16.663888709911962\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.0021674917079508305, best loss 0.0021674917079508305\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0091, current formula \\left(-0.624x_1^{0.005}-3.547x_2^{-0.013} + 1.280x_3^{1.470} + 4.363x_4^{-0.045}-1.396\\right)\n",
      "    Epoch 10000, current loss 0.0087, current formula \\left(-0.647x_1^{0.005}-5.481x_2^{-0.009} + 1.280x_3^{1.470} + 6.338x_4^{-0.032}-1.418\\right)\n",
      "  Finished run #2, loss 0.008703825995326042, best loss 0.0021674917079508305\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.060112323611974716, best loss 0.0021674917079508305\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0585, current formula \\left(0.225x_1^{0.013} + 0.239x_2^{1.849}-4.960x_3^{-0.051}-0.943x_4^{0.495} + 5.008\\right)\n",
      "  Finished run #4, loss 0.05826294794678688, best loss 0.0021674917079508305\n",
      "6 minutes 44 seconds passed from the start, the iteration took 1 minutes 25 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.003x_{1}^{1.0}+0.225x_{2}^{2.5}+1.275x_{3}^{1.5}-0.971x_{4}^{0.5}-0.458$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(0.002x_1^{0.763}-2.583x_2^{-0.018} + 1.281x_3^{1.493}-0.957x_4^{0.523} + 2.213\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 2.379183509716312\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.00648, current formula \\left(1.016x_1^{2.953} + 3.793x_2^{-0.044} + 1.116x_3^{3.546} + 0.076x_4^{1.647}-4.741\\right)\n",
      "    Epoch 10000, current loss 0.00609, current formula \\left(1.017x_1^{2.953} + 5.325x_2^{-0.033} + 1.116x_3^{3.547} + 0.076x_4^{1.576}-6.278\\right)\n",
      "  Finished run #1, loss 0.0060875737108290195, best loss 0.0060875737108290195\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.057, current formula \\left(1.007x_1^{2.972}-0.786x_2^{0.595}-3.763x_3^{-0.043} + 0.042x_4^{1.901} + 3.906\\right)\n",
      "    Epoch 10000, current loss 0.056, current formula \\left(1.008x_1^{2.977}-0.792x_2^{0.585}-6.370x_3^{-0.027} + 0.042x_4^{1.927} + 6.528\\right)\n",
      "  Finished run #2, loss 0.056017689406871796, best loss 0.0060875737108290195\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.04694350063800812, best loss 0.0060875737108290195\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.00019030326802749187, best loss 0.00019030326802749187\n",
      "8 minutes 21 seconds passed from the start, the iteration took 1 minutes 37 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1.021x_{1}^{3.0}-0.872x_{2}^{0.5}+1.113x_{3}^{3.5}+0.069x_{4}^{2.0}-0.183$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.021x_1^{3.000}-0.874x_2^{0.496} + 1.112x_3^{3.495} + 0.801x_4^{0.021}-0.941\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 0.5588497294654737\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[1.0092570517027788, 10.491184355952758, 16.663888709911962, 2.379183509716312, 0.5588497294654737]\n",
      "For 0 formulas out of 5 the error is less than 1e-05.\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #1----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.11668173223733902, best loss 0.11668173223733902\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.0375, current formula \\left(-0.216x_1^{4.476}-1.594x_2^{5.559} + 0.113x_3^{26.350} + 4.599x_4^{-0.041}-5.070\\right)\n",
      "    Epoch 10000, current loss 0.0366, current formula \\left(-0.215x_1^{4.440}-1.595x_2^{5.560} + 0.113x_3^{27.275} + 6.625x_4^{-0.030}-7.112\\right)\n",
      "  Finished run #2, loss 0.036643318831920624, best loss 0.036643318831920624\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.038396988064050674, best loss 0.036643318831920624\n",
      "  Initialization #4\n",
      "  Finished run #4, loss 0.001982675399631262, best loss 0.001982675399631262\n",
      "1 minutes 7 seconds passed from the start, the iteration took 1 minutes 7 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.196x_{1}^{3.417}-1.58x_{2}^{5.25}+0.056x_{3}^{4.917}-0.946x_{4}^{1.917}+0.051$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(1.644x_1^{-0.021}-1.580x_2^{5.285}-1.673x_3^{-0.005}-0.953x_4^{1.924} + 0.018\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 4.71323496871114\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #2----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.03747618570923805, best loss 0.03747618570923805\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.01439367700368166, best loss 0.01439367700368166\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.0138, current formula \\left(-0.875x_1^{2.928} + 4.154x_2^{-0.054} + 0.515x_3^{2.350} + 0.402x_4^{3.082}-3.205\\right)\n",
      "    Epoch 10000, current loss 0.0131, current formula \\left(-0.875x_1^{2.932} + 6.284x_2^{-0.038} + 0.516x_3^{2.341} + 0.403x_4^{3.078}-5.343\\right)\n",
      "  Finished run #3, loss 0.013074316084384918, best loss 0.013074316084384918\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0427, current formula \\left(2.707x_1^{-0.056}-1.052x_2^{0.623} + 0.530x_3^{2.582}-2.889x_4^{-0.026} + 1.827\\right)\n",
      "  Finished run #4, loss 0.042711641639471054, best loss 0.013074316084384918\n",
      "2 minutes 29 seconds passed from the start, the iteration took 1 minutes 22 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.901x_{1}^{2.917}-1.013x_{2}^{0.75}+0.52x_{3}^{2.417}+0.429x_{4}^{3.333}+1.778$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-0.875x_1^{2.932} + 6.284x_2^{-0.038} + 0.516x_3^{2.341} + 0.403x_4^{3.078}-5.344\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 11.62731082991836\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #3----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 2.7001970104301165e-10, best loss 2.7001970104301165e-10\n",
      "loss is smaller than 1e-05, terminating learning process\n",
      "2 minutes 35 seconds passed from the start, the iteration took 6 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -1.202x_{1}^{0.417}-0.922x_{2}^{4.0}+0.614x_{3}^{1.917}+0.493x_{4}^{2.583}-0.196$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.202x_1^{0.417}-0.922x_2^{4.000} + 0.614x_3^{1.917} + 0.493x_4^{2.583}-0.196\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 9.928283306592789e-09\n",
      "EXACT RECOVERY\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #4----------------------------\n",
      "  Initialization #1\n",
      "  Finished run #1, loss 0.07169807702302933, best loss 0.07169807702302933\n",
      "  Initialization #2\n",
      "  Finished run #2, loss 0.010754821822047234, best loss 0.010754821822047234\n",
      "  Initialization #3\n",
      "  Finished run #3, loss 0.06234350800514221, best loss 0.010754821822047234\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.0724, current formula \\left(-1.625x_1^{-0.047}-4.829x_2^{-0.042}-1.563x_3^{0.497}-0.487x_4^{2.191} + 5.161\\right)\n",
      "  Finished run #4, loss 0.0719979926943779, best loss 0.010754821822047234\n",
      "3 minutes 39 seconds passed from the start, the iteration took 1 minutes 4 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.478x_{1}^{2.167}+1.172x_{2}^{3.0}-1.617x_{3}^{0.5}-0.516x_{4}^{2.167}-1.98$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-1.572x_1^{-0.051} + 1.166x_2^{2.990}-1.580x_3^{0.508}-0.528x_4^{2.363}-0.208\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 1.366857101712928\n",
      "FAILURE\n",
      "\n",
      "\n",
      "----------------------------Exploring new formula #5----------------------------\n",
      "  Initialization #1\n",
      "    Epoch 5000, current loss 0.0128, current formula \\left(-1.867x_1^{-0.038} + 1.894x_2^{3.394} + 1.056x_3^{3.951}-1.537x_4^{3.909} + 1.963\\right)\n",
      "    Epoch 10000, current loss 0.0127, current formula \\left(-2.895x_1^{-0.025} + 1.894x_2^{3.395} + 1.056x_3^{3.950}-1.538x_4^{3.910} + 2.991\\right)\n",
      "  Finished run #1, loss 0.012664072215557098, best loss 0.012664072215557098\n",
      "  Initialization #2\n",
      "    Epoch 5000, current loss 0.165, current formula \\left(-1.135x_1^{-0.058}-8.179x_2^{-0.034} + 1.081x_3^{4.459}-1.563x_4^{3.894} + 10.130\\right)\n",
      "    Epoch 10000, current loss 0.164, current formula \\left(-1.149x_1^{-0.058}-10.964x_2^{-0.026} + 1.081x_3^{4.467}-1.563x_4^{3.894} + 12.935\\right)\n",
      "  Finished run #2, loss 0.16391098499298096, best loss 0.012664072215557098\n",
      "  Initialization #3\n",
      "    Epoch 5000, current loss 0.122, current formula \\left(0.599x_1^{5.514} + 1.946x_2^{3.586} + 1.081x_3^{3.873} + 6.566x_4^{-0.031}-7.179\\right)\n",
      "    Epoch 10000, current loss 0.12, current formula \\left(0.599x_1^{5.516} + 1.947x_2^{3.584} + 1.081x_3^{3.864} + 10.764x_4^{-0.020}-11.388\\right)\n",
      "  Finished run #3, loss 0.1199827715754509, best loss 0.012664072215557098\n",
      "  Initialization #4\n",
      "    Epoch 5000, current loss 0.283, current formula \\left(0.581x_1^{5.608}-15.771x_2^{-0.018} + 1.102x_3^{4.328} + 16.608x_4^{-0.013}-0.693\\right)\n",
      "    Epoch 10000, current loss 0.28, current formula \\left(0.581x_1^{5.606}-21.294x_2^{-0.014} + 1.102x_3^{4.329} + 22.082x_4^{-0.010}-0.689\\right)\n",
      "  Finished run #4, loss 0.2797815799713135, best loss 0.012664072215557098\n",
      "6 minutes 48 seconds passed from the start, the iteration took 3 minutes 9 seconds\n",
      "ground truth and obtained formula\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0.539x_{1}^{5.0}+1.9x_{2}^{3.417}+1.061x_{3}^{4.083}-1.523x_{4}^{3.917}-0.064$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(-2.895x_1^{-0.025} + 1.894x_2^{3.395} + 1.056x_3^{3.950}-1.538x_4^{3.910} + 2.991\\right)$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE between formula parameters is 5.1554894790799075\n",
      "FAILURE\n",
      "\n",
      "################################################################################\n",
      "MSEs between parameters:\n",
      "[4.71323496871114, 11.62731082991836, 9.928283306592789e-09, 1.366857101712928, 5.1554894790799075]\n",
      "For 1 formulas out of 5 the error is less than 1e-05.\n"
     ]
    }
   ],
   "source": [
    "for j in range(1):\n",
    "    results = {}\n",
    "    for m_samples in [10, 100, 1000]:\n",
    "        results[m_samples] = {}\n",
    "        for n_variables in range(2, 5):\n",
    "            results[m_samples][n_variables] = []\n",
    "            i = 0\n",
    "            for min_power, max_power, divide_powers_by in ((1, 6, 1),\n",
    "                                                           (1, 12, 2), (1, 72,\n",
    "                                                                        12)):\n",
    "                recoveries = explore.explore(n_variables=n_variables,\n",
    "                                             m_samples=m_samples,\n",
    "                                             number_of_tested_formulas=5,\n",
    "                                             min_power=min_power,\n",
    "                                             max_power=max_power,\n",
    "                                             divide_powers_by=divide_powers_by)\n",
    "                results[m_samples][n_variables].append(recoveries / 5)\n",
    "                i += 1\n",
    "\n",
    "    with open(\"results\" + str(j + 75) + \".pkl\", \"wb\") as fout:\n",
    "        pickle.dump(results, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiments took 1 hour 3 minutes 31 seconds\n"
     ]
    }
   ],
   "source": [
    "times = np.array([(5, 42), (4, 34), (3, 43), (3, 26), (4, 47), (3, 46),\n",
    "                  (3, 27), (2, 7), (3, 12), (1, 33), (2, 44), (1, 50), (2, 50),\n",
    "                  (0, 58), (1, 44), (1, 25), (1, 12), (0, 8), (2, 45), (1, 58),\n",
    "                  (2, 16), (1, 55), (1, 12), (1, 38), (0, 48), (0, 46),\n",
    "                  (1, 5)])\n",
    "seconds = (times[:, 0].sum() * 60 + times[:, 1].sum())\n",
    "minutes, seconds = divmod(seconds, 60)\n",
    "hours, minutes = divmod(minutes, 60)\n",
    "print(\n",
    "    f\"The experiments took {hours} hour {minutes} minutes {seconds} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: {2: [0.2, 0.6, 0.4], 3: [0.2, 0.6, 0.0], 4: [0.0, 0.0, 0.2]},\n",
       " 100: {2: [1.0, 0.8, 0.8], 3: [0.6, 0.8, 0.4], 4: [0.6, 0.2, 0.6]},\n",
       " 1000: {2: [0.8, 0.6, 0.8], 3: [1.0, 0.6, 0.4], 4: [0.2, 0.2, 0.4]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = {}\n",
    "for m_samples in [10, 100, 1000]:\n",
    "    se[m_samples] = {}\n",
    "    for n_variables in range(2, 5):\n",
    "        a = np.array(results[m_samples][n_variables])\n",
    "        se[m_samples][n_variables] = np.sqrt(a * (1 - a) / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "barwidth = 1 / 6\n",
    "a = np.arange(-1, 2) / 4\n",
    "colors = {10: \"orange\", 100: \"cyan\", 1000: \"red\"}\n",
    "patches = []\n",
    "plt.figure(figsize=(15, 10))\n",
    "for n_variables in range(2, 5):\n",
    "    for m_samples in [1000, 100, 10]:\n",
    "        plt.bar(a + n_variables,\n",
    "                results[m_samples][n_variables],\n",
    "                width=1 / 4,\n",
    "                yerr=1.96 * se[m_samples][n_variables],\n",
    "                color=colors[m_samples],\n",
    "                edgecolor='black',\n",
    "                capsize=4,\n",
    "                alpha=0.5)\n",
    "    patches.append(\n",
    "        mpatches.Patch(color=colors[m_samples],\n",
    "                       label=str(m_samples) + \" samples\"))\n",
    "plt.xlabel('n variables')\n",
    "plt.ylabel('recovery rate')\n",
    "plt.xticks([2, 3, 4])\n",
    "plt.title(\n",
    "    \"NestedFormula experiments, 5 for each configuration, with 95% confidence intervals\"\n",
    ")\n",
    "plt.legend(handles=patches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "barwidth = 1 / 4\n",
    "a = np.arange(-1, 2) / 4\n",
    "colors = ['C0', 'C1', 'C2']\n",
    "ecolors = ['C3', 'C4', 'C5']\n",
    "# colors = [1, 2, 3]\n",
    "patches = []\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(3):\n",
    "    patches.append(\n",
    "        mpatches.Patch(color=colors[i], label=str(10**(i + 1)) + \" samples\"))\n",
    "# n_variables = 4\n",
    "# # for n_variables in range(2, 5):\n",
    "# for powers_\n",
    "# for m_samples in [1000, 100, 10]:\n",
    "#     plt.bar(a + n_variables, results[m_samples][n_variables], width=1/4, yerr=1.96 * se[m_samples][n_variables],\n",
    "#             color=colors[m_samples], edgecolor = 'black', capsize=4, alpha=0.5)\n",
    "\n",
    "for powers_type in range(3):\n",
    "    heights_a = [\n",
    "        pd.DataFrame(results).loc[:, 10][i][powers_type] for i in (2, 3, 4)\n",
    "    ]\n",
    "    heights_b = [\n",
    "        pd.DataFrame(results).loc[:, 100][i][powers_type] for i in (2, 3, 4)\n",
    "    ]\n",
    "    heights_c = [\n",
    "        pd.DataFrame(results).loc[:, 1000][i][powers_type] for i in (2, 3, 4)\n",
    "    ]\n",
    "\n",
    "    se_a = [pd.DataFrame(se).loc[:, 10][i][powers_type] for i in (2, 3, 4)]\n",
    "    se_b = [pd.DataFrame(se).loc[:, 100][i][powers_type] for i in (2, 3, 4)]\n",
    "    se_c = [pd.DataFrame(se).loc[:, 1000][i][powers_type] for i in (2, 3, 4)]\n",
    "\n",
    "    position = np.arange(2, 5) + (powers_type - 1) / 4\n",
    "\n",
    "    for x, ha, hb, hc, sea, seb, sec in zip(position, heights_a, heights_b,\n",
    "                                            heights_c, se_a, se_b, se_c):\n",
    "        for i, (h, serr, c, ec) in enumerate(\n",
    "                sorted(zip([ha, hb, hc], [sea, seb, sec], colors, ecolors))):\n",
    "            plt.bar(x,\n",
    "                    h,\n",
    "                    color=c,\n",
    "                    zorder=-i,\n",
    "                    width=barwidth,\n",
    "                    edgecolor='black')\n",
    "\n",
    "plt.xlabel('n variables')\n",
    "plt.ylabel('recovery rate')\n",
    "# plt.xticks([2 - 0.25, 2, 2 + 0.25,\n",
    "#            3 - 0.25, 3, 3 + 0.25,\n",
    "#            4 - 0.25, 4, 4 + 0.25],\n",
    "#            [\"integer powers\", \"half-integer\\n powers\\n2\", \"powers with \\ndenominator 12\",\n",
    "#            \"integer powers\", \"half-integer\\n powers\\n3\", \"powers with \\ndenominator 12\"\n",
    "#            \"integer powers\", \"half-integer\\n powers\\n4\", \"powers with \\ndenominator 12\"])\n",
    "plt.yticks(np.linspace(0, 1, 11))\n",
    "plt.grid()\n",
    "plt.title(\"NestedFormula experiments, 5 for each configuration\")\n",
    "plt.legend(handles=patches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "barwidth = 1 / 4\n",
    "a = np.arange(-1, 2) / 4\n",
    "colors = ['C0', 'C1', 'C2']\n",
    "ecolors = ['C3', 'C4', 'C5']\n",
    "# colors = [1, 2, 3]\n",
    "patches = []\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(3):\n",
    "    patches.append(\n",
    "        mpatches.Patch(color=colors[i], label=str(10**(i + 1)) + \" samples\"))\n",
    "    patches.append(\n",
    "        mpatches.Patch(color=ecolors[i],\n",
    "                       label=str(10**(i + 1)) +\n",
    "                       \" samples 95% confidence interval\"))\n",
    "# n_variables = 4\n",
    "# # for n_variables in range(2, 5):\n",
    "# for powers_\n",
    "# for m_samples in [1000, 100, 10]:\n",
    "#     plt.bar(a + n_variables, results[m_samples][n_variables], width=1/4, yerr=1.96 * se[m_samples][n_variables],\n",
    "#             color=colors[m_samples], edgecolor = 'black', capsize=4, alpha=0.5)\n",
    "\n",
    "for powers_type in range(3):\n",
    "    heights_a = [\n",
    "        pd.DataFrame(results).loc[:, 10][i][powers_type] for i in (2, 3, 4)\n",
    "    ]\n",
    "    heights_b = [\n",
    "        pd.DataFrame(results).loc[:, 100][i][powers_type] for i in (2, 3, 4)\n",
    "    ]\n",
    "    heights_c = [\n",
    "        pd.DataFrame(results).loc[:, 1000][i][powers_type] for i in (2, 3, 4)\n",
    "    ]\n",
    "\n",
    "    se_a = [pd.DataFrame(se).loc[:, 10][i][powers_type] for i in (2, 3, 4)]\n",
    "    se_b = [pd.DataFrame(se).loc[:, 100][i][powers_type] for i in (2, 3, 4)]\n",
    "    se_c = [pd.DataFrame(se).loc[:, 1000][i][powers_type] for i in (2, 3, 4)]\n",
    "\n",
    "    position = np.arange(2, 5) + (powers_type - 1) / 4\n",
    "\n",
    "    for x, ha, hb, hc, sea, seb, sec in zip(position, heights_a, heights_b,\n",
    "                                            heights_c, se_a, se_b, se_c):\n",
    "        for i, (h, serr, c, ec) in enumerate(\n",
    "                sorted(zip([ha, hb, hc], [sea, seb, sec], colors, ecolors))):\n",
    "            plt.bar(x,\n",
    "                    h,\n",
    "                    yerr=1.96 * serr,\n",
    "                    capsize=4,\n",
    "                    color=c,\n",
    "                    ecolor=ec,\n",
    "                    zorder=-i,\n",
    "                    width=barwidth,\n",
    "                    edgecolor='black')\n",
    "\n",
    "plt.xlabel('n variables')\n",
    "plt.ylabel('recovery rate')\n",
    "plt.xticks([2, 3, 4])\n",
    "plt.yticks(np.linspace(0, 1, 11))\n",
    "plt.grid()\n",
    "plt.title(\n",
    "    \"NestedFormula experiments, 5 for each configuration, with 95% confidence intervals\"\n",
    ")\n",
    "plt.legend(handles=patches)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "demonstration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
