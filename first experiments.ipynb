{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.a = torch.randn(1, 1).requires_grad_(True)\n",
    "        self.b = torch.randn(1, 1).requires_grad_(True)\n",
    "        self.s = torch.randn(1, 1).requires_grad_(True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.a * (x**self.s) + self.b\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.a.item()) + \"*x^{\" + str(self.s.item()) + \"} + \" + str(self.b.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1000, 1) * 50 + 1\n",
    "y = 1.2 * X**2.1 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.5801],\n",
       "         [27.0115],\n",
       "         [25.5401],\n",
       "         [31.3364],\n",
       "         [34.7313]]), tensor([[  21.4726],\n",
       "         [1221.3992],\n",
       "         [1086.3038],\n",
       "         [1666.9720],\n",
       "         [2067.9260]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5289931893348694*x^{0.07988166809082031} + 1.0962891578674316 3931240.5\n",
      "2.3126189708709717*x^{1.924354076385498} + 3.139185905456543 5001.82861328125\n",
      "2.1132264137268066*x^{1.948580026626587} + 2.873189926147461 3658.40380859375\n",
      "1.8540822267532349*x^{1.9836944341659546} + 2.551608085632324 2101.80029296875\n",
      "1.583121657371521*x^{2.026047468185425} + 2.244311571121216 811.8675537109375\n",
      "1.3701958656311035*x^{2.0647246837615967} + 2.0248992443084717 167.38079833984375\n",
      "1.2579935789108276*x^{2.08758282661438} + 1.922520637512207 15.517849922180176\n",
      "1.2212111949920654*x^{2.095518112182617} + 1.9017510414123535 1.4083102941513062\n",
      "1.2139309644699097*x^{2.0971150398254395} + 1.91511869430542 0.9192014336585999\n",
      "1.2129931449890137*x^{2.0973191261291504} + 1.9404945373535156 0.8914564847946167\n",
      "1.2127436399459839*x^{2.0973708629608154} + 1.9736430644989014 0.8629500269889832\n",
      "1.212477207183838*x^{2.097425699234009} + 2.015549421310425 0.827633261680603\n",
      "1.212143898010254*x^{2.097494125366211} + 2.0681564807891846 0.7843316197395325\n",
      "1.2117310762405396*x^{2.097578763961792} + 2.133725643157959 0.7320275902748108\n",
      "1.2109631299972534*x^{2.097546339035034} + 2.2147130966186523 2.7375192642211914\n",
      "1.2110600471496582*x^{2.0976858139038086} + 2.3121280670166016 0.6324427127838135\n",
      "1.2100697755813599*x^{2.0979254245758057} + 2.428431749343872 0.523216724395752\n",
      "1.209120512008667*x^{2.0981152057647705} + 2.5653865337371826 0.4328992962837219\n",
      "1.2081353664398193*x^{2.0983173847198486} + 2.7220911979675293 0.34349194169044495\n",
      "1.2069191932678223*x^{2.0984044075012207} + 2.8953282833099365 1.7465788125991821\n",
      "1.2061214447021484*x^{2.098785400390625} + 3.079054117202759 0.35751330852508545\n",
      "1.2047722339630127*x^{2.099008560180664} + 3.2632739543914795 0.11444973200559616\n",
      "1.2042794227600098*x^{2.0994699001312256} + 3.4390032291412354 7.48483419418335\n",
      "1.2028157711029053*x^{2.0993783473968506} + 3.5901875495910645 0.10121377557516098\n",
      "1.2019075155258179*x^{2.0996010303497314} + 3.71378231048584 0.017531462013721466\n",
      "1.2013384103775024*x^{2.0997228622436523} + 3.806300401687622 0.008304270915687084\n",
      "1.2008177042007446*x^{2.099778890609741} + 3.872239351272583 0.1472814977169037\n",
      "1.200723648071289*x^{2.099865436553955} + 3.915262460708618 0.020520182326436043\n",
      "1.200416088104248*x^{2.099914789199829} + 3.9416890144348145 0.0009384513832628727\n",
      "1.2004096508026123*x^{2.1000683307647705} + 3.9590907096862793 1.3297934532165527\n",
      "1.2003200054168701*x^{2.0999298095703125} + 3.9690020084381104 0.0005082603311166167\n",
      "1.2002224922180176*x^{2.09995174407959} + 3.9739267826080322 0.00024039458367042243\n",
      "1.1990630626678467*x^{2.098796844482422} + 3.9780359268188477 108.98735046386719\n",
      "1.2002983093261719*x^{2.099970579147339} + 3.980539083480835 0.06822316348552704\n",
      "1.2001495361328125*x^{2.099973440170288} + 3.9814255237579346 0.0014735845616087317\n",
      "1.2002028226852417*x^{2.099916696548462} + 3.983280897140503 0.08635062724351883\n",
      "1.2002532482147217*x^{2.0997791290283203} + 3.9839048385620117 1.5089762210845947\n",
      "1.2001984119415283*x^{2.099961280822754} + 3.982281446456909 0.0009306877618655562\n",
      "1.2000051736831665*x^{2.0996358394622803} + 3.9842212200164795 7.269676208496094\n",
      "1.200181245803833*x^{2.099956750869751} + 3.9822466373443604 0.001221698010340333\n",
      "1.201385736465454*x^{2.1012139320373535} + 3.984816789627075 127.51380157470703\n",
      "1.2003953456878662*x^{2.0999255180358887} + 3.984240770339966 0.008716672658920288\n",
      "1.2001824378967285*x^{2.099961042404175} + 3.9827749729156494 0.00010542697418713942\n",
      "1.2001237869262695*x^{2.099973201751709} + 3.9830851554870605 9.566894004819915e-05\n",
      "1.2001367807388306*x^{2.099968910217285} + 3.9828240871429443 0.00033209030516445637\n",
      "1.201149344444275*x^{2.100813865661621} + 3.985541820526123 62.81056594848633\n",
      "1.200326919555664*x^{2.0999763011932373} + 3.9836671352386475 0.12458156049251556\n",
      "1.2001211643218994*x^{2.099963426589966} + 3.9830551147460938 0.006854010280221701\n",
      "1.2002521753311157*x^{2.099945068359375} + 3.983344793319702 0.00023105909349396825\n",
      "1.2000644207000732*x^{2.0999081134796143} + 3.9831795692443848 0.34259033203125\n",
      "1.2002360820770264*x^{2.09989595413208} + 3.9834978580474854 0.15411800146102905\n",
      "1.2001185417175293*x^{2.099961757659912} + 3.9830474853515625 0.009881862439215183\n",
      "1.2002474069595337*x^{2.0999276638031006} + 3.9832446575164795 0.019557610154151917\n",
      "1.2001447677612305*x^{2.0999677181243896} + 3.9826245307922363 0.00021982916223350912\n",
      "1.2014333009719849*x^{2.1012375354766846} + 3.9849863052368164 133.32936096191406\n",
      "1.2002030611038208*x^{2.099942684173584} + 3.9829134941101074 0.010366890579462051\n",
      "1.1994482278823853*x^{2.099106550216675} + 3.9837446212768555 56.562713623046875\n",
      "1.2002208232879639*x^{2.0999257564544678} + 3.983057975769043 0.039011940360069275\n",
      "1.2001503705978394*x^{2.0999667644500732} + 3.982806921005249 0.00017072468472179025\n",
      "1.2004770040512085*x^{2.1000514030456543} + 3.984816312789917 1.3391433954238892\n",
      "1.2001492977142334*x^{2.0999693870544434} + 3.9826133251190186 0.00013671581109520048\n",
      "1.1998212337493896*x^{2.099522829055786} + 3.98386287689209 14.702874183654785\n",
      "1.2002183198928833*x^{2.0999536514282227} + 3.9820120334625244 0.00017424492398276925\n",
      "1.2002085447311401*x^{2.099956512451172} + 3.9827754497528076 0.00024233390286099166\n",
      "1.199920654296875*x^{2.099503755569458} + 3.9846231937408447 14.525634765625\n",
      "1.2004456520080566*x^{2.10001277923584} + 3.9845666885375977 0.6713394522666931\n",
      "1.2003231048583984*x^{2.099897861480713} + 3.9840362071990967 0.05539455637335777\n",
      "1.2001677751541138*x^{2.099965810775757} + 3.9825680255889893 0.00022725938470102847\n",
      "1.2000813484191895*x^{2.099597692489624} + 3.9849414825439453 8.136271476745605\n",
      "1.200221300125122*x^{2.099956750869751} + 3.9820544719696045 0.0012059141881763935\n",
      "1.2001490592956543*x^{2.0999789237976074} + 3.9830377101898193 0.006203838624060154\n",
      "1.2002519369125366*x^{2.09987473487854} + 3.98380184173584 0.2737402021884918\n",
      "1.2001383304595947*x^{2.099968433380127} + 3.982517957687378 0.00037736623198725283\n",
      "1.2003706693649292*x^{2.099973201751709} + 3.984978199005127 0.1624869555234909\n",
      "1.200280785560608*x^{2.0999112129211426} + 3.983172655105591 0.04269256070256233\n",
      "1.2001715898513794*x^{2.099966049194336} + 3.98262095451355 0.00048485989100299776\n",
      "1.2001320123672485*x^{2.0999786853790283} + 3.9828598499298096 0.002401084406301379\n",
      "1.2003965377807617*x^{2.0999722480773926} + 3.983768939971924 0.19180917739868164\n",
      "1.2002962827682495*x^{2.0999629497528076} + 3.9833104610443115 0.04145706817507744\n",
      "1.2001475095748901*x^{2.0999696254730225} + 3.9827542304992676 0.00011869033187394962\n",
      "1.2000555992126465*x^{2.099909543991089} + 3.983070135116577 0.3473292291164398\n",
      "1.2004133462905884*x^{2.0999693870544434} + 3.983855724334717 0.19764605164527893\n",
      "1.2001872062683105*x^{2.0999526977539062} + 3.9827065467834473 0.002950913505628705\n",
      "1.200972318649292*x^{2.1006555557250977} + 3.9850690364837646 41.68072509765625\n",
      "1.2001911401748657*x^{2.0999603271484375} + 3.98237681388855 0.00020519339886959642\n",
      "1.2013493776321411*x^{2.101144313812256} + 3.984920024871826 114.7839584350586\n",
      "1.200221300125122*x^{2.099961042404175} + 3.982691764831543 0.0043390472419559956\n",
      "1.2001478672027588*x^{2.0999667644500732} + 3.982797384262085 0.00026672196690924466\n",
      "1.200506329536438*x^{2.1000630855560303} + 3.9849936962127686 1.6698933839797974\n",
      "1.2001478672027588*x^{2.099970817565918} + 3.9828693866729736 0.00033635791623964906\n",
      "1.2002830505371094*x^{2.0999643802642822} + 3.9829697608947754 0.03687521442770958\n",
      "1.2001296281814575*x^{2.0999696254730225} + 3.983121395111084 0.0005735072190873325\n",
      "1.2001198530197144*x^{2.0999701023101807} + 3.9828391075134277 0.0013087170664221048\n",
      "1.2005133628845215*x^{2.1000261306762695} + 3.9849393367767334 1.061143398284912\n",
      "1.2001521587371826*x^{2.099961996078491} + 3.9829299449920654 0.0018461424624547362\n",
      "1.2002160549163818*x^{2.099735736846924} + 3.9846324920654297 2.592341423034668\n",
      "1.2002151012420654*x^{2.0999534130096436} + 3.9820563793182373 0.00015539147716481239\n",
      "1.2001471519470215*x^{2.0999722480773926} + 3.9830639362335205 0.0007346301572397351\n",
      "1.1989076137542725*x^{2.0987343788146973} + 3.9823343753814697 124.35843658447266\n",
      "1.199950098991394*x^{2.0998098850250244} + 3.98302960395813 2.251953601837158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.200381875038147*x^{2.0999724864959717} + 3.9841794967651367 0.17287017405033112\n",
      "1.2001584768295288*x^{2.0999670028686523} + 3.982470989227295 0.0001087376440409571\n",
      "1.2006747722625732*x^{2.1002557277679443} + 3.9852871894836426 8.987184524536133\n",
      "1.2001782655715942*x^{2.099964141845703} + 3.9825079441070557 0.0003737310180440545\n",
      "1.2001334428787231*x^{2.0999786853790283} + 3.9829671382904053 0.0026337727904319763\n",
      "1.2003470659255981*x^{2.099935293197632} + 3.983790636062622 0.007239732425659895\n",
      "1.2002390623092651*x^{2.0999503135681152} + 3.983062982559204 0.00041379890171810985\n",
      "1.2001368999481201*x^{2.099970817565918} + 3.982461452484131 7.546394772361964e-05\n",
      "1.1994400024414062*x^{2.099097728729248} + 3.983781337738037 57.74939727783203\n",
      "1.2003185749053955*x^{2.099971055984497} + 3.9833171367645264 0.09012607485055923\n",
      "1.2002578973770142*x^{2.0999677181243896} + 3.9831809997558594 0.030762070789933205\n",
      "1.2001391649246216*x^{2.099973201751709} + 3.9826502799987793 0.0004432298883330077\n",
      "1.200121521949768*x^{2.0999703407287598} + 3.9825613498687744 0.0010252899955958128\n",
      "1.2003310918807983*x^{2.0999596118927} + 3.983732223510742 0.05598866194486618\n",
      "1.2001608610153198*x^{2.099963665008545} + 3.9823074340820312 0.0003327130980324\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-13e382066265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ 0.001 * net.a**2 + 0.01 * net.b**2 + 0.003 * net.s**2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "net = Net()\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam([net.a, net.b, net.s], lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "best_model = \n",
    "for i in range(100000):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(X)\n",
    "    loss = criterion(output, y) #+ 0.001 * net.a**2 + 0.01 * net.b**2 + 0.003 * net.s**2\n",
    "    loss.backward()\n",
    "    if i % 500 == 0:\n",
    "        print(net, loss.item())\n",
    "    optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(307.6224)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.a = (2 * torch.randn(1, 1)).requires_grad_(True)\n",
    "        self.b = (2 * torch.randn(1, 1)).requires_grad_(True)\n",
    "        self.s1 = (2 * torch.randn(1, 1)).requires_grad_(True)\n",
    "        self.s2 = (2 * torch.randn(1, 1)).requires_grad_(True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.a * (x[:, 0]**self.s1) * (x[:, 1]**self.s2) + self.b\n",
    "\n",
    "    def __repr__(self):\n",
    "        return ''.join([str(round(self.a.item(), 3)), \n",
    "                        \"*x^{\", str(round(self.s1.item(), 3)), \"} * \", \n",
    "                        \"y^{\", str(round(self.s2.item(), 3)), \"} + \", \n",
    "                        str(self.b.item())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1000, 1) * 50 + 1\n",
    "Y = torch.rand(1000, 1) * 50 + 1\n",
    "train = torch.cat([X, Y], 1)\n",
    "z = 1.3 * X**2 * Y**(-1) + 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16.3335,  4.6578],\n",
       "        [ 1.4280, 16.1612],\n",
       "        [12.1116, 38.0939],\n",
       "        [13.1719, 27.1627],\n",
       "        [25.0910, 44.3791]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.163*x^{-2.74} * y^{-0.187} + -3.687274217605591 3943312.25\n",
      "0.031*x^{-3.653} * y^{-1.027} + 1.2721692323684692 3928700.0\n",
      "0.099*x^{-3.513} * y^{-0.918} + 6.1526360511779785 3914929.75\n",
      "2.22*x^{0.059} * y^{1.743} + 10.84795093536377 2632911.5\n",
      "5.575*x^{0.44} * y^{1.141} + 12.579306602478027 2493583.0\n",
      "8.284*x^{0.541} * y^{0.938} + 14.46911907196045 2443800.75\n",
      "10.81*x^{0.606} * y^{0.803} + 16.536043167114258 2409018.5\n",
      "13.301*x^{0.631} * y^{0.721} + 18.747966766357422 2381532.75\n",
      "15.821*x^{0.627} * y^{0.677} + 21.053001403808594 2358470.75\n",
      "18.405*x^{0.616} * y^{0.647} + 23.384628295898438 2338435.75\n",
      "21.077*x^{0.602} * y^{0.623} + 25.664081573486328 2320702.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-bf0b68e67b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# zero the gradient buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "net = Net()\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam([net.a, net.b, net.s1, net.s2], lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "for i in range(100000):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(train)\n",
    "    loss = criterion(output, y) + 10 * net.a**2 + 10 * net.b**2\n",
    "    loss.backward()\n",
    "    if i % 500 == 0:\n",
    "        print(net, loss.item())\n",
    "    optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, a = torch.randn(1, 1).requires_grad_(True), \n",
    "                 b = torch.randn(1, 1).requires_grad_(True),\n",
    "                s = torch.randn(1, 1).requires_grad_(True)):\n",
    "        super(Net, self).__init__()\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.s = s\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.a * (x**self.s) + self.b\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.a.item()) + \"*x^{\" + str(self.s.item()) + \"} + \" + str(self.b.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1000, 1) * 50 + 1\n",
    "y = 1.2 * X**2.1 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[40.6607],\n",
       "         [33.2041],\n",
       "         [39.2492],\n",
       "         [32.7164],\n",
       "         [29.4106]]), tensor([[2877.7524],\n",
       "         [1881.9507],\n",
       "         [2672.2390],\n",
       "         [1824.4929],\n",
       "         [1459.5933]]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.47959113121032715*x^{-0.48400548100471497} + 0.14454585313796997 4319264.0\n",
      "2.7631752490997314*x^{1.877172827720642} + 2.1954638957977295 8244.8076171875\n",
      "2.5149152278900146*x^{1.9024364948272705} + 1.8842211961746216 6377.11181640625\n",
      "2.177595853805542*x^{1.9410412311553955} + 1.4942528009414673 4016.777587890625\n",
      "1.7988146543502808*x^{1.9921917915344238} + 1.1009531021118164 1762.1224365234375\n",
      "1.473905324935913*x^{2.045438289642334} + 0.801784098148346 408.5000915527344\n",
      "1.2921141386032104*x^{2.0805840492248535} + 0.6564140915870667 38.70995330810547\n",
      "1.2327325344085693*x^{2.093137264251709} + 0.6278352737426758 3.4141905307769775\n",
      "1.2216240167617798*x^{2.0955498218536377} + 0.6480336785316467 2.299376964569092\n",
      "1.220313310623169*x^{2.095832586288452} + 0.6849777102470398 2.238408327102661\n",
      "1.2199647426605225*x^{2.095904588699341} + 0.7330887317657471 2.173898935317993\n",
      "1.2195907831192017*x^{2.095980167388916} + 0.7940108180046082 2.0936200618743896\n",
      "1.2191179990768433*x^{2.096076726913452} + 0.8706614375114441 1.9947302341461182\n",
      "1.2185282707214355*x^{2.0961968898773193} + 0.966495156288147 1.8745616674423218\n",
      "1.2179479598999023*x^{2.0963051319122314} + 1.0848411321640015 1.7351102828979492\n",
      "1.2167457342147827*x^{2.095893383026123} + 1.2292536497116089 28.648839950561523\n",
      "1.216269612312317*x^{2.096712827682495} + 1.4027376174926758 1.6079100370407104\n",
      "1.2147579193115234*x^{2.096963882446289} + 1.6081639528274536 1.1660054922103882\n",
      "1.2127765417099*x^{2.0967705249786377} + 1.8456509113311768 23.147361755371094\n",
      "1.211917757987976*x^{2.097550392150879} + 2.111787796020508 0.7338033318519592\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-3128fd918299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "net = Net()\n",
    "# create your optimizer\n",
    "optimizer = optim.Adam([net.a, net.b, net.s], lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "for i in range(100000):\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(X)\n",
    "    loss = criterion(output, y) #+ 0.001 * net.a**2 + 0.01 * net.b**2 + 0.003 * net.s**2\n",
    "    loss.backward()\n",
    "    if i % 500 == 0:\n",
    "        print(net, loss.item())\n",
    "    optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
