{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q41R-POjCq1e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.nn import MSELoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "import formula\n",
    "import functions\n",
    "import importlib\n",
    "# from hessian import hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'functions' from '/home/zybinmikhail/Documents/LearningFormulas/functions.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(formula)\n",
    "importlib.reload(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "nSlve2bj8Fc4",
    "outputId": "8af20f2a-2615-4441-9f99-478c048ff8d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vYw3FOwkkZLg"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tY8vOWlB8Fec"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "1SUAR5jV8Fec",
    "outputId": "6b71a445-b255-4f0e-ef10-1bd239c8dcbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(24.9905)\n"
     ]
    }
   ],
   "source": [
    "print(functions.descriptive_length_of_fraction(1.0, 3.0))\n",
    "print(functions.descriptive_length_of_real_number(0.3333333345))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kxgsuc0Y8FgA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vMZsInkrCq1w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9aiZJrHCq1p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aTTheLOCq17"
   },
   "outputs": [],
   "source": [
    "def PrettyRepresent(some_tensor):\n",
    "    return some_tensor.cpu().numpy()[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.rand(1000, 1) * 1000\n",
    "X2 = torch.rand(1000, 1) * 1000\n",
    "X3 = torch.rand(1000, 1) * 1000\n",
    "X = torch.cat([X1, X2, X3], dim=1).to(device)\n",
    "assert X.shape[1] == 3\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "k_-H5b-ICq2A",
    "outputId": "e873e5c4-0881-473a-bad1-8d902547bb0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[412.1618, 152.1658, 782.4766],\n",
      "        [ 86.8828, 297.0470,  75.2827],\n",
      "        [819.7552, 682.7042, 515.2332],\n",
      "        ...,\n",
      "        [353.8344, 825.9497, 272.4909],\n",
      "        [649.2591, 441.5891, 109.4009],\n",
      "        [551.4265, 689.8264, 174.8335]], device='cuda:0')\n",
      "Attempt 0\n",
      "[-8.0, 7.0, 29.0] [14, 18, 16] [-0.5714285969734192, 0.3888888955116272, 1.8125]\n",
      "[-41.0, -8.0, 4.0] [8, 32, 25] [-5.125, -0.25, 0.1599999964237213]\n",
      "\n",
      "Trying Adam\n",
      "Run #1\n",
      "Epoch 5000, current loss 12.5, current formula (1.62e-07x_1^{2.57} + 0.145x_2^{-0.218} + 2.57x_3^{-3.53} + 0.143)\n",
      "Epoch 10000, current loss 11.5, current formula (1.62e-07x_1^{2.57} + 0.147x_2^{-0.216} + 1.73x_3^{-2.5} + 0.147)\n",
      "Finished run #1, loss 11.507048606872559, best loss 11.507048606872559\n",
      "Run #2\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #2, loss 2518087680.0, best loss 11.507048606872559\n",
      "Run #3\n",
      "Epoch 5000, current loss 1.41, current formula (-1.73x_1^{-5.42} + 1.58x_2^{0.217} + 2.6x_3^{0.059}-4.66)\n",
      "Epoch 10000, current loss 0.0808, current formula (-0.438x_1^{-8.55} + 1.5x_2^{0.0999} + 2.68x_3^{0.135}-3.88)\n",
      "Finished run #3, loss 0.08084731549024582, best loss 0.08084731549024582\n",
      "Run #4\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #4, loss 182735168.0, best loss 0.08084731549024582\n",
      "Run #5\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #5, loss 5961726.0, best loss 0.08084731549024582\n",
      "Run #6\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #6, loss 3898572.75, best loss 0.08084731549024582\n",
      "Run #7\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #7, loss 88331891245056.0, best loss 0.08084731549024582\n",
      "Run #8\n",
      "Epoch 5000, current loss 0.0463, current formula (0.0634x_1^{-2.13}-0.079x_2^{-0.0083} + 3.57x_3^{0.128}-2.83)\n",
      "Finished run #8, loss 0.0048703718930482864, best loss 0.0048703718930482864\n",
      "Run #9\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #9, loss 1068876431360.0, best loss 0.0048703718930482864\n",
      "Run #10\n",
      "Epoch 5000, current loss 0.0215, current formula (2.4x_1^{0.00186} + 6.86x_2^{-0.00392}-10.6x_3^{-0.0937} + 1.79)\n",
      "Epoch 10000, current loss 0.0176, current formula (2.97x_1^{0.000631} + 7.52x_2^{-0.00369}-12.3x_3^{-0.0753} + 2.38)\n",
      "Finished run #10, loss 0.017592905089259148, best loss 0.0048703718930482864\n",
      "(-0.254x_1^{-2.1} + 0.0782x_2^{-0.0106} + 3.59x_3^{0.113}-2.32)\n",
      "(\\frac{-3}{10}x_1^{\\frac{-21}{10}} + \\frac{1}{10}x_2^{\\frac{0}{10}} + \\frac{36}{10}x_3^{\\frac{1}{10}}\\frac{-23}{10})\n",
      "Trying Rprop\n",
      "Run #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run #1, loss 0.0009667888516560197, best loss 0.0009667888516560197\n",
      "Run #2\n",
      "Finished run #2, loss 1.3485785075317835e-06, best loss 1.3485785075317835e-06\n",
      "Run #3\n",
      "Finished run #3, loss 0.0006471396191045642, best loss 1.3485785075317835e-06\n",
      "Run #4\n",
      "Finished run #4, loss 0.016028162091970444, best loss 1.3485785075317835e-06\n",
      "Run #5\n",
      "Finished run #5, loss 0.0029740617610514164, best loss 1.3485785075317835e-06\n",
      "Run #6\n",
      "Finished run #6, loss 0.0007945856195874512, best loss 1.3485785075317835e-06\n",
      "Run #7\n",
      "Finished run #7, loss 0.019250646233558655, best loss 1.3485785075317835e-06\n",
      "Run #8\n",
      "Finished run #8, loss 0.022300735116004944, best loss 1.3485785075317835e-06\n",
      "Run #9\n",
      "Finished run #9, loss 0.019175121560692787, best loss 1.3485785075317835e-06\n",
      "Run #10\n",
      "Finished run #10, loss 0.021744828671216965, best loss 1.3485785075317835e-06\n",
      "(-0.567x_1^{-5.09} + 0.394x_2^{-0.273} + 1.85x_3^{0.158}-0.0374)\n",
      "(\\frac{-6}{10}x_1^{\\frac{-51}{10}} + \\frac{4}{10}x_2^{\\frac{-3}{10}} + \\frac{19}{10}x_3^{\\frac{1}{9}}\\frac{0}{10})\n",
      "Trying SGD\n",
      "Run #1\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #1, loss nan, best loss 1e+20\n",
      "Run #2\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #2, loss nan, best loss 1e+20\n",
      "Run #3\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #3, loss nan, best loss 1e+20\n",
      "Run #4\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #4, loss nan, best loss 1e+20\n",
      "Run #5\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #5, loss nan, best loss 1e+20\n",
      "Run #6\n",
      "Finished run #6, loss 0.41967660188674927, best loss 0.41967660188674927\n",
      "Run #7\n",
      "Finished run #7, loss 0.4081270694732666, best loss 0.4081270694732666\n",
      "Run #8\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #8, loss nan, best loss 0.4081270694732666\n",
      "Run #9\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #9, loss nan, best loss 0.4081270694732666\n",
      "Run #10\n",
      "Epoch 5000, current loss 0.252, current formula (-0.535x_1^{-24.2}-0.555x_2^{-2.99}-2.04x_3^{-0.223} + 5.38)\n",
      "Epoch 10000, current loss 0.124, current formula (-0.628x_1^{-24.2}-0.402x_2^{-2.99}-4.41x_3^{-0.206} + 6.15)\n",
      "Finished run #10, loss 0.12436775118112564, best loss 0.12436775118112564\n",
      "(-0.628x_1^{-24.2}-0.402x_2^{-2.99}-4.41x_3^{-0.206} + 6.15)\n",
      "(\\frac{-6}{10}x_1^{\\frac{-242}{10}}\\frac{-4}{10}x_2^{\\frac{-30}{10}}\\frac{-44}{10}x_3^{\\frac{-2}{10}} + \\frac{61}{10})\n",
      "#####\n",
      "Attempt 1\n",
      "[-33.0, -7.0, 32.0] [9, 16, 39] [-3.6666667461395264, -0.4375, 0.8205128312110901]\n",
      "[4.0, 31.0, -13.0] [2, 32, 28] [2.0, 0.96875, -0.4642857015132904]\n",
      "\n",
      "Trying Adam\n",
      "Run #1\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #1, loss 2232609406976.0, best loss 2232609406976.0\n",
      "Run #2\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #2, loss 40464233267200.0, best loss 2232609406976.0\n",
      "Run #3\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #3, loss 5063402061824.0, best loss 2232609406976.0\n",
      "Run #4\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #4, loss 4988115968.0, best loss 4988115968.0\n",
      "Run #5\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #5, loss 5.929100092049059e+20, best loss 4988115968.0\n",
      "Run #6\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #6, loss 649929856.0, best loss 649929856.0\n",
      "Run #7\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #7, loss 1725211869184.0, best loss 649929856.0\n",
      "Run #8\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #8, loss 663755712.0, best loss 649929856.0\n",
      "Run #9\n",
      "Epoch 5000, current loss 3.23e+04, current formula (-3.67x_1^{2.0}-0.661x_2^{-1.05} + 0.709x_3^{0.824} + 3.37)\n",
      "Epoch 10000, current loss 1.56e+07, current formula (-3.68x_1^{2.0} + 0.427x_2^{-1.22} + 0.6x_3^{0.755} + 2.94)\n",
      "Finished run #9, loss 15645781.0, best loss 15645781.0\n",
      "Run #10\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #10, loss 35192520704.0, best loss 15645781.0\n",
      "(-3.68x_1^{2.0} + 0.426x_2^{-1.22} + 0.599x_3^{0.754} + 2.94)\n",
      "(\\frac{-37}{10}x_1^{\\frac{20}{10}} + \\frac{4}{10}x_2^{\\frac{-12}{10}} + \\frac{6}{10}x_3^{\\frac{8}{10}} + \\frac{29}{10})\n",
      "Trying Rprop\n",
      "Run #1\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #1, loss 1194724294656.0, best loss 1194724294656.0\n",
      "Run #2\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #2, loss 1184787202048.0, best loss 1184787202048.0\n",
      "Run #3\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #3, loss 1411256832.0, best loss 1411256832.0\n",
      "Run #4\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #4, loss 1218931064832.0, best loss 1411256832.0\n",
      "Run #5\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #5, loss 1305895895040.0, best loss 1411256832.0\n",
      "Run #6\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #6, loss 10794153984.0, best loss 1411256832.0\n",
      "Run #7\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #7, loss 1301291859968.0, best loss 1411256832.0\n",
      "Run #8\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #8, loss 1225293299712.0, best loss 1411256832.0\n",
      "Run #9\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #9, loss 1183547785216.0, best loss 1411256832.0\n",
      "Run #10\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #10, loss 677788928.0, best loss 677788928.0\n",
      "(-8.09x_1^{1.88} + 10.3x_2^{-0.026} + 27.4x_3^{0.744} + 4.18e+04)\n",
      "(\\frac{-81}{10}x_1^{\\frac{19}{10}} + \\frac{103}{10}x_2^{\\frac{0}{10}} + \\frac{274}{10}x_3^{\\frac{7}{10}} + \\frac{418050}{10})\n",
      "Trying SGD\n",
      "Run #1\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #1, loss nan, best loss 1e+20\n",
      "Run #2\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #2, loss nan, best loss 1e+20\n",
      "Run #3\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #3, loss nan, best loss 1e+20\n",
      "Run #4\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #4, loss nan, best loss 1e+20\n",
      "Run #5\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #5, loss nan, best loss 1e+20\n",
      "Run #6\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #6, loss nan, best loss 1e+20\n",
      "Run #7\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #7, loss nan, best loss 1e+20\n",
      "Run #8\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #8, loss nan, best loss 1e+20\n",
      "Run #9\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #9, loss nan, best loss 1e+20\n",
      "Run #10\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #10, loss nan, best loss 1e+20\n",
      "(1.15x_1^{-2.07} + 0.629x_2^{0.227} + 1.36x_3^{0.837} + 5.87)\n",
      "(\\frac{11}{10}x_1^{\\frac{-21}{10}} + \\frac{6}{10}x_2^{\\frac{2}{10}} + \\frac{14}{10}x_3^{\\frac{8}{10}} + \\frac{59}{10})\n",
      "#####\n",
      "Attempt 2\n",
      "[8.0, 18.0, -41.0] [45, 35, 2] [0.17777778208255768, 0.5142857432365417, -20.5]\n",
      "[-35.0, -8.0, -47.0] [10, 4, 27] [-3.5, -2.0, -1.7407407760620117]\n",
      "\n",
      "Trying Adam\n",
      "Run #1\n",
      "Epoch 5000, current loss 0.0328, current formula (0.955x_1^{0.00864} + 0.508x_2^{-2.21}-13.9x_3^{-2.32}-1.01)\n",
      "Finished run #1, loss 0.0020943887066096067, best loss 0.0020943887066096067\n",
      "Run #2\n",
      "Epoch 5000, current loss 1.85e+03, current formula (12.2x_1^{0.199}-0.703x_2^{0.775} + 6.47x_3^{0.287} + 1.44)\n",
      "Epoch 10000, current loss 1.09e+02, current formula (14.2x_1^{-0.0632}-0.415x_2^{0.654} + 6.51x_3^{0.0756} + 2.17)\n",
      "Finished run #2, loss 109.3961410522461, best loss 0.0020943887066096067\n",
      "Run #3\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #3, loss 30175995625472.0, best loss 0.0020943887066096067\n",
      "Run #4\n",
      "Epoch 5000, current loss 1.1e+02, current formula (0.379x_1^{0.186} + 0.748x_2^{0.477}-0.000365x_3^{1.6}-0.0959)\n",
      "Epoch 10000, current loss 9.1, current formula (0.0828x_1^{0.107} + 0.514x_2^{0.351}-3.06e-05x_3^{1.6}-3.15)\n",
      "Finished run #4, loss 9.102225303649902, best loss 0.0020943887066096067\n",
      "Run #5\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #5, loss 13149634822144.0, best loss 0.0020943887066096067\n",
      "Run #6\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #6, loss 77393166336.0, best loss 0.0020943887066096067\n",
      "Run #7\n",
      "Epoch 5000, current loss 6.5, current formula (1.38x_1^{-16.8} + 0.432x_2^{-1.97} + 5.35x_3^{0.077}-8.59)\n",
      "Epoch 10000, current loss 6.44, current formula (1.93x_1^{-27.2} + 0.412x_2^{-1.96} + 10.1x_3^{0.052}-13.9)\n",
      "Finished run #7, loss 6.436680793762207, best loss 0.0020943887066096067\n",
      "Run #8\n",
      "Epoch 5000, current loss 6.94, current formula (-4.68e-05x_1^{0.979} + 0.000276x_2^{1.05}-0.492x_3^{-0.0364} + 0.131)\n",
      "Epoch 10000, current loss 6.63, current formula (0.0003x_1^{0.979}-6.44e-05x_2^{1.05}-1.14x_3^{-0.435}-0.0766)\n",
      "Finished run #8, loss 6.627725601196289, best loss 0.0020943887066096067\n",
      "Run #9\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #9, loss 36543401984.0, best loss 0.0020943887066096067\n",
      "Run #10\n",
      "Epoch 5000, current loss 20.0, current formula (-4.38x_1^{-4.38} + 1.86x_2^{0.288}-0.0318x_3^{0.802}-4.96)\n",
      "Epoch 10000, current loss 7.63, current formula (-0.435x_1^{-8.28} + 1.75x_2^{0.189} + 0.00562x_3^{0.8}-6.38)\n",
      "Finished run #10, loss 7.629556655883789, best loss 0.0020943887066096067\n",
      "(0.991x_1^{0.00137} + 0.514x_2^{-2.05}-18.7x_3^{-1.88}-1.0)\n",
      "(\\frac{10}{10}x_1^{\\frac{0}{10}} + \\frac{5}{10}x_2^{\\frac{-21}{10}}\\frac{-187}{10}x_3^{\\frac{-19}{10}}\\frac{-10}{10})\n",
      "Trying Rprop\n",
      "Run #1\n",
      "Finished run #1, loss 0.00042244544601999223, best loss 0.00042244544601999223\n",
      "Run #2\n",
      "Finished run #2, loss 0.0003978333552367985, best loss 0.0003978333552367985\n",
      "Run #3\n",
      "Finished run #3, loss 0.0004214481741655618, best loss 0.0003978333552367985\n",
      "Run #4\n",
      "Finished run #4, loss 0.00042106915498152375, best loss 0.0003978333552367985\n",
      "Run #5\n",
      "Finished run #5, loss 0.0003930280508939177, best loss 0.0003930280508939177\n",
      "Run #6\n",
      "Finished run #6, loss 0.00039767607813701034, best loss 0.0003930280508939177\n",
      "Run #7\n",
      "Epoch 5000, current loss 1.97, current formula (-3.18e-07x_1^{1.86} + 0.452x_2^{-3.93}-0.000109x_3^{-18.9} + 0.109)\n",
      "Epoch 10000, current loss 1.97, current formula (-3.18e-07x_1^{1.86} + 0.452x_2^{-3.93}-0.000109x_3^{-18.9} + 0.109)\n",
      "Finished run #7, loss 1.9706653356552124, best loss 0.0003930280508939177\n",
      "Run #8\n",
      "Finished run #8, loss 0.00040459970477968454, best loss 0.0003930280508939177\n",
      "Run #9\n",
      "Finished run #9, loss 1.7944006685866043e-05, best loss 1.7944006685866043e-05\n",
      "Run #10\n",
      "Epoch 5000, current loss 6.41, current formula (2.06x_1^{-23.9}-12.4x_2^{-0.00435} + 14.2x_3^{0.0412}-6.18)\n",
      "Finished run #10, loss 6.393729209899902, best loss 1.7944006685866043e-05\n",
      "(12.0x_1^{-8.21e+02} + 0.514x_2^{-2.0}-20.5x_3^{-1.74} + 0.000196)\n",
      "(\\frac{120}{10}x_1^{\\frac{-8206}{10}} + \\frac{5}{10}x_2^{\\frac{-20}{10}}\\frac{-205}{10}x_3^{\\frac{-17}{10}} + \\frac{0}{10})\n",
      "Trying SGD\n",
      "Run #1\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #1, loss nan, best loss 1e+20\n",
      "Run #2\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #2, loss nan, best loss 1e+20\n",
      "Run #3\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #3, loss nan, best loss 1e+20\n",
      "Run #4\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #4, loss nan, best loss 1e+20\n",
      "Run #5\n",
      "Epoch 5000, current loss 0.247, current formula (3.83e+03x_1^{-4.93e+04} + 0.563x_2^{-1.15}-6.09x_3^{-3.53}-0.0202)\n",
      "Epoch 10000, current loss 0.156, current formula (3.83e+03x_1^{-4.93e+04} + 0.541x_2^{-1.19}-8.17x_3^{-3.1}-0.017)\n",
      "Finished run #5, loss 0.15567569434642792, best loss 0.15567569434642792\n",
      "Run #6\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #6, loss nan, best loss 0.15567569434642792\n",
      "Run #7\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #7, loss nan, best loss 0.15567569434642792\n",
      "Run #8\n",
      "Epoch 5000, current loss 0.253, current formula (0.648x_1^{0.0276} + 0.666x_2^{-1.13}-5.99x_3^{-3.55}-0.784)\n",
      "Epoch 10000, current loss 0.158, current formula (0.66x_1^{0.0226} + 0.628x_2^{-1.18}-8.1x_3^{-3.12}-0.772)\n",
      "Finished run #8, loss 0.15795408189296722, best loss 0.15567569434642792\n",
      "Run #9\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #9, loss nan, best loss 0.15567569434642792\n",
      "Run #10\n",
      "Epoch 5000, current loss 0.229, current formula (-1.22e+04x_1^{-1.63e+05} + 0.181x_2^{-17.9}-6.44x_3^{-3.45}-0.0179)\n",
      "Epoch 10000, current loss 0.147, current formula (-1.22e+04x_1^{-1.63e+05} + 0.112x_2^{-17.9}-8.41x_3^{-3.06}-0.0149)\n",
      "Finished run #10, loss 0.14728142321109772, best loss 0.14728142321109772\n",
      "(-1.22e+04x_1^{-1.63e+05} + 0.112x_2^{-17.9}-8.41x_3^{-3.06}-0.0149)\n",
      "(\\frac{-121948}{10}x_1^{\\frac{-1625710}{10}} + \\frac{1}{10}x_2^{\\frac{-179}{10}}\\frac{-84}{10}x_3^{\\frac{-31}{10}}\\frac{0}{10})\n",
      "#####\n",
      "Attempt 3\n",
      "[8.0, 7.0, -10.0] [21, 25, 30] [0.380952388048172, 0.2800000011920929, -0.3333333432674408]\n",
      "[39.0, 27.0, -2.0] [32, 34, 30] [1.21875, 0.7941176295280457, -0.06666667014360428]\n",
      "\n",
      "Trying Adam\n",
      "Run #1\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #1, loss 362529.9375, best loss 362529.9375\n",
      "Run #2\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #2, loss 3.763206159780926e+21, best loss 362529.9375\n",
      "Run #3\n",
      "Epoch 5000, current loss 4.06e+02, current formula (0.522x_1^{1.17}-31.8x_2^{-0.361} + 0.0303x_3^{0.912} + 3.93)\n",
      "Epoch 10000, current loss 2.74e+02, current formula (0.458x_1^{1.19}-74.5x_2^{-0.311} + 0.0449x_3^{0.798} + 26.6)\n",
      "Finished run #3, loss 274.4373779296875, best loss 274.4373779296875\n",
      "Run #4\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #4, loss 485396.875, best loss 274.4373779296875\n",
      "Run #5\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #5, loss 3889460224.0, best loss 274.4373779296875\n",
      "Run #6\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #6, loss 2923716864.0, best loss 274.4373779296875\n",
      "Run #7\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #7, loss 240589001981952.0, best loss 274.4373779296875\n",
      "Run #8\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #8, loss 1250942.75, best loss 274.4373779296875\n",
      "Run #9\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #9, loss 627577856.0, best loss 274.4373779296875\n",
      "Run #10\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #10, loss 302029.46875, best loss 274.4373779296875\n",
      "(0.458x_1^{1.19}-74.5x_2^{-0.31} + 0.0448x_3^{0.798} + 26.6)\n",
      "(\\frac{5}{10}x_1^{\\frac{12}{10}}\\frac{-745}{10}x_2^{\\frac{-3}{10}} + \\frac{0}{10}x_3^{\\frac{8}{10}} + \\frac{266}{10})\n",
      "Trying Rprop\n",
      "Run #1\n",
      "Epoch 5000, current loss 8.63e+04, current formula (-1.02e+04x_1^{-0.0469} + 0.00683x_2^{1.37}-52.2x_3^{-2.59} + 8.53e+03)\n",
      "Epoch 10000, current loss 8.52e+04, current formula (-1.11e+04x_1^{-0.0427} + 4.18e-05x_2^{2.13}-51.1x_3^{-2.59} + 9.43e+03)\n",
      "Finished run #1, loss 85218.828125, best loss 85218.828125\n",
      "Run #2\n",
      "Epoch 5000, current loss 3.85e+02, current formula (0.474x_1^{1.19}-15.5x_2^{-8.7} + 96.6x_3^{0.000352}-74.0)\n",
      "Epoch 10000, current loss 78.0, current formula (0.381x_1^{1.22}-2.97e+02x_2^{-0.0813} + 2.49e+02x_3^{0.00104}-29.4)\n",
      "Finished run #2, loss 77.9814682006836, best loss 77.9814682006836\n",
      "Run #3\n",
      "Epoch 5000, current loss 10.4, current formula (0.337x_1^{1.24} + 1.86x_2^{0.536} + 0.823x_3^{0.0794}-5.86)\n",
      "Epoch 10000, current loss 0.457, current formula (0.373x_1^{1.22} + 0.472x_2^{0.722} + 1.03x_3^{0.0587}-3.01)\n",
      "Finished run #3, loss 0.45653173327445984, best loss 0.45653173327445984\n",
      "Run #4\n",
      "Epoch 5000, current loss 13.5, current formula (0.442x_1^{1.2} + 1.32x_2^{0.584} + 0.000216x_3^{0.631}-19.0)\n",
      "Epoch 10000, current loss 0.342, current formula (0.387x_1^{1.22} + 0.436x_2^{0.733} + 0.00118x_3^{0.626}-3.46)\n",
      "Finished run #4, loss 0.3423432409763336, best loss 0.3423432409763336\n",
      "Run #5\n",
      "Epoch 5000, current loss 75.1, current formula (0.259x_1^{1.27} + 5.45x_2^{0.396} + 4.63x_3^{0.052}-6.88)\n",
      "Epoch 10000, current loss 4.31, current formula (0.358x_1^{1.23} + 1.33x_2^{0.582} + 4.77x_3^{0.0356}-11.5)\n",
      "Finished run #5, loss 4.3055853843688965, best loss 0.3423432409763336\n",
      "Run #6\n",
      "Epoch 5000, current loss 8.63e+04, current formula (-1.06e+04x_1^{-0.045} + 4.08x_2^{0.456} + 1.42x_3^{0.396} + 8.87e+03)\n",
      "Epoch 10000, current loss 8.37e+04, current formula (-1.41e+04x_1^{-0.0324} + 3.53x_2^{0.474} + 1.42x_3^{0.379} + 1.23e+04)\n",
      "Finished run #6, loss 83698.46875, best loss 0.3423432409763336\n",
      "Run #7\n",
      "Epoch 5000, current loss 1.29e+02, current formula (0.498x_1^{1.18}-2.28e+02x_2^{-0.126} + 81.3x_3^{0.000875} + 47.9)\n",
      "Epoch 10000, current loss 76.4, current formula (0.397x_1^{1.21}-3.34e+02x_2^{-0.0689} + 1.28e+02x_3^{0.0011} + 1.29e+02)\n",
      "Finished run #7, loss 76.40860748291016, best loss 0.3423432409763336\n",
      "Run #8\n",
      "Epoch 5000, current loss 9.16, current formula (0.435x_1^{1.2} + 0.608x_2^{0.689} + 2.85x_3^{0.00124}-15.5)\n",
      "Epoch 10000, current loss 0.265, current formula (0.386x_1^{1.22} + 0.418x_2^{0.739} + 9.33x_3^{0.00497}-12.6)\n",
      "Finished run #8, loss 0.26524218916893005, best loss 0.26524218916893005\n",
      "Run #9\n",
      "Epoch 5000, current loss 8.59e+04, current formula (-1.09e+04x_1^{-0.0438} + 0.0636x_2^{1.04} + 1.82x_3^{0.363} + 9.15e+03)\n",
      "Epoch 10000, current loss 8.44e+04, current formula (-1.22e+04x_1^{-0.0381} + 5.86e-05x_2^{2.08} + 1.81x_3^{0.359} + 1.06e+04)\n",
      "Finished run #9, loss 84425.3515625, best loss 0.26524218916893005\n",
      "Run #10\n",
      "Epoch 5000, current loss 26.1, current formula (0.307x_1^{1.25} + 2.58x_2^{0.492} + 12.0x_3^{-0.00447}-13.6)\n",
      "Epoch 10000, current loss 1.09, current formula (0.369x_1^{1.22} + 0.608x_2^{0.687} + 6.99x_3^{0.0176}-9.93)\n",
      "Finished run #10, loss 1.0885483026504517, best loss 0.26524218916893005\n",
      "(0.386x_1^{1.22} + 0.418x_2^{0.739} + 9.33x_3^{0.00496}-12.6)\n",
      "(\\frac{4}{10}x_1^{\\frac{12}{10}} + \\frac{4}{10}x_2^{\\frac{7}{10}} + \\frac{93}{10}x_3^{\\frac{0}{10}}\\frac{-126}{10})\n",
      "Trying SGD\n",
      "Run #1\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #1, loss nan, best loss 1e+20\n",
      "Run #2\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #2, loss nan, best loss 1e+20\n",
      "Run #3\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #3, loss nan, best loss 1e+20\n",
      "Run #4\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #4, loss nan, best loss 1e+20\n",
      "Run #5\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #5, loss nan, best loss 1e+20\n",
      "Run #6\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #6, loss nan, best loss 1e+20\n",
      "Run #7\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #7, loss nan, best loss 1e+20\n",
      "Run #8\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #8, loss nan, best loss 1e+20\n",
      "Run #9\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #9, loss nan, best loss 1e+20\n",
      "Run #10\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #10, loss nan, best loss 1e+20\n",
      "(0.423x_1^{2.35}-0.171x_2^{-2.87} + 2.41x_3^{-0.529} + 0.902)\n",
      "(\\frac{4}{10}x_1^{\\frac{23}{10}}\\frac{-2}{10}x_2^{\\frac{-29}{10}} + \\frac{24}{10}x_3^{\\frac{-5}{10}} + \\frac{9}{10})\n",
      "#####\n",
      "Attempt 4\n",
      "[-32.0, 40.0, -14.0] [24, 45, 42] [-1.3333333730697632, 0.8888888955116272, -0.3333333432674408]\n",
      "[-9.0, -38.0, 4.0] [12, 25, 11] [-0.75, -1.5199999809265137, 0.3636363744735718]\n",
      "\n",
      "Trying Adam\n",
      "Run #1\n",
      "Epoch 5000, current loss 2.19, current formula (-0.541x_1^{-1.31} + 2.94x_2^{-3.94}-0.00142x_3^{1.23} + 0.801)\n",
      "Finished run #1, loss 0.07144831120967865, best loss 0.07144831120967865\n",
      "Run #2\n",
      "Epoch 5000, current loss 0.0231, current formula (0.15x_1^{0.27}-1.34x_2^{-0.0125}-0.144x_3^{0.466}-0.108)\n",
      "Epoch 10000, current loss 0.00557, current formula (0.0501x_1^{0.246}-0.341x_2^{0.0202}-0.303x_3^{0.375} + 0.0591)\n",
      "Finished run #2, loss 0.0055735413916409016, best loss 0.0055735413916409016\n",
      "Run #3\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #3, loss 252933856.0, best loss 0.0055735413916409016\n",
      "Run #4\n",
      "Finished run #4, loss 0.01396843884140253, best loss 0.0055735413916409016\n",
      "Run #5\n",
      "Epoch 5000, current loss 0.157, current formula (-4.85x_1^{-0.0102} + 0.875x_2^{-1.14} + 7.78x_3^{-0.156}-1.6)\n",
      "Epoch 10000, current loss 0.0822, current formula (-7.71x_1^{-0.00773} + 0.926x_2^{-1.17} + 13.8x_3^{-0.0839}-4.13)\n",
      "Finished run #5, loss 0.08222932368516922, best loss 0.0055735413916409016\n",
      "Run #6\n",
      "Epoch 5000, current loss 0.176, current formula (-3.83x_1^{-0.0136} + 0.862x_2^{-1.13} + 7.17x_3^{-0.162}-2.32)\n",
      "Epoch 10000, current loss 0.0837, current formula (-7.18x_1^{-0.00838} + 0.926x_2^{-1.17} + 13.6x_3^{-0.0862}-4.37)\n",
      "Finished run #6, loss 0.08372222632169724, best loss 0.0055735413916409016\n",
      "Run #7\n",
      "Epoch 5000, current loss 0.917, current formula (0.29x_1^{-0.0489}-3.35x_2^{0.102} + 1.03x_3^{-0.105} + 2.29)\n",
      "Epoch 10000, current loss 0.456, current formula (-2.64x_1^{-0.0128}-3.32x_2^{0.0114} + 2.31x_3^{-0.195} + 2.2)\n",
      "Finished run #7, loss 0.4556600749492645, best loss 0.0055735413916409016\n",
      "Run #8\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #8, loss 13112763392.0, best loss 0.0055735413916409016\n",
      "Run #9\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #9, loss 441606111232.0, best loss 0.0055735413916409016\n",
      "Run #10\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #10, loss 107476472.0, best loss 0.0055735413916409016\n",
      "(0.0501x_1^{0.246}-0.341x_2^{0.0202}-0.303x_3^{0.375} + 0.0591)\n",
      "(\\frac{1}{10}x_1^{\\frac{2}{10}}\\frac{-3}{10}x_2^{\\frac{0}{10}}\\frac{-3}{10}x_3^{\\frac{4}{10}} + \\frac{1}{10})\n",
      "Trying Rprop\n",
      "Run #1\n",
      "Finished run #1, loss 0.009285347536206245, best loss 0.009285347536206245\n",
      "Run #2\n",
      "Finished run #2, loss 0.11833304911851883, best loss 0.009285347536206245\n",
      "Run #3\n",
      "Finished run #3, loss 0.0018909325590357184, best loss 0.0018909325590357184\n",
      "Run #4\n",
      "Finished run #4, loss 0.010358518920838833, best loss 0.0018909325590357184\n",
      "Run #5\n",
      "Epoch 5000, current loss 0.0692, current formula (-13.0x_1^{-0.00489}-2.9x_2^{0.00387} + 19.6x_3^{-0.0531}-1.8)\n",
      "Finished run #5, loss 0.06357164680957794, best loss 0.0018909325590357184\n",
      "Run #6\n",
      "Finished run #6, loss 0.0029039971996098757, best loss 0.0018909325590357184\n",
      "Run #7\n",
      "Epoch 5000, current loss 0.069, current formula (-11.0x_1^{-0.0059}-0.194x_2^{0.0363} + 19.7x_3^{-0.0525}-6.68)\n",
      "Finished run #7, loss 0.06541474908590317, best loss 0.0018909325590357184\n",
      "Run #8\n",
      "Finished run #8, loss 0.004774116445332766, best loss 0.0018909325590357184\n",
      "Run #9\n",
      "Epoch 5000, current loss 0.0684, current formula (-11.2x_1^{-0.00568}-1.47x_2^{0.00718} + 20.1x_3^{-0.0513}-5.58)\n",
      "Epoch 10000, current loss 0.0643, current formula (-15.2x_1^{-0.00411}-1.51x_2^{0.00657} + 24.2x_3^{-0.0408}-5.64)\n",
      "Finished run #9, loss 0.0642966702580452, best loss 0.0018909325590357184\n",
      "Run #10\n",
      "Finished run #10, loss 0.0008230960229411721, best loss 0.0008230960229411721\n",
      "(-1.39x_1^{-0.773} + 0.904x_2^{-1.45}-0.568x_3^{0.302} + 0.5)\n",
      "(\\frac{-14}{10}x_1^{\\frac{-8}{10}} + \\frac{9}{10}x_2^{\\frac{-14}{10}}\\frac{-6}{10}x_3^{\\frac{3}{10}} + \\frac{5}{10})\n",
      "Trying SGD\n",
      "Run #1\n",
      "Epoch 5000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Epoch 10000, current loss nan, current formula (nanx_1^{nan}nanx_2^{nan}nanx_3^{nan}nan)\n",
      "Finished run #1, loss nan, best loss 1e+20\n",
      "Run #2\n"
     ]
    }
   ],
   "source": [
    "for attempt in range(100):\n",
    "    print(\"Attempt\", attempt)\n",
    "    lambd_num = torch.randint(-50, 50, (1, 3)).float().to(device)\n",
    "    lambd_denom = torch.randint(1, 50, (1, 3)).to(device)\n",
    "    lambd = lambd_num / lambd_denom\n",
    "    print(PrettyRepresent(lambd_num), PrettyRepresent(lambd_denom), PrettyRepresent(lambd))\n",
    "    power_num = torch.randint(-50, 50, (1, 3)).float().to(device)\n",
    "    power_denom = torch.randint(1, 50, (1, 3)).to(device)\n",
    "    power = power_num / power_denom\n",
    "    print(PrettyRepresent(power_num), PrettyRepresent(power_denom), PrettyRepresent(power))\n",
    "    \n",
    "    print()\n",
    "    y = torch.sum(lambd * X**power, 1, keepdim=True)\n",
    "    # X = X.to(device)\n",
    "    # y = y.to(device)\n",
    "    print(\"Trying Adam\")\n",
    "    formula = LearnFormula(X, y, optimizer_for_formula=optim.Adam, device=device)\n",
    "    print(formula)\n",
    "    print(formula.simplify(X, y))\n",
    "    print(\"Trying Rprop\")\n",
    "    formula = LearnFormula(X, y, optimizer_for_formula=optim.Rprop, device=device)\n",
    "    print(formula)\n",
    "    print(formula.simplify(X, y))\n",
    "    print(\"Trying SGD\")\n",
    "    formula = LearnFormula(X, y, optimizer_for_formula=optim.SGD, device=device)\n",
    "    print(formula)\n",
    "    print(formula.simplify(X, y))\n",
    "    print(\"#####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "nvcKVs8XwWx8",
    "outputId": "55ee0ca2-9c88-4fcb-afca-4d2127a54246"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.7179487347602844, 0.0714285746216774, 4.5]]"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambd.cpu().numpy()[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-_lGNjj8FgA"
   },
   "outputs": [],
   "source": [
    "formula1 = LearnFormula(X1, y1, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kIpM2aWD8FgA"
   },
   "outputs": [],
   "source": [
    "simplified_formula1 = formula.simplify(X1, y1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1Io0KgL8FgA"
   },
   "outputs": [],
   "source": [
    "PrintFormula(simplified_formula1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EuehoTT18FgA"
   },
   "outputs": [],
   "source": [
    "formula = LearnFormula(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPx_4rgA8FgA"
   },
   "outputs": [],
   "source": [
    "simplified_formula = formula.simplify(X2, y2, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "keL2hOKk8FgA"
   },
   "outputs": [],
   "source": [
    "PrintFormula(simplified_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "STUGWd0W8Fhk",
    "outputId": "8abecccc-04d5-4f85-870d-e340f534e9d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  0, -2]])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JWimgIzCOqg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.5000, 15.0000],\n",
      "        [15.0000,  4.5000]], grad_fn=<CopySlices>)\n",
      "tensor([[4.0000, 8.0000],\n",
      "        [8.0000, 4.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "x = torch.tensor([1.5, 2.5], requires_grad=True)\n",
    "y = x.pow(2).prod()\n",
    "h = hessian(y, x, create_graph=True)\n",
    "\n",
    "print(h)\n",
    "# tensor([[12.5, 15],\n",
    "#         [15,  4.5]], grad_fn=<CopySlices>)\n",
    "\n",
    "h2 = hessian(h.sum(), x)\n",
    "print(h2)\n",
    "# tensor([[4, 8],\n",
    "#         [8, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[900.0867, 490.2016, 562.9807],\n",
      "        [426.8015,  82.8674, 137.5523],\n",
      "        [199.5287, 102.5683, 622.7318],\n",
      "        ...,\n",
      "        [134.0636, 224.8117,  88.9737],\n",
      "        [750.7083, 444.3012, 548.6312],\n",
      "        [635.8929, 532.0922, 606.6346]])\n",
      "[-47.0, -47.0, 5.0] [35, 35, 20] [-1.3428571224212646, -1.3428571224212646, 0.25]\n",
      "[-46.0, -50.0, 11.0] [10, 15, 8] [-4.599999904632568, -3.3333332538604736, 1.375]\n",
      "\n",
      "Run #1\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #1, loss 87031272.0, best loss 87031272.0\n",
      "Run #2\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #2, loss 1.900191663163179e+18, best loss 87031272.0\n",
      "Run #3\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #3, loss 1.9040583706801603e+18, best loss 87031272.0\n",
      "Run #4\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #4, loss 2056560.125, best loss 2056560.125\n",
      "Run #5\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #5, loss 112877472.0, best loss 2056560.125\n",
      "Run #6\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #6, loss 1.9002640934916588e+18, best loss 2056560.125\n",
      "Run #7\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #7, loss 29610600.0, best loss 2056560.125\n",
      "Run #8\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #8, loss 1.9002541978870088e+18, best loss 2056560.125\n",
      "Run #9\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #9, loss 1400251.875, best loss 1400251.875\n",
      "Run #10\n",
      "The model does not seem to converge, finishing at epoch 1000\n",
      "Finished run #10, loss 1.9000389684858716e+18, best loss 1400251.875\n"
     ]
    }
   ],
   "source": [
    "X1 = torch.rand(1000, 1) * 1000\n",
    "X2 = torch.rand(1000, 1) * 1000\n",
    "X3 = torch.rand(1000, 1) * 1000\n",
    "X = torch.cat([X1, X2, X3], dim=1).to(device)\n",
    "assert X.shape[1] == 3\n",
    "print(X)\n",
    "\n",
    "lambd_num = torch.randint(-50, 50, (1, 3)).float().to(device)\n",
    "lambd_denom = torch.randint(1, 50, (1, 3)).to(device)\n",
    "lambd = lambd_num / lambd_denom\n",
    "print(PrettyRepresent(lambd_num), PrettyRepresent(lambd_denom), PrettyRepresent(lambd))\n",
    "power_num = torch.randint(-50, 50, (1, 3)).float().to(device)\n",
    "power_denom = torch.randint(1, 50, (1, 3)).to(device)\n",
    "power = power_num / power_denom\n",
    "print(PrettyRepresent(power_num), PrettyRepresent(power_denom), PrettyRepresent(power))\n",
    "\n",
    "print()\n",
    "y = torch.sum(lambd * X**power, 1, keepdim=True)\n",
    "# X = X.to(device)\n",
    "# y = y.to(device)\n",
    "formula = LearnFormula(X, y, optimizer_for_formula=optim.Rprop, device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.6x_1^{-4.33} + 11.5x_2^{0.713}-1.96e+03x_3^{-0.414} + 4.53e+02)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6cbe786b98cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbase_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSWA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from torchcontrib.optim import SWA\n",
    "\n",
    "...\n",
    "...\n",
    "\n",
    "# training loop\n",
    "base_opt = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "opt = torchcontrib.optim.SWA(base_opt, swa_start=10, swa_freq=5, swa_lr=0.05)\n",
    "for _ in range(100):\n",
    "     opt.zero_grad()\n",
    "     loss_fn(model(input), target).backward()\n",
    "     opt.step()\n",
    "opt.swap_swa_sgd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchcontrib\n",
      "  Downloading https://files.pythonhosted.org/packages/72/36/45d475035ab35353911e72a03c1c1210eba63b71e5a6917a9e78a046aa10/torchcontrib-0.0.2.tar.gz\n",
      "Building wheels for collected packages: torchcontrib\n",
      "  Building wheel for torchcontrib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/zybinmikhail/snap/jupyter/6/.cache/pip/wheels/06/06/7b/a5f5920bbf4f12a2c927e438fac17d4cd9560f8336b00e9a99\n",
      "Successfully built torchcontrib\n",
      "Installing collected packages: torchcontrib\n",
      "Successfully installed torchcontrib-0.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install torchcontrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "demonstration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
